<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>SymmetricDS User Guide</title><link rel="stylesheet" href="css/docbook-style.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.72.0"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div xmlns:fo="http://www.w3.org/1999/XSL/Format" id="banner"><a style="border:none;" href="http://www.symmetricds.org/" title="SymmetricDS User Guide"><img style="border:none;" alt="SymmetricDS" src="images/banner-logo.gif"></a></div><div class="book" lang="en"><div class="titlepage"><div><div><h1 class="title"><a name="user-guide"></a>SymmetricDS User Guide</h1></div><div><div xmlns:fo="http://www.w3.org/1999/XSL/Format" class="authorgroup"><h2>Authors</h2><p></p>
            <span class="author"><span class="firstname">Eric</span> <span class="surname">Long</span></span>
            , <span class="author"><span class="firstname">Chris</span> <span class="surname">Henson</span></span>
            , <span class="author"><span class="firstname">Mark</span> <span class="surname">Hanes</span></span>
            , <span class="author"><span class="firstname">Greg</span> <span class="surname">Wilmer</span></span>
        </div></div><div><p class="releaseinfo">
            v3.5
        </p></div><div><p class="copyright">Copyright &copy; 2007 - 2013 JumpMind, Inc</p></div><div><div class="legalnotice"><a name="d4e22"></a>
            <p>
                Permission to use, copy, modify, and distribute the SymmetricDS User Guide Version
                3.5 for any purpose and without fee is hereby granted in perpetuity, provided that
                the above copyright notice and this paragraph appear in all copies.
            </p>
        </div></div></div><hr></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="preface"><a href="#d4e24">Preface</a></span></dt><dt><span class="chapter"><a href="#introduction">1. Introduction</a></span></dt><dd><dl><dt><span class="section"><a href="#requirements">1.1. System Requirements</a></span></dt><dt><span class="section"><a href="#definition">1.2. Overview</a></span></dt><dd><dl><dt><span class="section"><a href="#d4e74">1.2.1. A Node is Born</a></span></dt><dt><span class="section"><a href="#d4e87">1.2.2. Capturing Changes</a></span></dt><dt><span class="section"><a href="#d4e100">1.2.3. Change Delivery</a></span></dt><dt><span class="section"><a href="#d4e105">1.2.4. Channeling Data</a></span></dt></dl></dd><dt><span class="section"><a href="#d4e111">1.3. Features</a></span></dt><dd><dl><dt><span class="section"><a href="#bi-sync">1.3.1. Two-Way Table Synchronization</a></span></dt><dt><span class="section"><a href="#data-channels">1.3.2. Data Channels</a></span></dt><dt><span class="section"><a href="#notification">1.3.3. Change Notification</a></span></dt><dt><span class="section"><a href="#transports">1.3.4. HTTP(S) Transport</a></span></dt><dt><span class="section"><a href="#plugins">1.3.5. Data Filtering and Rerouting</a></span></dt><dt><span class="section"><a href="#transactions">1.3.6. Transaction Awareness</a></span></dt><dt><span class="section"><a href="#jmx">1.3.7. Remote Management</a></span></dt><dt><span class="section"><a href="#feature-filesync">1.3.8. File Synchronization</a></span></dt></dl></dd><dt><span class="section"><a href="#background">1.4. Origins</a></span></dt><dt><span class="section"><a href="#d4e176">1.5. Why Database Triggers?</a></span></dt><dt><span class="section"><a href="#d4e192">1.6. Support</a></span></dt><dt><span class="section"><a href="#d4e197">1.7. What's New in SymmetricDS 3</a></span></dt></dl></dd><dt><span class="chapter"><a href="#tutorial">2. Quick Start Tutorial</a></span></dt><dd><dl><dt><span class="section"><a href="#tutorial-install">2.1. Installing SymmetricDS</a></span></dt><dt><span class="section"><a href="#ch02-create-database">2.2. Creating and Populating Your Databases</a></span></dt><dt><span class="section"><a href="#ch02-start-server">2.3. Starting SymmetricDS</a></span></dt><dt><span class="section"><a href="#ch02-register-node">2.4. Registering a Node</a></span></dt><dt><span class="section"><a href="#ch02-initial-load">2.5. Sending an Initial Load</a></span></dt><dt><span class="section"><a href="#ch02-pull">2.6. Pulling Data</a></span></dt><dt><span class="section"><a href="#ch02-push">2.7. Pushing Data</a></span></dt><dt><span class="section"><a href="#ch02-verify-outgoing">2.8. Verifying Outgoing Batches</a></span></dt><dt><span class="section"><a href="#ch02-verify-incoming">2.9. Verifying Incoming Batches</a></span></dt><dt><span class="section"><a href="#multi-homing">2.10. Multi-Homing</a></span></dt></dl></dd><dt><span class="chapter"><a href="#planning">3. Planning</a></span></dt><dd><dl><dt><span class="section"><a href="#identifying-nodes">3.1. Identifying Nodes</a></span></dt><dt><span class="section"><a href="#organizing-nodes">3.2. Organizing Nodes</a></span></dt><dt><span class="section"><a href="#grouping-nodes">3.3. Defining Node Groups</a></span></dt><dt><span class="section"><a href="#linking-nodes">3.4. Linking Nodes</a></span></dt><dt><span class="section"><a href="#choosing-channels">3.5. Choosing Data Channels</a></span></dt><dt><span class="section"><a href="#defining-data-changes">3.6. Defining Data Changes to be Captured and Routed</a></span></dt><dd><dl><dt><span class="section"><a href="#defining-data-changes-triggers">3.6.1. Defining Triggers</a></span></dt><dt><span class="section"><a href="#defining-data-changes-routers">3.6.2. Defining Routers</a></span></dt><dt><span class="section"><a href="#defining-data-changes-trigger-routers">3.6.3. Mapping Triggers to Routers</a></span></dt><dd><dl><dt><span class="section"><a href="#defining-data-changes-trigger-routers-initial-load">3.6.3.1. Planning Initial Loads</a></span></dt><dt><span class="section"><a href="#defining-data-changes-trigger-routers-ping-back">3.6.3.2. Circular References and "Ping Back"</a></span></dt></dl></dd><dt><span class="section"><a href="#planning-registration">3.6.4. Planning for Registering Nodes</a></span></dt></dl></dd><dt><span class="section"><a href="#defining-transformation">3.7. Planning Data Transformations</a></span></dt><dt><span class="section"><a href="#defining-conflicts">3.8. Planning Conflict Detection and Resolution</a></span></dt></dl></dd><dt><span class="chapter"><a href="#configuration">4. Configuration</a></span></dt><dd><dl><dt><span class="section"><a href="#configuration-node-properties">4.1. Node Properties</a></span></dt><dt><span class="section"><a href="#configuration-node">4.2. Node</a></span></dt><dt><span class="section"><a href="#configuration-node-group">4.3. Node Group</a></span></dt><dt><span class="section"><a href="#configuration-node-group-link">4.4. Node Group Link</a></span></dt><dt><span class="section"><a href="#configuration-channel">4.5. Channel</a></span></dt><dt><span class="section"><a href="#configuration-triggers-and-routers">4.6. Triggers, Routers, and Trigger / Routers Mappings</a></span></dt><dd><dl><dt><span class="section"><a href="#configuration-trigger">4.6.1. Trigger</a></span></dt><dd><dl><dt><span class="section"><a href="#configuration-trigger-lobs">4.6.1.1. Large Objects</a></span></dt><dt><span class="section"><a href="#configuration-trigger-external-select">4.6.1.2. External Select</a></span></dt></dl></dd><dt><span class="section"><a href="#configuration-router">4.6.2. Router</a></span></dt><dd><dl><dt><span class="section"><a href="#configuration-default-router">4.6.2.1. Default Router</a></span></dt><dt><span class="section"><a href="#configuration-column-match-router">4.6.2.2. Column Match Router</a></span></dt><dt><span class="section"><a href="#configuration-lookup-table-router">4.6.2.3. Lookup Table Router</a></span></dt><dt><span class="section"><a href="#configuration-subselect-router">4.6.2.4. Subselect Router</a></span></dt><dt><span class="section"><a href="#configuration-scripted-router">4.6.2.5. Scripted Router</a></span></dt><dt><span class="section"><a href="#configuration-audit-table-router">4.6.2.6. Audit Table Router</a></span></dt><dt><span class="section"><a href="#configuration-routing-external-select">4.6.2.7. Utilizing External Select when Routing</a></span></dt></dl></dd><dt><span class="section"><a href="#configuration-trigger-router">4.6.3. Trigger / Router Mappings</a></span></dt><dd><dl><dt><span class="section"><a href="#configuration-trigger-router-enabled">4.6.3.1. Enable / disable trigger router</a></span></dt><dt><span class="section"><a href="#configuration-initial-load">4.6.3.2. Initial Loads</a></span></dt><dt><span class="section"><a href="#configuration-dead-triggers">4.6.3.3. Dead Triggers</a></span></dt><dt><span class="section"><a href="#configuration-trigger-router-ping-back">4.6.3.4. Enabling "Ping Back"</a></span></dt></dl></dd></dl></dd><dt><span class="section"><a href="#configuration-registration">4.7. Opening Registration</a></span></dt><dt><span class="section"><a href="#transform-data">4.8. Transforming Data</a></span></dt><dd><dl><dt><span class="section"><a href="#transform-data-tables">4.8.1. Transform Configuration Tables</a></span></dt><dt><span class="section"><a href="#transform-data-types">4.8.2. Transformation Types</a></span></dt></dl></dd><dt><span class="section"><a href="#data-load-filter">4.9. Data Load Filters</a></span></dt><dd><dl><dt><span class="section"><a href="#data-load-filter-config">4.9.1. Load Filter Configuration Table</a></span></dt><dt><span class="section"><a href="#data-load-filter-variables">4.9.2. Variables available to Data Load Filters</a></span></dt><dt><span class="section"><a href="#data-load-filter-examples">4.9.3. Data Load Filter Example</a></span></dt></dl></dd><dt><span class="section"><a href="#conflicts">4.10. Conflict Detection and Resolution</a></span></dt><dt><span class="section"><a href="#file-sync">4.11. File Synchronization</a></span></dt><dd><dl><dt><span class="section"><a href="#filesync-overview">4.11.1. Overview</a></span></dt><dt><span class="section"><a href="#filesync-operation">4.11.2. Operation</a></span></dt><dt><span class="section"><a href="#filesync-beanshell">4.11.3. File Sync Bean Shell Scripts</a></span></dt><dt><span class="section"><a href="#filesync-examples">4.11.4. File Sync Examples</a></span></dt><dd><dl><dt><span class="section"><a href="#filesync-example-1">4.11.4.1. Sync Text Files From Server To Client</a></span></dt><dt><span class="section"><a href="#filesync-example-2">4.11.4.2. Route changes to a specific node based on a directory
name</a></span></dt></dl></dd></dl></dd><dt><span class="section"><a href="#jobs">4.12. Jobs</a></span></dt><dd><dl><dt><span class="section"><a href="#routing-job">4.12.1. Route Job</a></span></dt><dd><dl><dt><span class="section"><a href="#data-gaps">4.12.1.1. Data Gaps</a></span></dt></dl></dd><dt><span class="section"><a href="#push-pull-job">4.12.2. Push and Pull Jobs for Database changes</a></span></dt><dt><span class="section"><a href="#file-sync-push-pull">4.12.3. File Sync Push and Pull Jobs</a></span></dt><dt><span class="section"><a href="#file-sync-tracker-job">4.12.4. File System Tracker Job</a></span></dt><dt><span class="section"><a href="#sync-triggers">4.12.5. Sync Triggers Job</a></span></dt><dt><span class="section"><a href="#purge-job">4.12.6. Purge Jobs</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#advanced-topics">5. Advanced Topics</a></span></dt><dd><dl><dt><span class="section"><a href="#advanced-sync">5.1. Advanced Synchronization</a></span></dt><dd><dl><dt><span class="section"><a href="#bi-direction-sync">5.1.1. Bi-Directional Synchronization</a></span></dt><dt><span class="section"><a href="#multi-tier">5.1.2. Multi-Tiered Synchronization</a></span></dt><dd><dl><dt><span class="section"><a href="#registration-redirect">5.1.2.1. Registration Redirect</a></span></dt></dl></dd></dl></dd><dt><span class="section"><a href="#jms-publishing">5.2. JMS Publishing</a></span></dt><dt><span class="section"><a href="#deployment-options">5.3. Deployment Options</a></span></dt><dd><dl><dt><span class="section"><a href="#deployment-options-web-archive">5.3.1. Web Archive (WAR)</a></span></dt><dt><span class="section"><a href="#deployment-options-embedded">5.3.2. Embedded</a></span></dt></dl></dd><dt><span class="section"><a href="#deployment-options-standalone">5.4. Standalone</a></span></dt><dt><span class="section"><a href="#running-service">5.5. Running SymmetricDS as a Service</a></span></dt><dd><dl><dt><span class="section"><a href="#running-service-windows">5.5.1. Running as a Windows Service</a></span></dt><dt><span class="section"><a href="#running-service-unix">5.5.2. Running as a *nix Service</a></span></dt></dl></dd><dt><span class="section"><a href="#clustering">5.6. Clustering</a></span></dt><dt><span class="section"><a href="#encrypted-passwords">5.7. Encrypted Passwords</a></span></dt><dt><span class="section"><a href="#secure-transport">5.8. Secure Transport</a></span></dt><dd><dl><dt><span class="section"><a href="#secure-transport-sym">5.8.1. Sym Launcher</a></span></dt><dt><span class="section"><a href="#secure-transport-tomcat">5.8.2. Tomcat</a></span></dt><dt><span class="section"><a href="#secure-transport-keystore">5.8.3. Keystores</a></span></dt><dt><span class="section"><a href="#secure-transport-keys">5.8.4. Generating Keys</a></span></dt></dl></dd><dt><span class="section"><a href="#basic-auth">5.9. Basic Authentication</a></span></dt><dt><span class="section"><a href="#extensions">5.10. Extension Points</a></span></dt><dd><dl><dt><span class="section"><a href="#extensions-parameter-filter">5.10.1. IParameterFilter</a></span></dt><dt><span class="section"><a href="#extensions-data-loader-filter">5.10.2. IDatabaseWriterFilter</a></span></dt><dt><span class="section"><a href="#extensions-databasewriter-errorhandler">5.10.3. IDatabaseWriterErrorHandler</a></span></dt><dt><span class="section"><a href="#extensions-dataloader-factory">5.10.4. IDataLoaderFactory</a></span></dt><dt><span class="section"><a href="#extensions-acknowledge-event-listener">5.10.5. IAcknowledgeEventListener</a></span></dt><dt><span class="section"><a href="#extensions-reload-listener">5.10.6. IReloadListener</a></span></dt><dt><span class="section"><a href="#extensions-sync-url-extension">5.10.7. ISyncUrlExtension</a></span></dt><dt><span class="section"><a href="#extensions-column-transforms">5.10.8. IColumnTransform</a></span></dt><dt><span class="section"><a href="#extensions-node-id-generator">5.10.9. INodeIdCreator</a></span></dt><dt><span class="section"><a href="#extensions-trigger-creation-listener">5.10.10. ITriggerCreationListener</a></span></dt><dt><span class="section"><a href="#extensions-batch-algorithm">5.10.11. IBatchAlgorithm</a></span></dt><dt><span class="section"><a href="#extensions-data-router">5.10.12. IDataRouter</a></span></dt><dt><span class="section"><a href="#extensions-heartbeat-listener">5.10.13. IHeartbeatListener</a></span></dt><dt><span class="section"><a href="#extensions-offline-client-listener">5.10.14. IOfflineClientListener</a></span></dt><dt><span class="section"><a href="#extensions-offline-server-listener">5.10.15. IOfflineServerListener</a></span></dt><dt><span class="section"><a href="#extensions-node-password">5.10.16. INodePasswordFilter</a></span></dt></dl></dd><dt><span class="section"><a href="#android">5.11. Synchronization to and from Android Devices </a></span></dt></dl></dd><dt><span class="chapter"><a href="#administration">6. Administration</a></span></dt><dd><dl><dt><span class="section"><a href="#solving-synchronization-issues">6.1. Solving Synchronization Issues</a></span></dt><dd><dl><dt><span class="section"><a href="#solving-synchronization-issues-analysis-outgoing">6.1.1. Analyzing the Issue - Outgoing Batches</a></span></dt><dt><span class="section"><a href="#solving-synchronization-issues-analysis-incoming">6.1.2. Analyzing the Issue - Incoming Batches</a></span></dt><dt><span class="section"><a href="#solving-synchronization-issues-resolution-outgoing">6.1.3. Resolving the Issue - Outgoing Batches</a></span></dt><dt><span class="section"><a href="#solving-synchronization-issues-resolution-incoming">6.1.4. Resolving the Issue - Incoming Batches</a></span></dt></dl></dd><dt><span class="section"><a href="#changing-triggers">6.2. Changing Triggers</a></span></dt><dt><span class="section"><a href="#grouplet">6.3. Maintaining multiple synchronization configurations through Grouplets</a></span></dt><dd><dl><dt><span class="section"><a href="#grouplet-example">6.3.1. Grouplet Example</a></span></dt></dl></dd><dt><span class="section"><a href="#resync-data">6.4. Re-synchronizing Data</a></span></dt><dt><span class="section"><a href="#changing-configuration">6.5. Changing Configuration</a></span></dt><dt><span class="section"><a href="#logging">6.6. Logging Configuration</a></span></dt><dt><span class="section"><a href="#admin-jmx">6.7. Java Management Extensions</a></span></dt><dt><span class="section"><a href="#temporary-files">6.8. Temporary Files</a></span></dt></dl></dd><dt><span class="appendix"><a href="#data-model">A. Data Model</a></span></dt><dd><dl><dt><span class="section"><a href="#table_channel">A.1. CHANNEL</a></span></dt><dt><span class="section"><a href="#table_conflict">A.2. CONFLICT</a></span></dt><dt><span class="section"><a href="#table_data">A.3. DATA</a></span></dt><dt><span class="section"><a href="#table_data_event">A.4. DATA_EVENT</a></span></dt><dt><span class="section"><a href="#table_data_gap">A.5. DATA_GAP</a></span></dt><dt><span class="section"><a href="#table_extract_request">A.6. EXTRACT_REQUEST</a></span></dt><dt><span class="section"><a href="#table_file_incoming">A.7. FILE_INCOMING</a></span></dt><dt><span class="section"><a href="#table_file_snapshot">A.8. FILE_SNAPSHOT</a></span></dt><dt><span class="section"><a href="#table_file_trigger">A.9. FILE_TRIGGER</a></span></dt><dt><span class="section"><a href="#table_file_trigger_router">A.10. FILE_TRIGGER_ROUTER</a></span></dt><dt><span class="section"><a href="#table_grouplet">A.11. GROUPLET</a></span></dt><dt><span class="section"><a href="#table_grouplet_link">A.12. GROUPLET_LINK</a></span></dt><dt><span class="section"><a href="#table_incoming_batch">A.13. INCOMING_BATCH</a></span></dt><dt><span class="section"><a href="#table_incoming_error">A.14. INCOMING_ERROR</a></span></dt><dt><span class="section"><a href="#table_load_filter">A.15. LOAD_FILTER</a></span></dt><dt><span class="section"><a href="#table_lock">A.16. LOCK</a></span></dt><dt><span class="section"><a href="#table_node">A.17. NODE</a></span></dt><dt><span class="section"><a href="#table_node_communication">A.18. NODE_COMMUNICATION</a></span></dt><dt><span class="section"><a href="#table_node_channel_ctl">A.19. NODE_CHANNEL_CTL</a></span></dt><dt><span class="section"><a href="#table_node_group">A.20. NODE_GROUP</a></span></dt><dt><span class="section"><a href="#table_node_group_channel_wnd">A.21. NODE_GROUP_CHANNEL_WND</a></span></dt><dt><span class="section"><a href="#table_node_group_link">A.22. NODE_GROUP_LINK</a></span></dt><dt><span class="section"><a href="#table_node_host">A.23. NODE_HOST</a></span></dt><dt><span class="section"><a href="#table_node_host_channel_stats">A.24. NODE_HOST_CHANNEL_STATS</a></span></dt><dt><span class="section"><a href="#table_node_host_job_stats">A.25. NODE_HOST_JOB_STATS</a></span></dt><dt><span class="section"><a href="#table_node_host_stats">A.26. NODE_HOST_STATS</a></span></dt><dt><span class="section"><a href="#table_node_identity">A.27. NODE_IDENTITY</a></span></dt><dt><span class="section"><a href="#table_node_security">A.28. NODE_SECURITY</a></span></dt><dt><span class="section"><a href="#table_outgoing_batch">A.29. OUTGOING_BATCH</a></span></dt><dt><span class="section"><a href="#table_parameter">A.30. PARAMETER</a></span></dt><dt><span class="section"><a href="#table_registration_redirect">A.31. REGISTRATION_REDIRECT</a></span></dt><dt><span class="section"><a href="#table_registration_request">A.32. REGISTRATION_REQUEST</a></span></dt><dt><span class="section"><a href="#table_router">A.33. ROUTER</a></span></dt><dt><span class="section"><a href="#table_sequence">A.34. SEQUENCE</a></span></dt><dt><span class="section"><a href="#table_table_reload_request">A.35. TABLE_RELOAD_REQUEST</a></span></dt><dt><span class="section"><a href="#table_transform_table">A.36. TRANSFORM_TABLE</a></span></dt><dt><span class="section"><a href="#table_transform_column">A.37. TRANSFORM_COLUMN</a></span></dt><dt><span class="section"><a href="#table_trigger">A.38. TRIGGER</a></span></dt><dt><span class="section"><a href="#table_trigger_hist">A.39. TRIGGER_HIST</a></span></dt><dt><span class="section"><a href="#table_trigger_router">A.40. TRIGGER_ROUTER</a></span></dt><dt><span class="section"><a href="#table_trigger_router_grouplet">A.41. TRIGGER_ROUTER_GROUPLET</a></span></dt></dl></dd><dt><span class="appendix"><a href="#parameters">B. Parameters</a></span></dt><dd><dl><dt><span class="section"><a href="#ap01-startup">B.1. Startup Parameters</a></span></dt><dt><span class="section"><a href="#ap01-runtime">B.2. Runtime Parameters</a></span></dt><dt><span class="section"><a href="#ap01-server">B.3. Server Configuration</a></span></dt></dl></dd><dt><span class="appendix"><a href="#databases">C. Database Notes</a></span></dt><dd><dl><dt><span class="section"><a href="#ap02-oracle">C.1. Oracle</a></span></dt><dt><span class="section"><a href="#ap02-mysql">C.2. MySQL</a></span></dt><dt><span class="section"><a href="#ap02-mariadb">C.3. MariaDB</a></span></dt><dt><span class="section"><a href="#ap02-postgresql">C.4. PostgreSQL</a></span></dt><dt><span class="section"><a href="#ap02-greenplum">C.5. Greenplum</a></span></dt><dt><span class="section"><a href="#ap02-sql-server">C.6. MS SQL Server</a></span></dt><dt><span class="section"><a href="#ap02-hsqldb">C.7. HSQLDB</a></span></dt><dt><span class="section"><a href="#ap02-h2">C.8. H2</a></span></dt><dt><span class="section"><a href="#ap02-derby">C.9. Apache Derby</a></span></dt><dt><span class="section"><a href="#ap02-db2">C.10. IBM DB2</a></span></dt><dt><span class="section"><a href="#ap02-firebird">C.11. Firebird</a></span></dt><dt><span class="section"><a href="#ap02-informix">C.12. Informix</a></span></dt><dt><span class="section"><a href="#ap02-interbase">C.13. Interbase</a></span></dt><dt><span class="section"><a href="#ap02-sqlite">C.14. SQLite</a></span></dt><dt><span class="section"><a href="#ap02-ase">C.15. Sybase Active Server Enterprise</a></span></dt><dt><span class="section"><a href="#ap02-sqlanywhere">C.16. Sybase SQL Anywhere</a></span></dt></dl></dd><dt><span class="appendix"><a href="#data-format">D. Data Format</a></span></dt><dt><span class="appendix"><a href="#upgrading">E. Upgrading from 2.x</a></span></dt><dt><span class="appendix"><a href="#version-numbering">F. Version Numbering</a></span></dt></dl></div>
    
    <div class="preface" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="d4e24"></a>Preface</h2></div></div></div>
        
        <p>
            SymmetricDS is an open-source, web-enabled, database independent, data synchronization software application. It uses
            web and database technologies to replicate tables between relational databases in near
            real time. The software was designed to scale for a large number of databases, work
            across low-bandwidth connections, and withstand periods of network outages.
        </p>
        <p>
            This User Guide introduces SymmetricDS and its uses for data synchronization. It is
            intended for users who want to be quickly familiarized with the software, configure it,
            and use its many features.  This version of the guide was generated on 2014-03-02 at 10:29:16.
        </p>
        
    </div>

    <div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="introduction"></a>Chapter&nbsp;1.&nbsp;Introduction</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#requirements">1.1. System Requirements</a></span></dt><dt><span class="section"><a href="#definition">1.2. Overview</a></span></dt><dd><dl><dt><span class="section"><a href="#d4e74">1.2.1. A Node is Born</a></span></dt><dt><span class="section"><a href="#d4e87">1.2.2. Capturing Changes</a></span></dt><dt><span class="section"><a href="#d4e100">1.2.3. Change Delivery</a></span></dt><dt><span class="section"><a href="#d4e105">1.2.4. Channeling Data</a></span></dt></dl></dd><dt><span class="section"><a href="#d4e111">1.3. Features</a></span></dt><dd><dl><dt><span class="section"><a href="#bi-sync">1.3.1. Two-Way Table Synchronization</a></span></dt><dt><span class="section"><a href="#data-channels">1.3.2. Data Channels</a></span></dt><dt><span class="section"><a href="#notification">1.3.3. Change Notification</a></span></dt><dt><span class="section"><a href="#transports">1.3.4. HTTP(S) Transport</a></span></dt><dt><span class="section"><a href="#plugins">1.3.5. Data Filtering and Rerouting</a></span></dt><dt><span class="section"><a href="#transactions">1.3.6. Transaction Awareness</a></span></dt><dt><span class="section"><a href="#jmx">1.3.7. Remote Management</a></span></dt><dt><span class="section"><a href="#feature-filesync">1.3.8. File Synchronization</a></span></dt></dl></dd><dt><span class="section"><a href="#background">1.4. Origins</a></span></dt><dt><span class="section"><a href="#d4e176">1.5. Why Database Triggers?</a></span></dt><dt><span class="section"><a href="#d4e192">1.6. Support</a></span></dt><dt><span class="section"><a href="#d4e197">1.7. What's New in SymmetricDS 3</a></span></dt></dl></div>
  

  <p>This User Guide will introduce both basic and advanced concepts in the
  configuration of SymmetricDS. By the end of this chapter, you will have a
  better understanding of SymmetricDS' capabilities, and many of its basic
  concepts.</p>

  <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="requirements"></a>1.1.&nbsp;System Requirements</h2></div></div></div>
    

    <p>SymmetricDS is written in Java 5 and requires a Java SE Runtime
    Environment (JRE) or Java SE Development Kit (JDK) version 5.0 or
    above.</p>

    <p>Any database with trigger technology and a JDBC driver has the
    potential to run SymmetricDS. The database is abstracted through a
    <span class="emphasis"><em>Database Dialect</em></span> in order to support specific
    features of each database. The following Database Dialects have been
    included with this release:</p>

    <div class="itemizedlist"><ul type="disc"><li>
        <p>MySQL version 5.0.2 and above</p>
      </li><li>
        <p>MariaDB version 5.1 and above</p>
      </li><li>
        <p>Oracle version 10g and above</p>
      </li><li>
        <p>PostgreSQL version 8.2.5 and above</p>
      </li><li>
        <p>Sql Server 2005 and above</p>
      </li><li>
        <p>Sql Server Azure</p>
      </li><li>
        <p>HSQLDB 2.x</p>
      </li><li>
        <p>H2 1.x</p>
      </li><li>
        <p>Apache Derby 10.3.2.1 and above</p>
      </li><li>
        <p>IBM DB2 9.5</p>
      </li><li>
        <p>Firebird 2.0 and above</p>
      </li><li>
        <p>Interbase 2009 and above</p>
      </li><li>
        <p>Greenplum 8.2.15 and above</p>
      </li><li>
        <p>SQLite 3 and above</p>
      </li><li>
        <p>Sybase Adaptive Server Enterprise 12.5 and above</p>
      </li><li>
        <p>Sybase SQL Anywhere 9 and above</p>
      </li></ul></div>

    <p>See <a href="#databases" title="Appendix&nbsp;C.&nbsp;Database Notes">Appendix&nbsp;C, <i xmlns:xlink="http://www.w3.org/1999/xlink">Database Notes</i></a>, for compatibility notes and other
    details for your specific database.</p>
  </div>

  <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="definition"></a>1.2.&nbsp;Overview</h2></div></div></div>
    

    <p>The following is an overview of how SymmetricDS works.</p>

    

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="d4e74"></a>1.2.1.&nbsp;A Node is Born</h3></div></div></div>
      

      <p>SymmetricDS is a Java-based application that hosts a
      synchronization engine which acts as an agent for data synchronization
      between a single database instance and other synchronization engines in
      a network.</p>

      <p>The SymmetricDS engine is also referred to as a
      <span class="emphasis"><em>node</em></span>. SymmetricDS is designed to be able to scale
      out to many thousands of nodes. The database connection is configured by
      providing a database connection string, database user, and database
      password in a properties file. SymmetricDS can synchronize any table
      that is accessible by the database connection, given that the database
      user has been assigned the appropriate database permissions.</p>

      <div class="figure"><a name="figure-overview-1"></a><div class="figure-contents">
        

        <div class="mediaobject"><img src="images/overview-1.gif" alt="Simple Configuration"></div>
      </div><p class="title"><b>Figure&nbsp;1.1.&nbsp;Simple Configuration</b></p></div><br class="figure-break">

      <p>A SymmetricDS node is assigned an external id and a node group id.
      The external id is a meaningful, user-assigned identifier that is used
      by SymmetricDS to understand which data is destined for a given node.
      The node group id is used to identify groupings or tiers of nodes. It
      defines where the node fits into the overall node network. For example,
      one node group might be named &#8220;corporate&#8221; and represent an enterprise or
      corporate database. Another node group might be named &#8220;local_office&#8221; and
      represent databases located in different offices across a country. The
      external id for a &#8220;local_office&#8221; could be an office number or some other
      identifying alphanumeric string. A node is uniquely identified in a
      network by a node id that is automatically generated from the external
      id. If local office number 1 had two office databases and two
      SymmetricDS nodes, they would probably have an external id of &#8220;1&#8221; and
      node ids of &#8220;1-1&#8221; and &#8220;1-2.&#8221;</p>

      <p>SymmetricDS can be deployed in a number of ways. The most common
      option is to deploy it as a stand alone process running as a service on
      your chosen server platform. When deployed in this manner SymmetricDS
      can act as either a client, a multi-tenant server or both depending on
      where the SymmetricDS database fits into the overall network of
      databases. Although it can run on the same server as its database, it is
      not required to do so. SymmetricDS can also be deployed as a web
      application in an application server such as Apache Tomcat, JBoss
      Application Server, IBM WebSphere, or others.</p>

      <p>SymmetricDS was designed to be a simple, approachable,
      non-threatening tool for technology personnel. It can be thought of and
      dealt with as a web application, only instead of a browser as the
      client, other SymmetricDS engines are the clients. It has all the
      characteristics of a web application and can be tuned using the same
      principles that would be used to tune user facing web
      applications.</p>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="d4e87"></a>1.2.2.&nbsp;Capturing Changes</h3></div></div></div>
      

      <p>Changes are captured at a SymmetricDS enabled database by database
      triggers that are installed automatically by SymmetricDS based on
      configuration settings that you specify. The database triggers record
      data changes in the <a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
      table. The database triggers are designed to be as noninvasive and as
      lightweight as possible. After SymmetricDS triggers are installed,
      changes are captured for any Data Manipulation Language (DML) statements
      performed by external applications. Note that no additional libraries or
      changes are needed by the applications that use the database and
      SymmetricDS does not have to be online for data to be captured.</p>

      <p>Database tables that need to be replicated are configured in a
      series of SymmetricDS configuration tables. The configuration for the
      entire network of nodes is typically managed at a central node in the
      network, known as the registration server node. The registration server
      node is almost always the same node as the root node in a tree topology.
      When configuring &#8220;leaf&#8221; nodes, one of the start-up parameters is the URL
      of the registration server node. If the &#8220;leaf&#8221; node has not yet
      registered, it contacts the registration server and requests to join the
      network. Upon acceptance, the node downloads its configuration. After a
      node is registered, SymmetricDS can also provide an initial load of data
      before synchronization starts.</p>

      <p>SymmetricDS will install or update its database triggers at
      start-up time and on a regular basis when a scheduled "sync triggers"
      job runs (by default, each night at midnight). The "sync triggers" job
      detects changes to your database structure or trigger configuration when
      deciding whether a trigger needs to be rebuilt. Optionally, the "sync
      triggers" job can be turned off and the database triggers DDL script can
      be generated and run by a DBA.</p>

      <p>After changed data is inserted by the database trigger into the
      <a href="#table_data" title="A.3.&nbsp;DATA">DATA</a> table, it is batched and
      assigned to a node by the "router" job. Routing data refers to choosing
      the nodes in the SymmetricDS network to which the data should be sent.
      By default, data is routed to other nodes based on the node group.
      Optionally, characteristics of the data or of the target nodes can also
      be used for routing. A batch of data is a group of data changes that are
      transported and loaded together at the target node in a single database
      transaction. Batches are recorded in the <a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a> . Batches are node
      specific. <a href="#table_data" title="A.3.&nbsp;DATA">DATA</a> and <a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a> are linked by <a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a> . The delivery status of
      a batch is maintained in <a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a> . After the data has been delivered to a remote node
      the batch status is changed to &#8216;OK.&#8217;</p>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="d4e100"></a>1.2.3.&nbsp;Change Delivery</h3></div></div></div>
      

      <p>Data is delivered to remote nodes over HTTP or HTTPS. It can be
      delivered in one of two ways depending on the type of transport link
      that is configured between node groups. A node group can be configured
      to push changes to other nodes in a group or pull changes from other
      nodes in a group. Pushing is initiated from the "push" job at the source
      node. If there are batches that are waiting to be transported, the
      pushing node will reserve a connection to each target node using an HTTP
      HEAD request. If the reservation request is accepted, then the source
      node will fully extract the data for the batch. Data is extracted to a
      memory buffer in CSV format until a configurable threshold is reached.
      If the threshold is reached, the data is flushed to a file and the
      extraction of data continues to that file. After the batch has been
      extracted, it is transported using an HTTP PUT to the target node. The
      next batch is then extracted and sent. This is repeated until the
      maximum number of batches have been sent for each channel or there are
      no more batches available to send. After all the batches have been sent
      for one push, the target returns a list of the batch statuses.</p>

      <p>Pull requests are initiated by the "pull" job from at the target
      node. A pull request uses an HTTP GET. The same extraction process that
      happens for a "push" also happens during a "pull."</p>

      <p>After data has been extracted and transported, the data is loaded
      at the target node. Similar to the extract process, while data is being
      received the data loader will cache the CSV in a memory buffer until a
      threshold is reached. If the threshold is reached the data is flushed to
      a file and the receiving of data continues. After all of the data in a
      batch is available locally, a database connection is retrieved from the
      connection pool and the events that had occurred at the source database
      are played back against the target database.</p>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="d4e105"></a>1.2.4.&nbsp;Channeling Data</h3></div></div></div>
      

      <p>Data is always delivered to a remote node in the order it was
      recorded for a specific channel. A channel is a user defined grouping of
      tables that are dependent on each other. Data that is captured for
      tables belonging to a channel is always synchronized together. Each
      trigger must be assigned a channel id as part of the trigger definition
      process. The channel id is recorded on SYM_DATA and SYM_OUTGOING_BATCH.
      If a batch fails to load, then no more data is sent for that channel
      until the failure has been addressed. Data on other channels will
      continue to be synchronized, however.</p>

      <p>If a remote node is offline, the data remains recorded at the
      source database until the node comes back online. Optionally, a timeout
      can be set where a node is removed from the network. Change data is
      purged from the data capture tables by SymmetricDS after it has been
      sent and a configurable purge retention period has been reached. Unsent
      change data for a disabled node is also purged.</p>

      <p>The default behavior of SymmetricDS in the case of data integrity
      errors is to attempt to repair the data. If an insert statement is run
      and there is already a row that exists, SymmetricDS will fall back and
      try to update the existing row. Likewise, if an update that was
      successful on a source node is run and no rows are found to update on
      the destination, then SymmetricDS will fall back to an insert on the
      destination. If a delete is run and no rows were deleted, the condition
      is simply logged. This behavior can be modified by tweaking the settings
      for conflict detection and resolution.</p>

      <p>SymmetricDS was designed to use standard web technologies so it
      can be scaled to many clients across different types of databases. It
      can synchronize data to and from as many client nodes as the deployed
      database and web infrastructure will support. When a two-tier database
      and web infrastructure is maxed out, a SymmetricDS network can be
      designed to use N-tiers to allow for even greater scalability. At this
      point we have covered what SymmetricDS is and how it does its job of
      replicating data to many databases using standard, well understood
      technologies.</p>
    </div>
  </div>

  <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d4e111"></a>1.3.&nbsp;Features</h2></div></div></div>
    

    <p>At a high level, SymmetricDS comes with a number of features that
    you are likely to need or want when doing data synchronization. A majority
    of these features were created as a direct result of real-world use of
    SymmetricDS in production settings.</p>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="bi-sync"></a>1.3.1.&nbsp;Two-Way Table Synchronization</h3></div></div></div>
      

      <p>In practice, much of the data in a typical synchronization
      requires synchronization in just one direction. For example, a retail
      store sends its sales transactions to a central office, and the central
      office sends its stock items and pricing to the store. Other data may
      synchronize in both directions. For example, the retail store sends the
      central office an inventory document, and the central office updates the
      document status, which is then sent back to the store. SymmetricDS
      supports bi-directional or two-way table synchronization and avoids
      getting into update loops by only recording data changes outside of
      synchronization.</p>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="data-channels"></a>1.3.2.&nbsp;Data Channels</h3></div></div></div>


      



      <p>SymmetricDS supports the concept of <span class="emphasis"><em>channels</em></span>
      of data. Data synchronization is defined at the table (or table subset)
      level, and each managed table can be assigned to a
      <span class="emphasis"><em>channel</em></span> that helps control the flow of data. A
      channel is a category of data that can be enabled, prioritized and
      synchronized independently of other channels. For example, in a retail
      environment, users may be waiting for inventory documents to update
      while a promotional sale event updates a large number of items. If
      processed in order, the item updates would delay the inventory updates
      even though the data is unrelated. By assigning changes to the item
      tables to an <span class="emphasis"><em>item</em></span> channel and inventory tables'
      changes to an <span class="emphasis"><em>inventory</em></span> channel, the changes are
      processed independently so inventory can get through despite the large
      amount of item data.</p>

       Channels are discussed in more detail in

      <a href="#choosing-channels" title="3.5.&nbsp;Choosing Data Channels">Section&nbsp;3.5, &#8220;Choosing Data Channels&#8221;</a>

       .
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="notification"></a>1.3.3.&nbsp;Change Notification</h3></div></div></div>
      

      <p>After a change to the database is recorded, the SymmetricDS nodes
      interested in the change are notified. Change notification is configured
      to perform either a <span class="emphasis"><em>push</em></span> (trickle-back) or a
      <span class="emphasis"><em>pull</em></span> (trickle-poll) of data. When several nodes
      target their changes to a central node, it is efficient to push the
      changes instead of waiting for the central node to pull from each source
      node. If the network configuration protects a node with a firewall, a
      pull configuration could allow the node to receive data changes that
      might otherwise be blocked using push. The frequency of the change
      notification is configurable and defaults to once per minute.</p>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="transports"></a>1.3.4.&nbsp;HTTP(S) Transport</h3></div></div></div>
      

      <p>By default, SymmetricDS uses web-based HTTP or HTTPS in a style
      called Representation State Transfer (REST). It is lightweight and easy
      to manage. A series of filters are also provided to enforce
      authentication and to restrict the number of simultaneous
      synchronization streams. The <code class="literal">ITransportManager</code>
      interface allows other transports to be implemented.</p>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="plugins"></a>1.3.5.&nbsp;Data Filtering and Rerouting</h3></div></div></div>
      

      <p>Using SymmetricDS, data can be filtered as it is recorded,
      extracted, and loaded. </p><div class="itemizedlist"><ul type="disc"><li>
            <p>Data routing is accomplished by assigning a router type to a
            <a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a> configuration.
            Routers are responsible for identifying what target nodes captured
            changes should be delivered to. Custom routers are possible by
            providing a class implementing <code class="literal">IDataRouter</code>
            .</p>
          </li><li>
            <p>In addition to synchronization, SymmetricDS is also capable
            of performing fairly complex transformations (see <a href="#transform-data" title="4.8.&nbsp;Transforming Data">Section&nbsp;4.8</a> ) of data as
            the synchronization data is loaded into a target database. The
            transformations can be used to merge source data, make multiple
            copies of source data across multiple target tables, set defaults
            in the target tables, etc. The types of transformation can also be
            extended to create even more custom transformations.</p>
          </li><li>
            <p>As data changes are loaded in the target database, data can
            be filtered, either by a simple bean shell load filter (see
            <a href="#data-load-filter" title="4.9.&nbsp;Data Load Filters">Section&nbsp;4.9</a>
            data-load-filter) or by a class implementing <a href="#extensions-data-loader-filter" title="5.10.2.&nbsp;IDatabaseWriterFilter">IDatabaseWriterFilter</a>. You
            can change the data in a column, route it somewhere else, trigger
            initial loads, or many other possibilities. One possible use might
            be to route credit card data to a secure database and blank it out
            as it loads into a centralized sales database. The filter can also
            prevent data from reaching the database altogether, effectively
            replacing the default data loading process.</p>
          </li></ul></div>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="transactions"></a>1.3.6.&nbsp;Transaction Awareness</h3></div></div></div>
      

      <p>Many databases provide a unique transaction identifier associated
      with the rows that are committed together as a transaction. SymmetricDS
      stores the transaction identifier, along with the data that changed, so
      it can play back the transaction exactly as it occurred originally. This
      means the target database maintains the same transactional integrity as
      its source. Support for transaction identification for supported
      databases is documented in the appendix of this guide.</p>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="jmx"></a>1.3.7.&nbsp;Remote Management</h3></div></div></div>
      

      <p>Administration functions are exposed through Java Management
      Extensions (JMX) and can be accessed from the Java JConsole or through
      an application server. Functions include opening registration, reloading
      data, purging old data, and viewing batches. A number of configuration
      and runtime properties are available to be viewed as well.</p>

      <p>SymmetricDS also provides functionality to send SQL events through
      the same synchronization mechanism that is used to send data. The data
      payload can be any SQL statement. The event is processed and
      acknowledged just like any other event type.</p>
    </div>
    
    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="feature-filesync"></a>1.3.8.&nbsp;File Synchronization</h3></div></div></div>
      
      <p>Quite a few users of SymmetricDS have found that they have a need to not only synchronize database tables to remote locations, but they also have a set of files that should be synchronized.  As of version 3.5 SymmetricDS now support file synchronization.</p>
      <p>Please see <a href="#file-sync" title="4.11.&nbsp;File Synchronization">Section&nbsp;4.11, &#8220;File Synchronization&#8221;</a>
    for more information.</p>
    </div>    
  </div>

  <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="background"></a>1.4.&nbsp;Origins</h2></div></div></div>
    

    <p>The idea of SymmetricDS was born from a real-world need. Several of
    the original developers were, several years ago, implementing a commercial
    Point of Sale (POS) system for a large retailer. The development team came
    to the conclusion that the software available for trickling back
    transactions to corporate headquarters (frequently known as the 'central
    office' or 'general office') did not meet the project needs. The list of
    project requirements made finding the ideal solution difficult:</p>

    <div class="itemizedlist"><ul type="disc"><li>
        <p>Sending and receiving data with up to 2000 stores during peak
        holiday loads.</p>
      </li><li>
        <p>Supporting one database platform at the store and a different
        one at the central office.</p>
      </li><li>
        <p>Synchronizing some data in one direction, and other data in both
        directions.</p>
      </li><li>
        <p>Filtering out sensitive data and re-routing it to a protected
        database.</p>
      </li><li>
        <p>Preparing the store database with an initial load of data from
        the central office.</p>
      </li></ul></div>

    <p>The team ultimately created a custom solution that met the
    requirements and led to a successful project. From this work came the
    knowledge and experience that SymmetricDS benefits from today.</p>
  </div>

  <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d4e176"></a>1.5.&nbsp;Why Database Triggers?</h2></div></div></div>
    

    <p>There are several industry recognized techniques to capture changing
    data for replication, synchronization and integration in a relational
    database.</p>

    <div class="itemizedlist"><ul type="disc"><li>
        <p><span class="emphasis"><em>Lazy data capture</em></span> queries changed data from
        a source system using some SQL condition (like a time stamp
        column).</p>
      </li><li>
        <p><span class="emphasis"><em>Trigger-based data capture</em></span> installs
        database triggers to capture changes.</p>
      </li><li>
        <p><span class="emphasis"><em>Log-based data capture</em></span> reads data changes
        from proprietary database recovery logs.</p>
      </li></ul></div>

    <p>All three of these techniques have advantages and disadvantages, and
    all three are on the road map for SymmetricDS. At present time,
    SymmetricDS supports trigger-based data capture and basic lazy data
    capture. These two techniques were implemented first for a variety of
    reasons, not the least of which is that the majority of use cases that
    SymmetricDS targets can be solved using trigger-based and conditional
    replication in a way that allows for more database platforms to be
    supported using industry standard technologies. This fact allowed our
    developers' valuable time and energy to be invested in designing a product
    that is easy to install, configure and manage versus spending time reverse
    engineering proprietary and not well documented database log files.</p>

    <p>Trigger-based data capture does introduce a measurable amount of
    overhead on database operations. The amount of overhead can vary greatly
    depending on the processing power and configuration of the database
    platform, and the usage of the database by applications. With nonstop
    advances in hardware and database technology, trigger-based data capture
    has become feasible for use cases that involve high data throughput or
    require scaling out.</p>

    <p>Trigger-based data capture is easier to implement and support than
    log-based solutions. It uses well known database concepts and is very
    accessible to software and database developers and database
    administrators. It can usually be installed, configured, and managed by
    application development teams or database administrators and does not
    require deployment on the database server itself.</p>
  </div>

  <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d4e192"></a>1.6.&nbsp;Support</h2></div></div></div>
    

    <p>SymmetricDS is backed by JumpMind, Inc.</p>

    <p>SymmetricDS is, and always will be, open source, which means free
    community support is available online, through the forums and the issue
    tracker. In a production environment, we have found that clients demand
    fast, more experienced help from the original architects and engineers &#8212;
    people who have the knowledge and experience to design, tune,
    troubleshoot, and shape future versions of the product.</p>

    <p>To meet this demand, JumpMind provides Support Subscriptions
    designed to provide your organization with expert, dependable support from
    development to mission critical production support.</p>
  </div>

  <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="d4e197"></a>1.7.&nbsp;What's New in SymmetricDS 3</h2></div></div></div>
    

    <p>SymmetricDS 3 builds upon the existing SymmetricDS 2.x software base
    and incorporates a number of architectural changes and performance
    improvements. If you are brand new to SymmetricDS, you can safely skip
    this section. If you have used SymmetricDS 2.x in the past, this section
    summarizes the key differences you will encounter when moving to
    SymmetricDS 3.</p>

    <p>One optimization that effects both routing and data extraction is a
    change to the routing process to reuse batches across nodes if all of the
    data in the batches is going to be the same. SymmetricDS will
    automatically reuse batches if the default router is being used and there
    are NO inbound routers that have sync_on_incoming_batch turned on. If the
    same data is being sent to all nodes then a great deal of processing,
    during both routing and extraction, can be avoided. This is especially
    useful when data is being delivered to thousands of nodes. As a result of
    this change, the primary key of <a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a> has changed. This means that during an upgrade the
    table will be rebuilt.</p>

    <p>Another optimization that effects data transport is the change to
    load batches as soon as they have been delivered to a target node. In 2.x
    all batches for a synchronization run were delivered, and then data was
    loaded. When errors occurred early on and there were several big batches
    or hundreds of batches to deliver, this was inefficient because all the
    batches were transported before the loading started.</p>

    <p>Yet another optimization allows SymmetricDS to scale better when it
    is initiating communication with nodes. The pulling and pushing of data
    now happens from a configurable, but fixed size thread pool so that
    multiple nodes can be pulled and pushed to concurrently. This means that
    now, a centralized node can reach out to many child nodes in an efficient
    manner where in the past, the child nodes were relied upon to initiate
    communication.</p>

    <p>The 2.x series allowed multiple nodes to be hosted in one standalone
    SymmetricDS instance. This feature (called multiServerMode) was off by
    default. In SymmetricDS 3 this feature is now the preferred mode of
    operation. It formalizes where properties file are configured and allows
    multiple nodes to be hosted on one JVM which saves on system
    resources.</p>

    <p>SymmetricDS 3 introduces a long anticipated feature: Conflict
    Detection and Resolution. Please see <a href="#defining-conflicts" title="3.8.&nbsp;Planning Conflict Detection and Resolution">Section&nbsp;3.8, &#8220;Planning Conflict Detection and Resolution&#8221;</a>
    for more information.</p>

    <p>Transformations are now friendlier. They allow columns to be
    implied. This means that when configuring transformations, not all of the
    columns have to be specified which makes transformations much more
    maintainable.</p>

    <p>An architectural change to the data loader subsystem allows the data
    loader to now be pluggable by channel. This will allow more efficient data
    loaders to be built if necessary. It will also make it straight forward to
    load data into non-relational data stores.</p>

    <p>Several properties and extension points have been deprecated or
    renamed. Please see <a href="#upgrading" title="Appendix&nbsp;E.&nbsp;Upgrading from 2.x">Appendix&nbsp;E, <i xmlns:xlink="http://www.w3.org/1999/xlink">Upgrading from 2.x</i></a> for a list of deprecated
    features.</p>
  </div>
</div>
    <div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="tutorial"></a>Chapter&nbsp;2.&nbsp;Quick Start Tutorial</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#tutorial-install">2.1. Installing SymmetricDS</a></span></dt><dt><span class="section"><a href="#ch02-create-database">2.2. Creating and Populating Your Databases</a></span></dt><dt><span class="section"><a href="#ch02-start-server">2.3. Starting SymmetricDS</a></span></dt><dt><span class="section"><a href="#ch02-register-node">2.4. Registering a Node</a></span></dt><dt><span class="section"><a href="#ch02-initial-load">2.5. Sending an Initial Load</a></span></dt><dt><span class="section"><a href="#ch02-pull">2.6. Pulling Data</a></span></dt><dt><span class="section"><a href="#ch02-push">2.7. Pushing Data</a></span></dt><dt><span class="section"><a href="#ch02-verify-outgoing">2.8. Verifying Outgoing Batches</a></span></dt><dt><span class="section"><a href="#ch02-verify-incoming">2.9. Verifying Incoming Batches</a></span></dt><dt><span class="section"><a href="#multi-homing">2.10. Multi-Homing</a></span></dt></dl></div>
    
    <p>Now that an overview of SymmetricDS has been presented, a quick working example of SymmetricDS is in order.
        This section contains a hands-on tutorial that demonstrates how to synchronize two databases with a similar schema between two nodes of SymmetricDS. This example models a retail business that has a
        central office database (which we'll call the "root" or "corp" node) and multiple retail store databases (which we'll call the "client" or "store" nodes).
        For the tutorial, we will have only one "client" or store node, as shown in <a href="#figure-tutorial" title="Figure&nbsp;2.1.&nbsp;Simplified Two-Tier Retail Store Tutorial Example">Figure&nbsp;2.1</a>, although by the end of the tutorial
        you could extend the example and configure a second store, if desired.
        </p>

        <p>
                </p><div class="figure"><a name="figure-tutorial"></a><div class="figure-contents">
                    
                    <div class="mediaobject"><img src="images/tutorial-arch.gif" alt="Simplified Two-Tier Retail Store Tutorial Example"></div>
                </div><p class="title"><b>Figure&nbsp;2.1.&nbsp;Simplified Two-Tier Retail Store Tutorial Example</b></p></div><p><br class="figure-break">
            </p>
         <p>
         For this tutorial, we will install two separate copies of SymmetricDS to represent the two different servers.  One will represent the store server and one will represent the
         corp server.  Each installed copy of SymmetricDS will be responsible for one database, and thus each copy acts as a single "node" in SymmetricDS terminology.
         This is the most common configuration of SymmetricDS - one installed copy of the software is responsible for one single database and represents one node.
         (Incidentally, there is also an option to configure a single installed copy of SymmetricDS to be responsible for both nodes.  This is called "multi-homing" and will be discussed  at the very
         end of the tutorial.)
         Since you are most likely going to run both SymmetricDS copies on a single machine, we will run the two copies of SymmetricDS on two separate ports.
         We will use port 8080 for the corp server and 9090 for the store server, as shown in  <a href="#figure-tutorial-separate" title="Figure&nbsp;2.2.&nbsp;Two SymmetricDS applications - one for corp, one for store">Figure&nbsp;2.2</a>.
         </p>
            <p>
                </p><div class="figure"><a name="figure-tutorial-separate"></a><div class="figure-contents">
                    
                    <div class="mediaobject"><img src="images/multi-home-separate.gif" alt="Two SymmetricDS applications - one for corp, one for store"></div>
                </div><p class="title"><b>Figure&nbsp;2.2.&nbsp;Two SymmetricDS applications - one for corp, one for store</b></p></div><p><br class="figure-break">
            </p>
        <p>
        Functionally, the corp SymmetricDS application will be responsible for capturing item data changes for the client, such as
        item number, description, and prices by store. The client SymmetricDS application (our store, specifically our first store, store # 001) captures sale transaction data
        changes for the root, such as time of sale and items sold.  The pricing information is sent
        only to the specific store for which the price is relevant, thereby minimizing the amount of pricing data sent to each store.
        In other words, item pricing specific to store 001 will only be sent to the database
        for store 001 and not to store 002's database, for example.
        </p>
        <p>
        The sample configuration has the client always initiating communication with the root node, which is a fairly common
        configuration.  In this configuration, the client
        will attach to the root on a periodic basis to pull data from the server, and the client will
        also push captured changes to the root when changes are available.</p>
    <p>Enough overview. Let's get started.  We will next walk through:
      </p><div class="procedure"><ol type="1"><li><p>Installing and configuring the two SymmetricDS applications,</p></li><li><p>Creating SymmetricDS configuration and sample tables as needed for the root and client, used to hold corp data and store data, respectively,</p></li><li><p>Creating sample retail data in the corp database,</p></li><li><p>Starting the SymmetricDS servers and registering the store with the corp node,</p></li><li><p>Sending an initial load of data to the store node,</p></li><li><p>Causing a data push and data pull operation, and</p></li><li><p>Verifying information about the batches that were sent and received.</p></li></ol></div><p>
       </p>

     <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="tutorial-install"></a>2.1.&nbsp;Installing SymmetricDS</h2></div></div></div>
        
        <p>
        First, we will install two copies of the SymmetricDS software and configure it with your database
        connection information:
        </p>
        <div class="procedure"><ol type="1"><li>
                <p>
                    Download the
                    <a xmlns:xlink="http://www.w3.org/1999/xlink" href="https://sourceforge.net/projects/symmetricds/files/" target="_top">symmetric-ds-3.x.x-server.zip</a>
                    file from
                    <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://www.symmetricds.org/" target="_top">http://www.symmetricds.org/</a>
                </p>
            </li><li>
                <p>
                    Create two directories to represent your two "machines". One will hold the corp installation of SymmetricDS and one
                    to hold the store installation.
                    For example, you could name the directories <code class="literal">sym-corp</code> and <code class="literal">sym-store001</code>, and we'll assume you used these names
                    below (but feel free to update the steps below with your directory names as needed).
                    Unzip the above zip file into both directories.
                    This will create a <code class="filename">symmetric-ds-3.x.x</code>
                    directory, which corresponds to the version you downloaded.
                </p>
            </li><li>
                <p>Properties files are use to store the minimal configuration information needed to start SymmetricDS.  Copy the corp sample properties file to the corp engines directory, and the store one to the store engines directory.  If you
                used the suggested directory names above, you would do the following copies:
                </p>
                            <p>
                                <code class="filename">samples/corp-000.properties</code> to <code class="filename">sym-corp/symmetric-ds-3.x.x/engines/</code>
                            </p>
                            <p>and</p>
                            <p>
                                <code class="filename">samples/store-001.properties</code> to <code class="filename">sym-store001/symmetric-ds-3.x.x/engines/</code>
                            </p>
                </li><li>
               <p>
               Browse both properties files and explore the various settings.  For exampl, notice that the root node is given a group id of corp, and that the store node
                is given a group id of store.
               Notice also that the root node is given an external id of 000, and the store node is given an external id of 001.</p>
                <p>
                    Set the following properties in
                    <span class="emphasis"><em>both</em></span>
                    properties files now present in the engines directories to specify how to connect to your particular database (the values below are just examples):
                </p>
                <pre class="programlisting"># The class name for the JDBC Driver
db.driver=com.mysql.jdbc.Driver

# The JDBC URL used to connect to the database
db.url=jdbc:mysql://localhost/sample

# The user to login as who can create and update tables
db.user=symmetric

# The password for the user to login as
db.password=secret</pre>
            </li><li>
                <p>
                    Next, set the following property in the
                    <code class="filename">store-001.properties</code>
                    file to specify where the root node can be contacted:
                </p>
                <pre class="programlisting"># The HTTP URL of the root node to contact for registration
registration.url=http://localhost:8080/sync/corp-000</pre>
                <div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Tip</h3>
                    <p>
                       Note that the  URL for an engine is in the following general format:
                       </p><pre class="programlisting">http://{hostname}:{port}/sync/{engine.name}</pre><p>
                       where the engine.name portion of the URL comes from a node's properties file.
                    </p>
                </div>

            </li></ol></div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ch02-create-database"></a>2.2.&nbsp;Creating and Populating Your Databases</h2></div></div></div>
        
        <div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
            <p> You must first create the databases for your root and client nodes using the administration tools provided by
                your database vendor. Make sure the name of the databases you create match the settings in the properties files you modified in the previous step.
            </p>
            <p>
                See
                 <a href="#databases" title="Appendix&nbsp;C.&nbsp;Database Notes">Appendix&nbsp;C, <i xmlns:xlink="http://www.w3.org/1999/xlink">Database Notes</i></a> for compatibility with your specific database.
            </p>
        </div>
        <p>
            First, create the sample tables in the
            <span class="emphasis"><em>root</em></span>
            node database, load the sample data, and load the sample configuration, by doing the following:
        </p>
        <div class="procedure"><ol type="1"><li>
                <p>
                    Open a command prompt and navigate to the
                    <code class="filename">samples</code>
                    subdirectory of your <span class="emphasis"><em>corp</em></span> SymmetricDS installation (for example, navigate to <code class="literal">sym-corp/symmetric-ds-3.x.x/samples</code>)
                </p>
            </li><li>
                <p>Create the sample tables for items, prices, and sales, in the root database by executing the following command:</p>
                <p>
                    <span><strong class="command">../bin/dbimport --engine corp-000 --format XML create_sample.xml</strong></span>
                </p>
                <p> Note that the warning messages from the command are safe to ignore.  </p>
                <p>Another quick comment about properties files.  At startup, SymmetricDS looks for one or more properties files in the <code class="literal">engines</code> directory. Since we have
                specified a <code class="literal">--engine</code> parameter on the command line, it will look only for the specific file listed, namely <code class="literal">corp-000.properties</code>.
                Technically, the <code class="literal">--engine corp-000</code> part is
                optional in our particular tutorial example.  Since there's only one properties file in the engines directory, SymmetricDS would just default
                to using that one file, after all.  By including it, though, it will reduce errors while running the tutorial, because if you run
                the command from the wrong SymmetricDS installation, SymmetricDS will complain about the missing engines property file you specified.
                </p>
            </li><li>
                <p>Next, create the SymmetricDS-specific tables in the corp node database. These tables will contain the configuration for
                    synchronization. The following command uses the auto-creation feature to create all the necessary SymmetricDS
                    system tables.</p>
                <p>
                    <span><strong class="command">../bin/symadmin --engine corp-000 create-sym-tables</strong></span>
                </p>
            </li><li>
                <p>Finally, load the sample item and transaction data and SymmetricDS configuration into the root node database by executing:</p>
                <p>
                    <span><strong class="command">../bin/dbimport --engine corp-000 insert_sample.sql</strong></span>
                </p>
                     <div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
                        Please note that for MySQL, you will need to use the file <code class="literal">insert_sample_mysql.sql</code> in the above command.  MySql uses back ticks (i.e., ` ) instead
                        of double quotes (") for case-sensitive table and column names.  The MySQL version of the file has the necessary change.
                    </div>
            </li></ol></div>
        <p>
            We have now created the corp database tables and populated them with our SymmetricDS configuration and sample data.  Next, we will create the sample tables in the
            <span class="emphasis"><em>store</em></span>
            node database to prepare it for receiving data.
        </p>
        <div class="procedure"><ol type="1"><li>
                <p>
                    Open a command prompt and navigate to the
                    <code class="filename">samples</code>
                    subdirectory of your <span class="emphasis"><em>store #001</em></span> SymmetricDS installation (for example, navigate to <code class="literal">sym-store001/symmetric-ds-3.x.x/samples</code>)
                </p>
            </li><li>
                <p>Create the empty, sample tables in the client database by executing:</p>
                <p>
                    <span><strong class="command"> ../bin/dbimport --engine store-001 --format XML create_sample.xml</strong></span>
                </p>
                <p>Note that the warning messages from the command are safe to ignore.  Also,
                feel free to review the <code class="literal">create_sample.xml</code> file to see what it contains.</p>
            </li></ol></div>
        <p>
            Please verify
            <span class="emphasis"><em>both</em></span>
            databases by logging in and listing the tables.
        </p>
        <div class="procedure"><ol type="1"><li>
                <p> Find the item tables that sync from root to client (that is, from corp to store): <code class="literal">item</code> and <code class="literal">item_selling_price</code>.</p>
            </li><li>
                <p> Find the sales tables that sync from store to corp: <code class="literal">sale_transaction</code> and <code class="literal">sale_return_line_item</code>.</p>
            </li><li>
                <p> Find the SymmetricDS system tables, which have a prefix of "sym_", such as <code class="literal">sym_channel</code>,
                <code class="literal">sym_trigger</code>, <code class="literal">sym_router</code>, and <code class="literal">sym_trigger_router</code>.</p>
            </li><li>
                <p>Validate the corp item tables have sample data.</p>
            </li></ol></div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ch02-start-server"></a>2.3.&nbsp;Starting SymmetricDS</h2></div></div></div>
        
        <p> Database setup and configuration for the tutorial is now complete.  Time to put SymmetricDS into action.
        We will now start both SymmetricDS nodes and observe the logging output.</p>
        <div class="procedure"><ol type="1"><li>
            <p>If they are not already open, open two command prompts and navigate to the samples directory of each installed SymmetricDS application
            (for example, navigate to <code class="literal">sym-corp/symmetric-ds-3.x.x/samples</code> and <code class="literal">sym-store001/symmetric-ds-3.x.x/samples</code>).
            </p></li><li>
                <p>From the corp samples directory, start the corp SymmetricDS by executing:</p>
                <p>
                    <span><strong class="command">../bin/sym --engine corp-000 --port 8080</strong></span>
                </p>
                <p>
                Upon startup for the first time, the corp node creates all the triggers that were configured by the sample
                    configuration. It listens on port 8080 for synchronization and registration requests for the corp-000 engine.</p>
            </li><li>
                <p>From the store001 samples directory, start the store SymmetricDS by executing:</p>
                <p>
                    <span><strong class="command">../bin/sym --engine store-001 --port 9090</strong></span>
                </p>
                <p>This command starts the store node server for the first time and uses the auto-creation feature to create the SymmetricDS system
                    tables.  It begins polling the corp node to try to register (it knows where to contact the corp node via the registration URL you configured in the previous steps).
                     Since registration is not yet open, the store
                    node receives an authorization failure (HTTP response of 403).  We discuss registration next.</p>
            </li></ol></div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ch02-register-node"></a>2.4.&nbsp;Registering a Node</h2></div></div></div>
        
        <p>When an unregistered node starts up, it will attempt to
                        register with the node specified by the registration URL (which is our root node, in almost every case). The registration node centrally controls nodes on
                    the network by allowing registration and returning configuration to a node once it has registered. In this tutorial, the registration node is
                    the root node or 'corp' node, and it also participates in synchronization with other nodes.</p>
        <p> So, we next need to open registration for the store node so that it may receive its initial load of
         data and so that it may receive and send data from and to the corp node.
         There are several ways to do this.  We will use an administration feature available in SymmetricDS and issue a command on the corp node (since it is the node responsible
         for registration).</p>
        <div class="procedure"><ol type="1"><li>
            <p>Leave the corp and store SymmetricDS applications that you started in the previous step running, and open a command prompt and navigate to corp's
                    <code class="filename">samples</code>
                    subdirectory of your corp SymmetricDS installation.</p>
                <p>Open registration for the store node server by executing:</p>
                <p>
                    <span><strong class="command"> ../bin/symadmin --engine corp-000 open-registration store 001</strong></span>
                </p>
                <p>
                    The registration is now opened for a node group called "store" with an external identifier of "001". This
                    information matches the settings in
                    <code class="filename">store-001.properties</code>
                    for the store node. In SymmetricDS, each node is assigned to a node group and is given an external ID that makes sense for the
                    application. In this tutorial, we have retail stores that run SymmetricDS, so we named our node group representing stores as "store" and
                    we used numeric identifiers for external ids starting with "001" ("000" is used to represent the corp node).  More information about node groups will be covered in the next chapter.
                </p>
            </li><li>
                <p>Watch the logging output of the store node to see it successfully register with the corp node. The store
                    is configured to attempt registration at a random time interval up to every minute.
                     Once registered, the corp and store nodes are enabled for
                    synchronization!</p>
            </li></ol></div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ch02-initial-load"></a>2.5.&nbsp;Sending an Initial Load</h2></div></div></div>
        
        <p>Next, we will send an initial load of data to our store, again using a node administration feature run on the corp node.</p>
        <div class="procedure"><ol type="1"><li>
                <p>
                    Open a command prompt and navigate to the corp
                    <code class="filename">samples</code>
                    subdirectory of the corp SymmetricDS installation. (Note that, in general, most system commands are issued using the corp server directly.
                    All configuration, for example, is entered at the corp and synchronized to any clients.)
                </p>
            </li><li>
                <p>Send an initial load of data to the store node server by executing:</p>
                <p>
                    <span><strong class="command">../bin/symadmin --engine corp-000 reload-node 001</strong></span>
                </p>
                <p> With this command, the server node queues up an initial load for the store node that will be sent the next
                    time the store performs its pull. The initial load includes data for each table that is configured for
                    synchronization (assuming its initial load order is a non-negative number, as discussed in later chapters).</p>
            </li><li>
                <p> Watch the logging output of both nodes to see the data transfer. The store is configured to pull data from
                    the corp node every minute.</p>
            </li></ol></div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ch02-pull"></a>2.6.&nbsp;Pulling Data</h2></div></div></div>
        
        <p>Next, we will make a change to the item data in the central office corp node database (we'll add a new item), and observe the data being pulled down to
        the store.
        </p>
        <div class="procedure"><ol type="1"><li>
                <p>Open an interactive SQL session with the <span class="emphasis"><em>corp</em></span> database.</p>
            </li><li>
                <p>Add a new item for sale, with different prices at store 001 and store 002:</p>
                <p>
                    <span><strong class="command">insert into "item" ("item_id", "name") values (110000055, 'Soft Drink');</strong></span>
                </p>
                <p>
                    <span><strong class="command">insert into "item_selling_price" ("item_id", "store_id", "price") values (110000055, '001', 0.65);</strong></span>
                    <span><strong class="command">insert into "item_selling_price" ("item_id", "store_id", "price") values (110000055, '002', 1.00);</strong></span>
                </p>
                <div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
                        Please note that for MySQL, you'll need to change the double quotes (") in the above commands to back ticks (i.e., `)
                        since MySQL uses back ticks instead of double quotes for case-sensitive table and column names.
                    </div>
                <p>Once the statements are committed, the data change is captured by SymmetricDS and queued for the store node to pull.
                </p>
            </li><li>
                <p>Watch the logging output of both nodes to see the data transfer. The store is configured to pull data from
                    the corp every minute.</p>
            </li><li>
                <p>Since <code class="literal">item_selling_price</code> is configured with a
                column match router in this tutorial, specific pricing data changes will be sent (or "routed", in SymmetricDS terms) only to nodes whose <code class="literal">store_id</code> matches the node's external ID
                (see <a href="#configuration-router" title="4.6.2.&nbsp;Router">Section&nbsp;4.6.2, &#8220;Router&#8221;</a> for details of the various routing options available).
                Verify that the new data arrives in the store database using another interactive SQL session.  In this case,
                the first pricing row will be routed to store 001 only, and the second row would be routed to store 002 (which doesn't exist currently,
                so in this case the data change is recorded but routed nowhere and therefore discarded.)
                </p>
            </li></ol></div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ch02-push"></a>2.7.&nbsp;Pushing Data</h2></div></div></div>
        
        <p>We will now simulate a sale at the store and observe how SymmetricDS pushes the sale transaction to the central office.</p>
        <div class="procedure"><ol type="1"><li>
                <p>Open an interactive SQL session with the <span class="emphasis"><em>store</em></span> node database.</p>
            </li><li>
                <p>Add a new sale to the store node database:</p>
                <p>
                    <span><strong class="command"> insert into "sale_transaction" ("tran_id", "store_id", "workstation", "day", "seq") values (1000, '001', '3',
                        '2007-11-01', 100);</strong></span>
                </p>
                <p>
                    <span><strong class="command"> insert into "sale_return_line_item" ("tran_id", "item_id", "price", "quantity") values (1000, 110000055, 0.65,
                        1);</strong></span>
                </p>
                <p> Once the statements are committed, the data change is captured and queued for the store node to push.
                </p>
            </li><li>
                <p> Watch the logging output of both nodes to see the data transfer. The store is configured to push data to
                    the corp node every minute.</p>
            </li></ol></div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ch02-verify-outgoing"></a>2.8.&nbsp;Verifying Outgoing Batches</h2></div></div></div>
        
        <p>Now that we have pushed and pulled data, we will demonstrate how you can obtain information about what data has been batched and sent.
         A batch is used for tracking and sending one or more data changes to a given node. The sending node creates a batch and the receiving
            node receives and then acknowledges it.
            </p><p>In addition, in SymmetricDS tables are grouped into data "Channels" for, among many reasons, the purpose of allowing different types of data to synchronize
            even when other types of data might be in error.  For example, if a batch for a given channel is in error, that batch will be retried with each synchronization for
            that channel until the batch is no longer in error.  Only after the batch is no longer in error will additional batches for that channel be sent.  In this way, the order of the data changes that have
            occurred for a given channel are guaranteed to be sent to the destination in the same order they occurred on the source.
            Batches on a channel without batch errors, however, will not be blocked by the existence of a batch in error on a different channel.  In this way,
            data changes for one channel are not blocked by errors present in another channel.
        </p>
        <p>Explore the outgoing batches by doing the following:</p>
        <div class="procedure"><ol type="1"><li>
                <p>Open an interactive SQL session with either the corp or store database.</p>
            </li><li>
                <p> Verify that the data change you made was captured:</p>
                <p>
                    <span><strong class="command">select * from sym_data order by data_id desc;</strong></span>
                </p>
                <p> Each row represents a row of data that was changed. Data Ids are sequentially increasing, so one of the most recent (highest) data ids should be
                related to your data insert SQLs.  The <code class="literal">event_type</code> is "I" for insert, "U" for update", or
                    "D" for delete. For insert and update, the captured data values are listed in <code class="literal">row_data</code>. For update and delete,
                    the primary key values are listed in <code class="literal">pk_data</code>.</p>
            </li><li>
                <p> Verify that the data change was included in a batch, using the data_id from the previous step:</p>
                <p>
                    <span><strong class="command"> select * from sym_data_event where data_id = ?;</strong></span>
                </p>
                <p>Batches are created based on the needed routing to nodes as part of a background job, called the Route Job.
                As part of the Route Job, the data change is assigned to a batch using a <code class="literal">batch_id</code> which is used to track
                and synchronize the data. The links between batches and data are managed by this <code class="literal">sym_data_event</code> table.</p>
            </li><li>
                <p>Verify that the data change was batched, sent to the destination, and acknowledged, using the <code class="literal">batch_id</code> from the previous step:
                </p>
                <p>
                    <span><strong class="command"> select * from sym_outgoing_batch where batch_id = ?;</strong></span>
                </p>
                <p>Batches initially have a status of "NE" when they are new and not yet sent to a node.  Once a receiving node acknowledges the batch, the batch status is
                changed to a status of "OK" for success or "ER" for error (failure). If the batch failed, the <code class="literal">error_flag</code> on
                the batch is also sent to 1, since the status of a batch that failed can
                change as it's being retried.</p>
            </li></ol></div>
        <p>
        Understanding these three tables, along with a fourth table discussed in the next section, is key to diagnosing any synchronization issues you might encounter.
        As you work with SymmetricDS, either when experimenting or starting to use SymmetricDS on your own data, spend time monitoring these tables to
        better understand how SymmetricDS works.  Exploring and solving any synchronization issues is discussed later in far greater depth in <a href="#solving-synchronization-issues" title="6.1.&nbsp;Solving Synchronization Issues">Section&nbsp;6.1, &#8220;Solving Synchronization Issues&#8221;</a>.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ch02-verify-incoming"></a>2.9.&nbsp;Verifying Incoming Batches</h2></div></div></div>
        
        <p> The receiving node keeps track of the batches it acknowledges and records statistics about loading the data.
            Duplicate batches are skipped by default, but this behavior can be changed with the <code class="literal">incoming.batches.skip.duplicates</code>
            runtime property.</p>
            <p>Explore incoming batches by doing the following:</p>
        <div class="procedure"><ol type="1"><li>
                <p>Open an interactive SQL session with either the corp or store database.</p>
            </li><li>
                <p> Verify that the batch was received and acknowledged, using a batch_id from the previous section:</p>
                <p>
                    <span><strong class="command"> select * from sym_incoming_batch where batch_id = ?;</strong></span>
                </p>
                <p> A batch represents a collection of changes loaded by the node. The sending node that created the batch is
                    recorded, and the batch's status is either "OK" for success or "ER" for error.</p>
            </li></ol></div>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="multi-homing"></a>2.10.&nbsp;Multi-Homing</h2></div></div></div>
      
        <p>
          Our Quick Start Tutorial is finished.
          We have successfully set up and performed synchronization between two databases.
          However, we did want to go back and discuss one of the first steps you did in the tutorial; namely, the step where you
          installed two copies of SymmetricDS when doing the tutorial.  Feel free to skip this section until a later time if you wish.
        </p>
        <p>
        In the example above, we placed one properties file in the engines directory of each installed SymmetricDS application.
        When SymmetricDS was started in the examples above, the application initialized, and then created a "SymmetricDS engine"
        based on the provided property file (again, each engine serves as a SymmetricDS node and is responsible for one particular database).
        </p>

        <p>
        In reality, though, the SymmetricDS application is capable of starting more than one engine at a time.   When SymmetricDS starts,
        it looks in the <code class="literal">engines</code> directory for any files that end in <code class="literal">.properties</code>.  It will start a SymmetricDS engine for each and every
        property file found. The <code class="literal">--engine</code> command line prompt is an override for this and will cause SymmetricDS to
        only start the one engine as specified on the command line.  In cases where a single SymmetricDS application is running multiple engines, this is known
        as a "multi-homed" SymmetricDS application, and the feature, in general, is known as "multi-homing".
        </p>
                       <p>
                </p><div class="figure"><a name="figure-tutorial-combined"></a><div class="figure-contents">
                    
                    <div class="mediaobject"><img src="images/multi-home-combined.gif" alt="Multi-Homed version of Tutorial"></div>
                </div><p class="title"><b>Figure&nbsp;2.3.&nbsp;Multi-Homed version of Tutorial</b></p></div><p><br class="figure-break">
            </p>
        <p>
        So, for our tutorial above, how could we have "multi-homed" the corp and store such that we only had to install a single copy of SymmetricDS?
        It's fairly simple.  The following changes to the above would be needed:

        </p>
         <div class="procedure"><ol type="1"><li>
            <p>Install a single copy of the SymmetricDS software instead of two copies.  You no longer need a directory to represent the two machines.</p>
            </li><li>
           <p> Instead of copying a single property file from <code class="literal">samples</code> to each separate <code class="literal">engines</code> directory, copy both files
            to just the one engines directory. </p></li><li>
           <p>All commands in the tutorial are run from the one single <code class="literal">samples</code> directory.</p></li><li>
            <p>When you start SymmetricDS, you will no longer specify a specific engine, as you want both engines to start.  The command, still run
            from the <code class="literal">samples</code> directory, would now be:</p>
             <p>
             <span><strong class="command">../bin/sym --port 8080</strong></span>
            </p>
            <p>Note that we are no longer using port 9090, by the way.  SymmetricDS now listens on port 8080 for traffic relevant to both the
            store and corp engines.</p>
            </li><li>
           <p>Other than starting the server, all other commands you executed will still have the <code class="literal">--engine</code> specification, since you are addressing the command
            itself to a specific node (engine) of SymmetricDS to open registration, set up the corp server to issue an initial load to store, etc.</p>
            </li></ol></div>

    </div>
</div>
    <div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="planning"></a>Chapter&nbsp;3.&nbsp;Planning</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#identifying-nodes">3.1. Identifying Nodes</a></span></dt><dt><span class="section"><a href="#organizing-nodes">3.2. Organizing Nodes</a></span></dt><dt><span class="section"><a href="#grouping-nodes">3.3. Defining Node Groups</a></span></dt><dt><span class="section"><a href="#linking-nodes">3.4. Linking Nodes</a></span></dt><dt><span class="section"><a href="#choosing-channels">3.5. Choosing Data Channels</a></span></dt><dt><span class="section"><a href="#defining-data-changes">3.6. Defining Data Changes to be Captured and Routed</a></span></dt><dd><dl><dt><span class="section"><a href="#defining-data-changes-triggers">3.6.1. Defining Triggers</a></span></dt><dt><span class="section"><a href="#defining-data-changes-routers">3.6.2. Defining Routers</a></span></dt><dt><span class="section"><a href="#defining-data-changes-trigger-routers">3.6.3. Mapping Triggers to Routers</a></span></dt><dd><dl><dt><span class="section"><a href="#defining-data-changes-trigger-routers-initial-load">3.6.3.1. Planning Initial Loads</a></span></dt><dt><span class="section"><a href="#defining-data-changes-trigger-routers-ping-back">3.6.3.2. Circular References and "Ping Back"</a></span></dt></dl></dd><dt><span class="section"><a href="#planning-registration">3.6.4. Planning for Registering Nodes</a></span></dt></dl></dd><dt><span class="section"><a href="#defining-transformation">3.7. Planning Data Transformations</a></span></dt><dt><span class="section"><a href="#defining-conflicts">3.8. Planning Conflict Detection and Resolution</a></span></dt></dl></div>
    
    <p>
        In the previous Chapter we presented a high level introduction to some basic concepts in SymmetricDS, some of the
        high-level features, and a tutorial demonstrating a basic, working example of SymmetricDS in action. This chapter
        will focus on the key considerations and decisions one must make when planning a SymmetricDS implementation. As
        needed, basic concepts will be reviewed or introduced throughout this Chapter. By the end of the chapter you should
        be able to proceed forward and implement your planned design. This Chapter will intentionally avoid discussing the
        underlying database tables that capture the configuration resulting from your analysis and design process.
        Implementation of your design, along with discussion of the tables backing each concept, is covered in
        <a href="#configuration" title="Chapter&nbsp;4.&nbsp;Configuration">Chapter&nbsp;4, <i xmlns:xlink="http://www.w3.org/1999/xlink">Configuration</i></a>
        .
    </p>
    <p> When needed, we will rely on an example of a typical use of SymmetricDS in retail situations. This example retail
        deployment of SymmetricDS might include many point-of-sale workstations located at stores that may have intermittent
        network connection to a central location. These workstations might have point-sale-software that uses a local
        relational database. The database is populated with items, prices and tax information from a centralized database.
        The point-of-sale software looks up item information from the local database and also saves sale information to the
        same database. The persisted sales need to be propagated back to the centralized database.
    </p>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="identifying-nodes"></a>3.1.&nbsp;Identifying Nodes</h2></div></div></div>
        
        <p>
            A
            <span class="emphasis"><em>node</em></span>
            is a single instance of SymmetricDS. It can be thought of as a proxy for a database which manages the
            synchronization of data to and/or from its database. For our example retail application, the following would be
            SymmetricDS nodes:
            </p><div class="itemizedlist"><ul type="disc"><li>Each point-of-sale workstation.</li><li>The central office database server.</li></ul></div><p>
            Each node of SymmetricDS can be either embedded in another application, run stand-alone, or even run in the
            background as a service. If desired, nodes can be clustered to help disperse load if they send and/or receive
            large volumes of data to or from a large number of nodes.
        </p>
        <p> Individual nodes are easy to identify when planning your implementation. If a database exists in your domain
            that needs to send or receive data, there needs to be a corresponding SymmetricDS instance (a node) responsible
            for managing the synchronization for that database.
        </p>
        
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="organizing-nodes"></a>3.2.&nbsp;Organizing Nodes</h2></div></div></div>
        
        <p> Nodes in SymmetricDS are organized into an overall node network, with connections based on what data needs to
            be synchronized where. The exact organization of your nodes will be very specific to your synchronization goals.
            As a starting point, lay out your nodes in diagram form and draw connections between nodes to represent cases in
            which data is to flow in some manner. Think in terms of what data is needed at which node, what data is in common
            to more than one node, etc. If it is helpful, you could also show data flow into and out of external systems. As
            you will discover later, SymmetricDS can publish data changes from a node as well using JMS.
        </p>
        <p>
            Our retail example, as shown in
            <a href="#figure-two-tier" title="Figure&nbsp;3.1.&nbsp;Two-Tier Retail Store Deployment Example">Figure&nbsp;3.1</a>
            , represents a tree hierarchy with a single central office node connected by lines to one or more children nodes
            (the POS workstations). Information flows from the central office node to an individual register and vice versa,
            but never flows between registers.
        </p>
        <p>
            </p><div class="figure"><a name="figure-two-tier"></a><div class="figure-contents">
                
                <div class="mediaobject"><img src="images/two-tier-arch.gif" alt="Two-Tier Retail Store Deployment Example"></div>
            </div><p class="title"><b>Figure&nbsp;3.1.&nbsp;Two-Tier Retail Store Deployment Example</b></p></div><p><br class="figure-break">
        </p>
        <p>
            More complex organization can also be used. Consider, for example, if the same retail example is expanded to
            include store
            <span class="emphasis"><em>servers</em></span>
            in each store to perform tasks such as opening the store for the day, reconciling registers, assigning employees,
            etc. One approach to this new configuration would be to create a three-tier hierarchy (see
            <a href="#figure-three-tier-store-server" title="Figure&nbsp;3.2.&nbsp;Three-Tier, In-Store Server, Retail Store Deployment Example">Figure&nbsp;3.2</a>
            ). The highest tier, the centralized database, connects with each store server's database. The store servers, in
            turn, communicate with the individual point-of-sale workstations at the store. In this way data from each
            register could be accumulated at the store server, then sent on to the central office. Similarly, data from the
            central office can be staged in the store server and then sent on to each register, filtering the register's data
            based on which register it is.
        </p>
        <p>
            </p><div class="figure"><a name="figure-three-tier-store-server"></a><div class="figure-contents">
                
                <div class="mediaobject"><img src="images/three-tier-arch.gif" alt="Three-Tier, In-Store Server, Retail Store Deployment Example"></div>
            </div><p class="title"><b>Figure&nbsp;3.2.&nbsp;Three-Tier, In-Store Server, Retail Store Deployment Example</b></p></div><p><br class="figure-break">
        </p>
        <p>
            One final example, show in
            <a href="#figure-three-tier-regional" title="Figure&nbsp;3.3.&nbsp;Three-Tier, Regional Server, Retail Store Deployment Example">Figure&nbsp;3.3</a>
            , again extending our original two-tier retail use case, would be to organize stores by "region" in the world.
            This three tier architecture would introduce new regional servers (and corresponding regional databases) which
            would consolidate information specific to stores the regional server is responsible for. The tiers in this case
            are therefore the central office server, regional servers, and individual store registers.
        </p>
        <p>
            </p><div class="figure"><a name="figure-three-tier-regional"></a><div class="figure-contents">
                
                <div class="mediaobject"><img src="images/three-tier-regional-arch.gif" alt="Three-Tier, Regional Server, Retail Store Deployment Example"></div>
            </div><p class="title"><b>Figure&nbsp;3.3.&nbsp;Three-Tier, Regional Server, Retail Store Deployment Example</b></p></div><p><br class="figure-break">
        </p>
        <p> These are just three common examples of how one might organize nodes in SymmetricDS. While the examples above
            were for the retail industry, the organization, they could apply to a variety of application domains.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="grouping-nodes"></a>3.3.&nbsp;Defining Node Groups</h2></div></div></div>
        
        <p>
            Once the organization of your SymmetricDS nodes has been chosen, you will need to
            <span class="emphasis"><em>group</em></span>
            your nodes based on which nodes share common functionality. This is accomplished in SymmetricDS through the
            concept of a
            <span class="emphasis"><em>Node Group</em></span>
            . Frequently, an individual tier in your network will represent one Node Group. Much of SymmetricDS'
            functionality is specified by Node Group and not an individual node. For example, when it comes time to decide
            where to route data captured by SymmetricDS, the routing is configured by
            <span class="emphasis"><em>Node Group</em></span>
            .
        </p>
        <p>
            For the examples above, we might define Node Groups of:
            </p><div class="itemizedlist"><ul type="disc"><li>"workstation", to represent each point-of-sale workstation</li><li>"corp" or "central-office" to represent the centralized node.</li><li>"store" to represent the store server that interacts with store workstations and sends and receives
                    data from a central office server.
                </li><li>"region" to represent the a regional server that interacts with store workstations and sends and
                    receives data from a central office server.
                </li></ul></div><p>
            Considerable thought should be given to how you define the Node Groups. Groups should be created for each set of
            nodes that synchronize common tables in a similar manner. Also, give your Node Groups meaningful names, as they
            will appear in many, many places in your implementation of SymmetricDS.
        </p>
        <p>Note that there are other mechanisms in SymmetricDS to route to individual nodes or smaller subsets of nodes
            within a Node Group, so do not choose Node Groups based on needing only subsets of data at specific nodes. For
            example, although you could, you would not want to create a Node Group for each store even though different tax
            rates need to be routed to each store. Each store needs to synchronize the same tables to the same groups, so
            'store' would be a good choice for a Node Group.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="linking-nodes"></a>3.4.&nbsp;Linking Nodes</h2></div></div></div>
        
        <p>
            Now that Node Groups have been chosen, the next step in planning is to document the individual links between Node
            Groups. These
            <span class="emphasis"><em>Node Group Links</em></span>
            establish a source Node Group, a target Node Group, and a
            <span class="emphasis"><em>data event action</em></span>
            , namely whether the data changes are
            <span class="emphasis"><em>pushed</em></span>
            or
            <span class="emphasis"><em>pulled</em></span>
            . The push method causes the source Node Group to connect to the target, while a pull method causes it to wait
            for the target to connect to it.
        </p>
        <p>For our retail store example, there are two Node Group Links defined. For the first link, the "store" Node
            Group pushes data to the "corp" central office Node Group. The second defines a "corp" to "store" link as a pull.
            Thus, the store nodes will periodically pull data from the central office, but when it comes time to send data to
            the central office a store node will do a push.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="choosing-channels"></a>3.5.&nbsp;Choosing Data Channels</h2></div></div></div>
        
        <p>When SymmetricDS captures data changes in the database, the changes are captured in the order in which they
            occur. In addition, that order is preserved when synchronizing the data to other nodes. Frequently, however, you
            will have cases where you have different "types" of data with differing priorities. Some data might, for example,
            need priority for synchronization despite the normal order of events. For example, in a retail environment, users
            may be waiting for inventory documents to update while a promotional sale event updates a large number of items.
        </p>
        <p>
            SymmetricDS supports this by allowing tables being synchronized to be grouped together into
            <span class="emphasis"><em>Channels</em></span>
            of data. A number of controls to the synchronization behavior of SymmetricDS are controlled at the Channel level.
            For example, Channels provide a processing order when synchronizing, a limit on the amount of data that will be
            batched together, and isolation from errors in other channels. By categorizing data into channels and assigning
            them to
            <a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
            s, the user gains more control and visibility into the flow of data. In addition, SymmetricDS allows for
            synchronization to be enabled, suspended, or scheduled by Channels as well. The frequency of synchronization can
            also be controlled at the channel level.
        </p>
        
        <p> Choosing Channels is fairly straightforward and can be changed over time, if needed. Think about the differing
            "types" of data present in your application, the volume of data in the various types, etc. What data is
            considered must-have and can't be delayed due to a high volume load of another type of data? For example, you
            might place employee-related data, such as clocking in or out, on one channel, but sales transactions on another.
            We will define which tables belong to which channels in the next sections.
        </p>
        <div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
            <p> Be sure that, when defining Channels, all tables related by foreign keys are included in the same channel.
            </p>
        </div>
        <div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
            <p> Avoid deadlocks!  If client database transactions include tables that update common rows along with different rows, then
            concurrent synchronization can cause database deadlocks.  You can avoid this by using channels to segregate those tables
            that cause the deadlocks.
            </p>
        </div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="defining-data-changes"></a>3.6.&nbsp;Defining Data Changes to be Captured and Routed</h2></div></div></div>
        
        <p>
            At this point, you have designed the node-related aspects of your implementation, namely choosing nodes, grouping
            the nodes based on functionality, defining which node groups send and receive data to which others (and by what
            method). You have defined data Channels based on the types and priority of data being synchronized. The largest
            remaining task prior to starting your implementation is to define and document what data changes are to be
            captured (by defining SymmetricDS
            <span class="emphasis"><em>Triggers</em></span>
            ), to decide to which node(s) the data changes are to be
            <span class="emphasis"><em>routed</em></span>
            to, and to decide which trigger applies to which router and under what conditions. We will also, in this section, discuss the concept of an
            <span class="emphasis"><em>initial load</em></span>
            of data into a SymmetricDS node.
        </p>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="defining-data-changes-triggers"></a>3.6.1.&nbsp;Defining Triggers</h3></div></div></div>
            
            <p>
                SymmetricDS uses
                <span class="emphasis"><em>database triggers</em></span>
                to capture and record changes to be synchronized to other nodes. Based on the configuration you provide,
                SymmetricDS creates the needed database triggers automatically for you. There is a great deal of flexibility
                in terms of defining the exact conditions under which a data change is captured. SymmetricDS triggers are
                defined in a table named
                <a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
                . Each trigger you define is for a particular table associated. Each trigger can also specify:
                </p><div class="itemizedlist"><ul type="disc"><li>whether to install a trigger for updates, inserts, and/or deletes</li><li>conditions on which an insert, update, and/or delete fires</li><li>a list of columns that should not be synchronized from this table</li><li>a SQL select statement that can be used to hold data needed for routing (known as External
                        Data)</li></ul></div><p>
            </p>
            <p> As you define your triggers, consider which data changes are relevant to your application and which ones
                ar not. Consider under what special conditions you might want to route data, as well. For our retail example,
                we likely want to have triggers defined for updating, inserting, and deleting pricing information in the
                central office so that the data can be routed down to the stores. Similarly, we need triggers on sales
                transaction tables such that sales information can be sent back to the central office.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="defining-data-changes-routers"></a>3.6.2.&nbsp;Defining Routers</h3></div></div></div>
            
            <p>
                The triggers that have been defined in the previous section only define
                <span class="emphasis"><em>when</em></span>
                data changes are to be captured for synchronization. They do not define
                <span class="emphasis"><em>where</em></span>
                the data changes are to be sent to. Routers, plus a mapping between Triggers and Routers (
                <a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
                ), define the process for determining which nodes receive the data changes.
            </p>
            <p>
                Before we discuss Routers and Trigger Routers, we should probably take a break and discuss the process
                SymmetricDS uses to keep track of the changes and routing. As we stated, SymmetricDS relies on auto-created
                database triggers to capture and record relevant data changes into a table, the
                <a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
                table. After the data is captured, a background process chooses the nodes that the data will be synchronized
                to. This is called
                <span class="emphasis"><em>routing</em></span>
                and it is performed by the Routing Job. Note that the Routing Job does not actually send any data. It just
                organizes and records the decisions on where to send data in a "staging" table called
                <a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
                and
                <a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
                .
            </p>
            <p>
                Now we are ready to discuss Routers. The router itself is what defines the configuration of where to send a
                data change. Each Router you define can be associated with or assigned to any number of Triggers through a
                join table that defines the relationship. Routers are defined in the SymmetricDS table named
                <a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
                . For each router you define, you will need to specify:
                </p><div class="itemizedlist"><ul type="disc"><li>the target table on the destination node to route the data</li><li>the source node group and target node group for the nodes to route the data to</li><li>
                        a router
                        <span class="emphasis"><em>type</em></span>
                        and router
                        <span class="emphasis"><em>expression</em></span>
                    </li><li>whether to route updates, inserts, and/or deletes</li></ul></div><p>
            </p>
            <p>
                For now, do not worry about the specific routing types. They will be covered later. For your design simply
                make notes of the information needed and decisions to determine the list of nodes to route to. You will find
                later that there is incredible flexibility and functionality available in routers. For example, you will find
                you can:
                </p><div class="itemizedlist"><ul type="disc"><li>send the changes to all nodes that belong to the target node group defined in the router.
                    </li><li>compare old or new column values to a constant value or the value of a node's identity.
                    </li><li>execute a SQL expression against the database to select nodes to route to. This SQL expression
                        can be passed values of old and new column values.
                    </li><li>execute a Bean Shell expression in order to select nodes to route to. The Bean Shell expression
                        can use the old and new column values.
                    </li><li>publish data changes directly to a messaging solution instead of transmitting changes to
                        registered nodes. (This router must be configured manually in XML as an extension point.)
                    </li></ul></div><p>
            </p>

        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="defining-data-changes-trigger-routers"></a>3.6.3.&nbsp;Mapping Triggers to Routers</h3></div></div></div>
            

             <p> For each of your Triggers (which specify when a data change should be captured),
                 you will need to decide which Router(s) to pair with the Trigger such that the change is routed
                 to the desired target nodes.   This needed mapping between Triggers and Routers, found in the table
                <a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
                , defines configuration specific to a particular Trigger and Router combination that you need.
                In addition to defining which triggers map to which routers, the table also has several
                settings present to define various behaviors, including initial loads and ping back.
            </p>
            <div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="defining-data-changes-trigger-routers-initial-load"></a>3.6.3.1.&nbsp;Planning Initial Loads</h4></div></div></div>
                
                <p>
                    SymmetricDS provides the ability to "load" or "seed" a node's database with specific sets of data from
                    its parent node. This concept is known as an
                    <span class="emphasis"><em>Initial Load</em></span>
                    of data and is used to start off most synchronization scenarios. The Trigger Router mapping defines how
                    initial loads can occur, so now is a good time to plan how your
                    <span class="emphasis"><em>Initial Loads</em></span>
                    will work. Using our retail example, consider a new store being opened. Initially, you would like to
                    pre-populate a store database with all the item, pricing, and tax data for that specific store. This is
                    achieved through an initial load. As part of your planning, be sure to consider which tables, if any, will
                    need to be loaded initially. SymmetricDS can also perform an initial load on a table with just a subset
                    of data. Initial Loads are further discussed in
                    <a href="#configuration-initial-load" title="4.6.3.2.&nbsp;Initial Loads">Section&nbsp;4.6.3.2, &#8220;Initial Loads&#8221;</a>.
                </p>
            </div>
            <div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="defining-data-changes-trigger-routers-ping-back"></a>3.6.3.2.&nbsp;Circular References and "Ping Back"</h4></div></div></div>
                
                <p>
                    When routing data, SymmetricDS by default checks each data change and will not route a data change back
                    to a node if it originated the change to begin with. This prevents the possibility of data changes
                    resulting in an infinite loop of changes under certain circumstances. You may find that, for some reason,
                    you need SymmetricDS to go ahead and send the data back to the originating node - a "ping back". As part
                    of the planning process, consider whether you have a special case for needing ping back. Ping Back
                    control is further discussed in
                    <a href="#configuration-trigger-router-ping-back" title="4.6.3.4.&nbsp;Enabling &#34;Ping Back&#34;">Section&nbsp;4.6.3.4, &#8220;Enabling "Ping Back"&#8221;</a>.
                </p>
            </div>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="planning-registration"></a>3.6.4.&nbsp;Planning for Registering Nodes</h3></div></div></div>
            
            <p>
                Our final step in planning an implementation of SymmetricDS involves deciding how a new node is connected to,
                or
                <span class="emphasis"><em>registered</em></span>
                with a parent node for the first time.
            </p>
            <p>
                The following are some options on ways you might register nodes:
                </p><div class="itemizedlist"><ul type="disc"><li>The tutorial uses the command line utility to register each individual node.</li><li>A JMX interface provides the same interface that the command line utility does. JMX can be
                        invoked programmatically or via a web console.</li><li>Both the utility and the JMX method register a node by inserting into two tables. A script can
                        be written to directly register nodes by directly inserting into the database.</li><li>SymmetricDS can be configured to auto register nodes. This means that any node that asks for a
                        registration will be given one.</li></ul></div><p>
            </p>
        </div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="defining-transformation"></a>3.7.&nbsp;Planning Data Transformations</h2></div></div></div>
        
        <p>
            SymmetricDS also provides the ability to
            <span class="emphasis"><em>transform</em></span>
            synchronized data instead of simply synchronizing it. Your application might, for example require a particular
            column in your source data to be mapped to two different target tables with possibly different column names. Or,
            you might need to "merge" one or more columns of data from two indepdentent tables into one table on the target.
            Or, you may want to set default column values on a target table based on a particular event on the source
            database. All of these operations, and many more, can be accomplished using SymmetricDS' transformation
            capabilities.
        </p>
        <p>
            As you plan your SymmetricDS implementation, make notes of cases where a data transformation is needed. Include
            details such as when the transformation might occur (is it only on an insert, or a delete?), which tables or
            columns play a part, etc. Complete details of all the transformation features, including how to configure a
            transformation, are discussed in <a href="#transform-data" title="4.8.&nbsp;Transforming Data">Section&nbsp;4.8, &#8220;Transforming Data&#8221;</a>.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="defining-conflicts"></a>3.8.&nbsp;Planning Conflict Detection and Resolution</h2></div></div></div>
        
        <p> As a final step to planning an implementation, consider for a moment cases in which the same data may be
            modified at nearly the same time at more than one node. For example, can data representing a customer be modified
            at both a central office and a store location? Conflict detection is the act of determining if an insert, update
            or delete is in "conflict" due to the target data row not being consistent with the data at the source prior to
            the insert/update/delete. Conflict resolution is the act of figuring out what to do when a conflict is detected.
            Both detection and resolution behaviour can be configured and customized in a number of ways. For example, a
            conflict can be "detected" based solely on a single column which has been modified to a different value, or a row
            can be considered in conflict if any data in the row has been changed from what was expected, even if the column
            that has been changed was still expected. There are also numerous ways to resolve the conflict, such as
            referencing a timestamp column and choosing whichever edit was "most recent" or perhaps causing the conflict to
            cause the channel to go into error until a manual resolution takes place. A set of conflict detection /
            resolution rules is configured for a given node group link, but you can set the rules to be for a given channel
            or for a given table in a channel.
        </p>
        <p>
            For the purpose of planning your implementation, make a list of all tables that could have data being modified at
            more than one node at the same time. For each table, think through what should happen in each case if such an
            event occurs. If the tables on a given channel all have the same set of conflict resolution and detection rules,
            then you might be able to configure the rules for the channel instead of a series of table-level detections and
            resolutions. Complete details on how to configure conflict resolution and detection are discussed further in
            <a href="#conflicts" title="4.10.&nbsp;Conflict Detection and Resolution">Section&nbsp;4.10, &#8220;Conflict Detection and Resolution&#8221;</a>.</p></div></div>
    <div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="configuration"></a>Chapter&nbsp;4.&nbsp;Configuration</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#configuration-node-properties">4.1. Node Properties</a></span></dt><dt><span class="section"><a href="#configuration-node">4.2. Node</a></span></dt><dt><span class="section"><a href="#configuration-node-group">4.3. Node Group</a></span></dt><dt><span class="section"><a href="#configuration-node-group-link">4.4. Node Group Link</a></span></dt><dt><span class="section"><a href="#configuration-channel">4.5. Channel</a></span></dt><dt><span class="section"><a href="#configuration-triggers-and-routers">4.6. Triggers, Routers, and Trigger / Routers Mappings</a></span></dt><dd><dl><dt><span class="section"><a href="#configuration-trigger">4.6.1. Trigger</a></span></dt><dd><dl><dt><span class="section"><a href="#configuration-trigger-lobs">4.6.1.1. Large Objects</a></span></dt><dt><span class="section"><a href="#configuration-trigger-external-select">4.6.1.2. External Select</a></span></dt></dl></dd><dt><span class="section"><a href="#configuration-router">4.6.2. Router</a></span></dt><dd><dl><dt><span class="section"><a href="#configuration-default-router">4.6.2.1. Default Router</a></span></dt><dt><span class="section"><a href="#configuration-column-match-router">4.6.2.2. Column Match Router</a></span></dt><dt><span class="section"><a href="#configuration-lookup-table-router">4.6.2.3. Lookup Table Router</a></span></dt><dt><span class="section"><a href="#configuration-subselect-router">4.6.2.4. Subselect Router</a></span></dt><dt><span class="section"><a href="#configuration-scripted-router">4.6.2.5. Scripted Router</a></span></dt><dt><span class="section"><a href="#configuration-audit-table-router">4.6.2.6. Audit Table Router</a></span></dt><dt><span class="section"><a href="#configuration-routing-external-select">4.6.2.7. Utilizing External Select when Routing</a></span></dt></dl></dd><dt><span class="section"><a href="#configuration-trigger-router">4.6.3. Trigger / Router Mappings</a></span></dt><dd><dl><dt><span class="section"><a href="#configuration-trigger-router-enabled">4.6.3.1. Enable / disable trigger router</a></span></dt><dt><span class="section"><a href="#configuration-initial-load">4.6.3.2. Initial Loads</a></span></dt><dt><span class="section"><a href="#configuration-dead-triggers">4.6.3.3. Dead Triggers</a></span></dt><dt><span class="section"><a href="#configuration-trigger-router-ping-back">4.6.3.4. Enabling "Ping Back"</a></span></dt></dl></dd></dl></dd><dt><span class="section"><a href="#configuration-registration">4.7. Opening Registration</a></span></dt><dt><span class="section"><a href="#transform-data">4.8. Transforming Data</a></span></dt><dd><dl><dt><span class="section"><a href="#transform-data-tables">4.8.1. Transform Configuration Tables</a></span></dt><dt><span class="section"><a href="#transform-data-types">4.8.2. Transformation Types</a></span></dt></dl></dd><dt><span class="section"><a href="#data-load-filter">4.9. Data Load Filters</a></span></dt><dd><dl><dt><span class="section"><a href="#data-load-filter-config">4.9.1. Load Filter Configuration Table</a></span></dt><dt><span class="section"><a href="#data-load-filter-variables">4.9.2. Variables available to Data Load Filters</a></span></dt><dt><span class="section"><a href="#data-load-filter-examples">4.9.3. Data Load Filter Example</a></span></dt></dl></dd><dt><span class="section"><a href="#conflicts">4.10. Conflict Detection and Resolution</a></span></dt><dt><span class="section"><a href="#file-sync">4.11. File Synchronization</a></span></dt><dd><dl><dt><span class="section"><a href="#filesync-overview">4.11.1. Overview</a></span></dt><dt><span class="section"><a href="#filesync-operation">4.11.2. Operation</a></span></dt><dt><span class="section"><a href="#filesync-beanshell">4.11.3. File Sync Bean Shell Scripts</a></span></dt><dt><span class="section"><a href="#filesync-examples">4.11.4. File Sync Examples</a></span></dt><dd><dl><dt><span class="section"><a href="#filesync-example-1">4.11.4.1. Sync Text Files From Server To Client</a></span></dt><dt><span class="section"><a href="#filesync-example-2">4.11.4.2. Route changes to a specific node based on a directory
name</a></span></dt></dl></dd></dl></dd><dt><span class="section"><a href="#jobs">4.12. Jobs</a></span></dt><dd><dl><dt><span class="section"><a href="#routing-job">4.12.1. Route Job</a></span></dt><dd><dl><dt><span class="section"><a href="#data-gaps">4.12.1.1. Data Gaps</a></span></dt></dl></dd><dt><span class="section"><a href="#push-pull-job">4.12.2. Push and Pull Jobs for Database changes</a></span></dt><dt><span class="section"><a href="#file-sync-push-pull">4.12.3. File Sync Push and Pull Jobs</a></span></dt><dt><span class="section"><a href="#file-sync-tracker-job">4.12.4. File System Tracker Job</a></span></dt><dt><span class="section"><a href="#sync-triggers">4.12.5. Sync Triggers Job</a></span></dt><dt><span class="section"><a href="#purge-job">4.12.6. Purge Jobs</a></span></dt></dl></dd></dl></div>


<p>
<a href="#planning" title="Chapter&nbsp;3.&nbsp;Planning">Chapter&nbsp;3</a>
introduced numerous concepts and the analysis and design needed to
create an implementation of SymmetricDS. This chapter re-visits each
analysis step and documents how to turn a SymmetricDS design into
reality through configuration of the various SymmetricDS tables. In
addition, several advanced configuration options, not presented
previously, will also be covered.
</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-node-properties"></a>4.1.&nbsp;Node Properties</h2></div></div></div>


<p>
To get a SymmetricDS node running, it needs to be given an identity and
it needs to know how to connect to the database it will be
synchronizing. The preferred way to configure a SymmetricDS engine is to
create a properties file in the engines directory. The SymmetricDS
server will create an engine for each properties file found in the
engines directory. When started up, SymmetricDS reads the
synchronization configuration and state from the database. If the
configuration tables are missing, they are created automatically (auto
creation can be disabled). Basic configuration is described by inserting
into the following tables (the complete data model is defined in
<a href="#data-model" title="Appendix&nbsp;A.&nbsp;Data Model">Appendix&nbsp;A, <i xmlns:xlink="http://www.w3.org/1999/xlink">Data Model</i></a>
).
</p><div class="itemizedlist"><ul type="disc"><li>
<p>
<a href="#table_node_group" title="A.20.&nbsp;NODE_GROUP">NODE_GROUP</a>
- specifies the tiers that exist in a SymmetricDS network
</p>
</li><li>
<p>
<a href="#table_node_group_link" title="A.22.&nbsp;NODE_GROUP_LINK">NODE_GROUP_LINK</a>
- links two node groups together for synchronization
</p>
</li><li>
<p>
<a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
- grouping and priority of synchronizations
</p>
</li><li>
<p>
<a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
- specifies tables, channels, and conditions for which changes in the
database should be captured
</p>
</li><li>
<p>
<a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
- specifies the routers defined for synchronization, along with other
routing details
</p>
</li><li>
<p>
<a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
- provides mappings of routers and triggers
</p>
</li></ul></div><p>
</p>

<p>During start up, triggers are verified against the
database, and database triggers are installed on tables that require
data changes to be captured. The Route, Pull and Push Jobs begin running
to synchronize changes with other nodes.</p>

<p>
Each node requires properties that allow it to connect to a database and
register with a parent node. Properties are configured in a file named
<code class="code">xxxxx.properties</code>
that is placed in the engines directory of the SymmetricDS install. The
file is usually named according to the engine.name, but it is not a
requirement.
</p>

<p>
To give a node its identity, the following properties are required. Any
other properties found in
<code class="code">conf/symmetric.properties</code>
can be overridden for a specific engine in an engine's properties file.
If the properties are changed in
<code class="code">conf/symmetric.properties</code>
they will take effect across all engines deployed to the server. Note
that you can use the variable
<code class="literal">$(hostName)</code>
to represent the host name of the machine when defining these properties
(for example, external.id=$(hostName) ).
</p>

<div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">engine.name</strong></span>
</span></dt><dd>
<p>This is an arbitrary name that is used to access a specific
engine using an HTTP URL. Each node configured in the engines directory
must have a unique engine name. The engine name is also used for the
domain name of registered JMX beans.</p>
</dd><dt><span class="term">
<span><strong class="command">group.id</strong></span>
</span></dt><dd>
<p>The node group that this node is a member of.
Synchronization is specified between node groups, which means you only
need to specify it once for multiple nodes in the same group.</p>
</dd><dt><span class="term">
<span><strong class="command">external.id</strong></span>
</span></dt><dd>
<p>The external id for this node has meaning to the user and
provides integration into the system where it is deployed. For example,
it might be a retail store number or a region number. The external id
can be used in expressions for conditional and subset data
synchronization. Behind the scenes, each node has a unique sequence
number for tracking synchronization events. That makes it possible to
assign the same external id to multiple nodes, if desired.</p>
</dd><dt><span class="term">
<span><strong class="command">sync.url</strong></span>
</span></dt><dd>
<p>
The URL where this node can be contacted for synchronization. At startup
and during each heartbeat, the node updates its entry in the database
with this URL. The sync url is of the format:
<code class="code">http://{hostname}:{port}/{webcontext}/sync/{engine.name}</code>
.
</p>

<p>The {webcontext} is blank for a standalone deployment. It
will typically be the name of the war file for an application server
deployment.</p>

<p>The {engine.name} can be left blank if there is only one
engine deployed in a SymmetricDS server.</p>
</dd></dl></div>

<p>When a new node is first started, it is has no information
about synchronizing. It contacts the registration server in order to
join the network and receive its configuration. The configuration for
all nodes is stored on the registration server, and the URL must be
specified in the following property:</p>

<div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">registration.url</strong></span>
</span></dt><dd>
<p>The URL where this node can connect for registration to
receive its configuration. The registration server is part of
SymmetricDS and is enabled as part of the deployment. This is typically
equal to the value of the sync.url of the registration server.</p>
</dd></dl></div>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
<p>
Note that a
<span class="emphasis"><em>registration server node</em></span>
is defined as one whose
<code class="literal">registration.url</code>
is either (a) blank, or (b) identical to its
<code class="literal">sync.url</code>
.
</p>
</div>

<p>For a deployment where the database connection pool should
be created using a JDBC driver, set the following properties:</p>

<div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">db.driver</strong></span>
</span></dt><dd>
<p>The class name of the JDBC driver.</p>
</dd><dt><span class="term">
<span><strong class="command">db.url</strong></span>
</span></dt><dd>
<p>The JDBC URL used to connect to the database.</p>
</dd><dt><span class="term">
<span><strong class="command">db.user</strong></span>
</span></dt><dd>
<p>The database username, which is used to login, create, and
update SymmetricDS tables.</p>
</dd><dt><span class="term">
<span><strong class="command">db.password</strong></span>
</span></dt><dd>
<p>The password for the database user.</p>
</dd></dl></div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-node"></a>4.2.&nbsp;Node</h2></div></div></div>


<p>
A
<span class="emphasis"><em>node</em></span>
, a single instance of SymmetricDS, is defined in the
<a href="#table_node" title="A.17.&nbsp;NODE">NODE</a>
table. Two other tables play a direct role in defining a node, as well
The first is
<a href="#table_node_identity" title="A.27.&nbsp;NODE_IDENTITY">NODE_IDENTITY</a>
. The
<span class="emphasis"><em>only</em></span>
row in this table is inserted in the database when the node first
<span class="emphasis"><em>registers</em></span>
with a parent node. In the case of a root node, the row is entered by
the user. The row is used by a node instance to determine its node
identity.
</p>

<p>
The following SQL statements set up a top-level registration server as a
node identified as "00000" in the "corp" node group.
</p><pre class="programlisting"> insert into SYM_NODE (node_id,
node_group_id, external_id, sync_enabled) values ('00000', 'corp',
'00000', 1); insert into SYM_NODE_IDENTITY values ('00000');</pre><p>
</p>

<p>
The second table,
<a href="#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
has rows created for each
<span class="emphasis"><em>child</em></span>
node that registers with the node, assuming auto-registration is
enabled. If auto registration is not enabled, you must create a row in
<a href="#table_node" title="A.17.&nbsp;NODE">NODE</a>
and
<a href="#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
for the node to be able to register. You can also, with this table,
manually cause a node to re-register or do a re-initial load by setting
the corresponding columns in the table itself. Registration is discussed
in more detail in
<a href="#configuration-registration" title="4.7.&nbsp;Opening Registration">Section&nbsp;4.7, &#8220;Opening Registration&#8221;</a>
.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-node-group"></a>4.3.&nbsp;Node Group</h2></div></div></div>


<p>
Node Groups are straightforward to configure and are defined in the
<a href="#table_node_group" title="A.20.&nbsp;NODE_GROUP">NODE_GROUP</a>
table. The following SQL statements would create node groups for "corp"
and "store" based on our retail store example.
</p><pre class="programlisting"> insert into SYM_NODE_GROUP
(node_group_id, description) values ('store', 'A retail store node');

insert into SYM_NODE_GROUP (node_group_id, description) values ('corp',
'A corporate node');</pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-node-group-link"></a>4.4.&nbsp;Node Group Link</h2></div></div></div>


<p>
Similarly, Node Group links are established using a data event action of
'P' for Push and 'W' for Pull ("wait"). The following SQL statements
links the "corp" and "store" node groups for synchronization. It
configures the "store" nodes to push their data changes to the "corp"
nodes, and the "corp" nodes to send changes to "store" nodes by waiting
for a pull.
</p><pre class="programlisting"> insert into SYM_NODE_GROUP_LINK
(source_node_group, target_node_group, data_event_action) values
('store', 'corp', 'P'); insert into SYM_NODE_GROUP_LINK
(source_node_group, target_node_group, data_event_action) values
('corp', 'store', 'W');</pre><p>
</p>

<p>A node group link can be configured to use the same node
group as the source and the target. This configuration allows a node
group to sync with every other node in its group.</p>
<p>A third type of link action of 'R' for 'Route Only' exists
if you want to associate a router with a link that will not move the
data. This action type might be useful when using an XML publishing
router or an audit table changes router.</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-channel"></a>4.5.&nbsp;Channel</h2></div></div></div>


<p>
By categorizing data into channels and assigning them to
<a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
s, the user gains more control and visibility into the flow of data. In
addition, SymmetricDS allows for synchronization to be enabled,
suspended, or scheduled by channels as well. The frequency of
synchronization and order that data gets synchronized is also controlled
at the channel level.
</p>

<p>
The following SQL statements setup channels for a retail store. An
"item" channel includes data for items and their prices, while a
"sale_transaction" channel includes data for ringing sales at a
register.
</p><pre class="programlisting"> insert into SYM_CHANNEL (channel_id,
processing_order, max_batch_size, max_batch_to_send,
extract_period_millis, batch_algorithm, enabled, description) values
('item', 10, 1000, 10, 0, 'default', 1, 'Item and pricing data'); insert
into SYM_CHANNEL (channel_id, processing_order, max_batch_size,
max_batch_to_send, extract_period_millis, batch_algorithm, enabled,
description) values ('sale_transaction', 1, 1000, 10, 60000,
'transactional', 1, 'retail sale transactions from register');</pre><p>
</p>

<p>
Batching is the grouping of data, by channel, to be transferred and
committed at the client together. There are three different
out-of-the-box batching algorithms which may be configured in the
batch_algorithm column on channel.
</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">default</strong></span>
</span></dt><dd>
<p>All changes that happen in a transaction are guaranteed to
be batched together. Multiple transactions will be batched and committed
together until there is no more data to be sent or the max_batch_size is
reached.</p>
</dd><dt><span class="term">
<span><strong class="command">transactional</strong></span>
</span></dt><dd>
<p>Batches will map directly to database transactions. If
there are many small database transactions, then there will be many
batches. The max_batch_size column has no effect.</p>
</dd><dt><span class="term">
<span><strong class="command">nontransactional</strong></span>
</span></dt><dd>
<p>Multiple transactions will be batched and committed
together until there is no more data to be sent or the max_batch_size is
reached. The batch will be cut off at the max_batch_size regardless of
whether it is in the middle of a transaction.</p>
</dd></dl></div><p>
</p>

<p>
If a channel contains
<span class="emphasis"><em>only</em></span>
tables that will be synchronized in one direction and and data is routed
to all the nodes in the target node groups, then batching on the channel
can be optimized to share batches across nodes. This is an important
feature when data needs to be routed to thousands of nodes. When this
mode is detected, you will see batches created in
<a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
with the
<code class="literal">common_flag</code>
set to 1.
</p>

<p>
There are also several size-related parameters that can be set by
channel. They include:
</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">max_batch_size</strong></span>
</span></dt><dd>
<p>Specifies the maximum number of data events to process
within a batch for this channel.</p>
</dd><dt><span class="term">
<span><strong class="command">max_batch_to_send</strong></span>
</span></dt><dd>
<p>Specifies the maximum number of batches to send for a given
channel during a 'synchronization' between two nodes. A
'synchronization' is equivalent to a push or a pull. For example, if
there are 12 batches ready to be sent for a channel and
max_batch_to_send is equal to 10, then only the first 10 batches will be
sent even though 12 batches are ready.</p>
</dd><dt><span class="term">
<span><strong class="command">max_data_to_route</strong></span>
</span></dt><dd>
<p>Specifies the maximum number of data rows to route for a
channel at a time.</p>
</dd></dl></div><p>
</p>

<p>Based on your particular synchronization requirements, you
can also specify whether old, new, and primary key data should be read
and included during routing for a given channel. These are controlled by
the columns use_old_data_to_route, use_row_data_to_route, and
use_pk_data_to_route, respectively. By default, they are all 1 (true).</p>

<p>
Finally, if data on a particular channel contains big lobs, you can set
the column contains_big_lob to 1 (true) to provide SymmetricDS the hint
that the channel contains big lobs. Some databases have shortcuts that
SymmetricDS can take advantage of if it knows that the lob columns in
<a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
aren't going to contain large lobs. The definition of how large a 'big'
lob is varies from database to database.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-triggers-and-routers"></a>4.6.&nbsp;Triggers, Routers, and Trigger / Routers Mappings</h2></div></div></div>


<p>In order to synchronize data, you must define at least one
trigger, at least one router, and provide at least one link between the
two (known as a trigger-router). </p>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="configuration-trigger"></a>4.6.1.&nbsp;Trigger</h3></div></div></div>


<p>
SymmetricDS captures synchronization data using database triggers.
SymmetricDS' Triggers are defined in the
<a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
table. Each record is used by SymmetricDS when generating database
triggers. Database triggers are only generated when a trigger is
associated with a
<a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
whose
<code class="literal">source_node_group_id</code>
matches the node group id of the current node.
</p>

<p>
The
<code class="literal">source_table_name</code>
may contain the asterisk ('*') wildcard character so that one
<a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
table entry can define synchronization for many tables. System tables
and any tables that start with the SymmetricDS table prefix will be
excluded. A list of wildcard tokens can also be supplied. If there are
multiple tokens, they should be delimited with a comma. A wildcard token
can also start with a bang ('!') to indicate an exclusive match. Tokens
are always evalulated from left to right. When a table match is made,
the table is either added to or removed from the list of tables. If
another trigger already exists for a table, then that table is not
included in the wildcard match (the explictly defined trigger entry take
precendence).
</p>

<p>
When determining whether a data change has occurred or not, by defalt
the triggers will record a change even if the data was updated to the
same value(s) they were originally. For example, a data change will be
captured if an update of one column in a row updated the value to the
same value it already was. There is a global property,
<code class="literal">trigger.update.capture.changed.data.only.enabled</code>
(false by default), that allows you to override this behavior. When set
to true, SymmetricDS will only capture a change if the data has truly
changed (i.e., when the new column data is not equal to the old column
data).
</p>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
The property
<code class="literal">trigger.update.capture.changed.data.only.enabled</code>
is currently only supported in the MySQL, DB2 and Oracle dialects.
</div>

<p>
The following SQL statement defines a trigger that will capture data for
a table named "item" whenever data is inserted, updated, or deleted. The
trigger is assigned to a channel also called 'item'.
</p><pre class="programlisting"> insert into SYM_TRIGGER
(trigger_id,source_table_name,channel_id,last_update_time,create_time)
values ('item', 'item', 'item', current_timestamp, current_timestamp); </pre><p>
</p>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
<p>Note that many databases allow for multiple triggers of the
same type to be defined. Each database defines the order in which the
triggers fire differently. If you have additional triggers beyond those
SymmetricDS installs on your table, please consult your database
documentation to determine if there will be issues with the ordering of
the triggers.</p>
</div>


<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-trigger-lobs"></a>4.6.1.1.&nbsp;Large Objects</h4></div></div></div>

<p>
Two lobs-related settings are also available on
<a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
:
</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">use_stream_lobs</strong></span>
</span></dt><dd>
<p>Specifies whether to capture lob data as the trigger is
firing or to stream lob columns from the source tables using callbacks
during extraction. A value of 1 indicates to stream from the source via
callback; a value of 0, lob data is captured by the trigger.</p>
</dd><dt><span class="term">
<span><strong class="command">use_capture_lobs</strong></span>
</span></dt><dd>
<p>Provides a hint as to whether this trigger will capture big
lobs data. If set to 1 every effort will be made during data capture in
trigger and during data selection for initial load to use lob facilities
to extract and store data in the database.</p>
</dd></dl></div><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-trigger-external-select"></a>4.6.1.2.&nbsp;External Select</h4></div></div></div>


<p>
Occasionally, you may find that you need to capture and save away a
piece of data present in another table when a trigger is firing. This
data is typically needed for the purposes of determining where to
'route' the data to once routing takes place. Each trigger definition
contains an optional
<code class="literal">external_select</code>
field which can be used to specify the data to be captured. Once
captured, this data is available during routing in
<a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
's
<code class="literal">external_data</code>
field. For these cases, place a SQL select statement which returns the
data item you need for routing in
<code class="literal">external_select</code>
. An example of the use of external select can be found in
<a href="#configuration-routing-external-select" title="4.6.2.7.&nbsp;Utilizing External Select when Routing">Section&nbsp;4.6.2.7, &#8220;Utilizing External Select when Routing&#8221;</a>
.
</p>
</div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="configuration-router"></a>4.6.2.&nbsp;Router</h3></div></div></div>


<p>
Routers provided in the base implementation currently include:
</p><div class="itemizedlist"><ul type="disc"><li>Default Router - a router that sends all data to
all nodes that belong to the target node group defined in the router.</li><li>Column Match Router - a router that compares old or
new column values to a constant value or the value of a node's
external_id or node_id.</li><li>Lookup Router - a router which can be configured to
determine routing based on an existing or ancillary table specifically
for the purpose of routing data.</li><li>Subselect Router - a router that executes a SQL
expression against the database to select nodes to route to. This SQL
expression can be passed values of old and new column values.</li><li>Scripted Router - a router that executes a Bean
Shell script expression in order to select nodes to route to. The script
can use the old and new column values.</li><li>Xml Publishing Router - a router the publishes data
changes directly to a messaging solution instead of transmitting changes
to registered nodes. This router must be configured manually in XML as
an extension point.</li><li>Audit Table Router - a router that inserts into an
automatically created audit table. It records captured changes to tables
that it is linked to. </li></ul></div><p>
The mapping between the set of triggers and set of routers is
many-to-many. This means that one trigger can capture changes and route
to multiple locations. It also means that one router can be defined an
associated with many different triggers.
</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-default-router"></a>4.6.2.1.&nbsp;Default Router</h4></div></div></div>


<p>
The simplest router is a router that sends all the data that is captured
by its associated triggers to all the nodes that belong to the target
node group defined in the router. A router is defined as a row in the
<a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table. It is then linked to triggers in the
<a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
table.
</p>

<p>
The following SQL statement defines a router that will send data from
the 'corp' group to the 'store' group.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, create_time,
last_update_time) values ('corp-2-store','corp', 'store',
current_timestamp, current_timestamp); </pre><p>
</p>

<p>
The following SQL statement maps the 'corp-2-store' router to the item
trigger.
</p><pre class="programlisting"> insert into SYM_TRIGGER_ROUTER
(trigger_id, router_id, initial_load_order, create_time,
last_update_time) values ('item', 'corp-2-store', 1, current_timestamp,
current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-column-match-router"></a>4.6.2.2.&nbsp;Column Match Router</h4></div></div></div>


<p>
Sometimes requirements may exist that require data to be routed based on
the current value or the old value of a column in the table that is
being routed. Column routers are configured by setting the
<code class="literal">router_type</code>
column on the
<a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table to
<code class="literal">column</code>
and setting the
<code class="literal">router_expression</code>
column to an equality expression that represents the expected value of
the column.
</p>

<p>The first part of the expression is always the column name.
The column name should always be defined in upper case. The upper case
column name prefixed by OLD_ can be used for a comparison being done
with the old column data value.</p>

<p>The second part of the expression can be a constant value,
a token that represents another column, or a token that represents some
other SymmetricDS concept. Token values always begin with a colon (:).</p>

<p>
Consider a table that needs to be routed to all nodes in the target
group only when a status column is set to 'READY TO SEND.' The following
SQL statement will insert a column router to accomplish that.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-ok','corp', 'store', 'column', 'STATUS=READY TO SEND',
current_timestamp, current_timestamp); </pre><p>
</p>

<p>
Consider a table that needs to be routed to all nodes in the target
group only when a status column changes values. The following SQL
statement will insert a column router to accomplish that. Note the use
of OLD_STATUS, where the OLD_ prefix gives access to the old column
value.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-status','corp', 'store', 'column', 'STATUS!=:OLD_STATUS',
current_timestamp, current_timestamp); </pre><p>
</p>

<p>
Consider a table that needs to be routed to only nodes in the target
group whose STORE_ID column matches the external id of a node. The
following SQL statement will insert a column router to accomplish that.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-id','corp', 'store', 'column', 'STORE_ID=:EXTERNAL_ID',
current_timestamp, current_timestamp); </pre><p>
Attributes on a
<a href="#table_node" title="A.17.&nbsp;NODE">NODE</a>
that can be referenced with tokens include:
</p><div class="itemizedlist"><ul type="disc"><li>:NODE_ID</li><li>:EXTERNAL_ID</li><li>:NODE_GROUP_ID</li></ul></div><p>
Captured EXTERNAL_DATA is also available for routing as a virtual
column.
</p>

<p>
Consider a table that needs to be routed to a redirect node defined by
its external id in the
<a href="#table_registration_redirect" title="A.31.&nbsp;REGISTRATION_REDIRECT">REGISTRATION_REDIRECT</a>
table. The following SQL statement will insert a column router to
accomplish that.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-redirect','corp', 'store', 'column',
'STORE_ID=:REDIRECT_NODE', current_timestamp, current_timestamp); </pre><p>
</p>

<p>
More than one column may be configured in a router_expression. When more
than one column is configured, all matches are added to the list of
nodes to route to. The following is an example where the STORE_ID column
may contain the STORE_ID to route to or the constant of ALL which
indicates that all nodes should receive the update.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-multiple-matches','corp', 'store', 'column',
'STORE_ID=ALL or STORE_ID=:EXTERNAL_ID', current_timestamp,
current_timestamp); </pre><p>
</p>

<p>
The NULL keyword may be used to check if a column is null. If the column
is null, then data will be routed to all nodes who qualify for the
update. This following is an example where the STORE_ID column is used
to route to a set of nodes who have a STORE_ID equal to their
EXTERNAL_ID, or to all nodes if the STORE_ID is null.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-multiple-matches','corp', 'store', 'column',
'STORE_ID=NULL or STORE_ID=:EXTERNAL_ID', current_timestamp,
current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-lookup-table-router"></a>4.6.2.3.&nbsp;Lookup Table Router</h4></div></div></div>


<p>
A lookup table may contain the id of the node where data needs to be
routed. This could be an existing table or an ancillary table that is
added specifically for the purpose of routing data. Lookup table routers
are configured by setting the
<code class="literal">router_type</code>
column on the
<a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table to
<code class="literal">lookuptable</code>
and setting a list of configuration parameters in the
<code class="literal">router_expression</code>
column.
</p>

<p>
Each of the following configuration parameters are required.
</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">LOOKUP_TABLE</strong></span>
</span></dt><dd>
<p>This is the name of the lookup table.</p>
</dd><dt><span class="term">
<span><strong class="command">KEY_COLUMN</strong></span>
</span></dt><dd>
<p>This is the name of the column on the table that is being
routed. It will be used as a key into the lookup table.</p>
</dd><dt><span class="term">
<span><strong class="command">LOOKUP_KEY_COLUMN</strong></span>
</span></dt><dd>
<p>This is the name of the column that is the key on the
lookup table.</p>
</dd><dt><span class="term">
<span><strong class="command">EXTERNAL_ID_COLUMN</strong></span>
</span></dt><dd>
<p>This is the name of the column that contains the
external_id of the node to route to on the lookup table.</p>
</dd></dl></div><p>
</p>

<p>Note that the lookup table will be read into memory and
cached for the duration of a routing pass for a single channel.</p>

<p>
Consider a table that needs to be routed to a specific store, but the
data in the changing table only contains brand information. In this
case, the STORE table may be used as a lookup table.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-ok','corp', 'store', 'lookuptable', 'LOOKUP_TABLE=STORE
KEY_COLUMN=BRAND_ID LOOKUP_KEY_COLUMN=BRAND_ID
EXTERNAL_ID_COLUMN=STORE_ID', current_timestamp, current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-subselect-router"></a>4.6.2.4.&nbsp;Subselect Router</h4></div></div></div>


<p>
Sometimes routing decisions need to be made based on data that is not in
the current row being synchronized. A 'subselect' router can be used in
these cases. A 'subselect' is configured with a
<code class="literal">router_expression</code>
that is a SQL select statement which returns a result set of the node
ids that need routed to. Column tokens can be used in the SQL expression
and will be replaced with row column data. The overhead of using this
router type is high because the 'subselect' statement runs for each row
that is routed. It should not be used for tables that have a lot of rows
that are updated. It also has the disadvantage that if the data being
relied on to determine the node id has been deleted before routing takes
place, then no results would be returned and routing would not happen.
</p>
<p>
The
<code class="literal">router_expression</code>
you specify is appended to the following SQL statement in order to
select the node ids:
</p><pre class="programlisting">select c.node_id from sym_node c where
c.node_group_id=:NODE_GROUP_ID and c.sync_enabled=1 and ... </pre><p>
</p><p>
As you can see, you have access to information about the node currently
under consideration for routing through the 'c' alias, for example
<code class="literal">c.external_id</code>
. There are two node-related tokens you can use in your expression:
</p><div class="itemizedlist"><ul type="disc"><li>:NODE_GROUP_ID</li><li>:EXTERNAL_DATA</li></ul></div><p>
</p><p>
Column names representing data for the row in question are prefixed with
a colon as well, for example:

<code class="literal">:EMPLOYEE_ID</code>
, or
<code class="literal">:OLD_EMPLOYEE_ID</code>
. Here, the OLD_ prefix indicates the value before the change in cases
where the old data has been captured.

</p>
<p> For an example, consider the case where an Order table and
an OrderLineItem table need to be routed to a specific store. The Order
table has a column named order_id and STORE_ID. A store node has an
external_id that is equal to the STORE_ID on the Order table.
OrderLineItem, however, only has a foreign key to its Order of order_id.
To route OrderLineItems to the same nodes that the Order will be routed
to, we need to reference the master Order record.</p>

<p>
There are two possible ways to solve this in SymmetricDS. One is to
configure a 'subselect' router_type on the
<a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table, shown below (The other possible approach is to use an
<code class="literal">external_select</code>
to capture the data via a trigger for use in a column match router,
demonstrated in
<a href="#configuration-routing-external-select" title="4.6.2.7.&nbsp;Utilizing External Select when Routing">Section&nbsp;4.6.2.7, &#8220;Utilizing External Select when Routing&#8221;</a>
).
</p>

<p>
Our solution utilizing subselect compares the external id of the current
node with the store id from the Order table where the order id matches
the order id of the current row being routed:
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store','corp', 'store', 'subselect', 'c.external_id in (select
STORE_ID from order where order_id=:ORDER_ID)', current_timestamp,
current_timestamp); </pre><p>
</p>

<p>As a final note, please note in this example that the
parent row in Order must still exist at the moment of routing for the
child rows (OrderLineItem) to route, since the select statement is run
when routing is occurring, not when the change data is first captured. </p>

</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-scripted-router"></a>4.6.2.5.&nbsp;Scripted Router</h4></div></div></div>


<p>
When more flexibility is needed in the logic to choose the nodes to
route to, then the a scripted router may be used. The currently
available scripting language is Bean Shell. Bean Shell is a Java-like
scripting language. Documentation for the Bean Shell scripting language
can be found at
<a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://www.beanshell.org/" target="_top">http://www.beanshell.org</a>
.
</p>

<p>
The router_type for a Bean Shell scripted router is 'bsh'. The
router_expression is a valid Bean Shell script that:
</p><div class="itemizedlist"><ul type="disc"><li>
adds node ids to the
<code class="code">targetNodes</code>
collection which is bound to the script
</li><li>returns a new collection of node ids</li><li>returns a single node id</li><li>returns true to indicate that all nodes should be
routed or returns false to indicate that no nodes should be routed</li></ul></div><p>
Also bound to the script evaluation is a list of
<code class="code">nodes</code>
. The list of
<code class="code">nodes</code>
is a list of eligible
<code class="code">org.jumpmind.symmetric.model.Node</code>
objects. The current data column values and the old data column values
are bound to the script evaluation as Java object representations of the
column data. The columns are bound using the uppercase names of the
columns. Old values are bound to uppercase representations that are
prefixed with 'OLD_'.
</p>

<p>
If you need access to any of the SymmetricDS services, then the instance
of
<code class="code">org.jumpmind.symmetric.ISymmetricEngine</code>
is accessible via the bound
<code class="code">engine</code>
variable.
</p>

<p>
In the following example, the node_id is a combination of STORE_ID and
WORKSTATION_NUMBER, both of which are columns on the table that is being
routed.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-bsh','corp', 'store', 'bsh', 'targetNodes.add(STORE_ID +
"-" + WORKSTATION_NUMBER);', current_timestamp, current_timestamp); </pre><p>
</p>

<p>
The same could also be accomplished by simply returning the node id. The
last line of a bsh script is always the return value.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-bsh','corp', 'store', 'bsh', 'STORE_ID + "-" +
WORKSTATION_NUMBER', current_timestamp, current_timestamp); </pre><p>
</p>

<p>
The following example will synchronize to all nodes if the FLAG column
has changed, otherwise no nodes will be synchronized. Note that here we
make use of OLD_, which provides access to the old column value.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-flag-changed','corp', 'store', 'bsh', 'FLAG != null
&amp;&amp; !FLAG.equals(OLD_FLAG)', current_timestamp,
current_timestamp); </pre><p>
</p>

<p>
The next example shows a script that iterates over each eligible node
and checks to see if the trimmed value of the column named STATION
equals the external_id.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-trimmed-station','corp', 'store', 'bsh', 'for
(org.jumpmind.symmetric.model.Node node : nodes) { if (STATION != null
&amp;&amp; node.getExternalId().equals(STATION.trim())) {
targetNodes.add(node.getNodeId()); } }', current_timestamp,
current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-audit-table-router"></a>4.6.2.6.&nbsp;Audit Table Router</h4></div></div></div>


<p>
This router audits captured data by recording the change in an audit
table that the router creates and keeps up to date (as long as
<code class="code">auto.config.database</code>
is set to true.) The router creates a table named the same as the table
for which data was captured with the suffix of _AUDIT. It will contain
all of the same columns as the original table with the same data types
only each column is nullable with no default values.
</p>

<p>
Three extra "AUDIT" columns are added to the table:
</p><div class="itemizedlist"><ul type="disc"><li>AUDIT_ID - the primary key of the table.</li><li>AUDIT_TIME - the time at which the change occurred.</li><li>AUDIT_EVENT - the DML type that happened to the
row.</li></ul></div><p>
</p>

<p>
The following is an example of an audit router
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type, create_time,
last_update_time) values ('audit_at_corp','corp', 'local', 'audit',
current_timestamp, current_timestamp); </pre><p>
</p>

<p>The audit router captures data for a group link. For the
audit router to work it must be associated with a node_group_link with
an action of type 'R'. The 'R' stands for 'only routes to'. In the above
example, we refer to a 'corp to local' group link. Here, local is a new
node_group created for the audit router. No nodes belong to the 'local'
node_group. If a trigger linked to an audit router fires on the corp
node, a new audit table will be created at the corp node with the new
data inserted.</p>
</div>




<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-routing-external-select"></a>4.6.2.7.&nbsp;Utilizing External Select when Routing</h4></div></div></div>




<p>
There may be times when you wish to route based on a piece of data that
exists in a table other than the one being routed. The approach, first
discussed in
<a href="#configuration-subselect-router" title="4.6.2.4.&nbsp;Subselect Router">Section&nbsp;4.6.2.4, &#8220;Subselect Router&#8221;</a>
, is to utilize an
<code class="literal">external_select</code>
to save away data in
<code class="literal">external_data</code>
, which can then be referenced during routing.
</p>
<p>
Reconsider subselect's Order / OrderLineItem example (found in
<a href="#configuration-subselect-router" title="4.6.2.4.&nbsp;Subselect Router">Section&nbsp;4.6.2.4, &#8220;Subselect Router&#8221;</a>
), where routing for the line item is accomplished by linking to the
"header" Order row. As an alternate way of solving the problem, we will
now use External Select combined with a column match router.
</p>
<p>
In this version of the solution, the STORE_ID is captured from the Order
table in the EXTERNAL_DATA column when the trigger fires. The router is
configured to route based on the captured EXTERNAL_DATA to all nodes
whose external id matches the captured external data.
</p><pre class="programlisting">insert into SYM_TRIGGER
(trigger_id,source_table_name,channel_id,external_select,
last_update_time,create_time) values ('orderlineitem', 'orderlineitem',
'orderlineitem','select STORE_ID from order where
order_id=$(curTriggerValue).$(curColumnPrefix)order_id',
current_timestamp, current_timestamp); insert into SYM_ROUTER
(router_id, source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-ext','corp', 'store', 'column',
'EXTERNAL_DATA=:EXTERNAL_ID', current_timestamp, current_timestamp); </pre><p>
</p>

<p>The following variables can be used with the external select:</p>

<div class="variablelist"><dl><dt><span class="term">
    		<span><strong class="command">$(curTriggerValue)</strong></span>
		</span></dt><dd>
    		<p>
    		  Variable to be replaced with the NEW or OLD column alias provided by the trigger context, which is platform specific.
    		  For insert and update triggers, the NEW alias is used; for delete triggers, the OLD alias is used.
    		  For example, "$(curTriggerValue).COLUMN" becomes ":new.COLUMN" for an insert trigger on Oracle.
    		</p>
		</dd><dt><span class="term">
            <span><strong class="command">$(curColumnPrefix)</strong></span>
        </span></dt><dd>
            <p>
                Variable to be replaced with the NEW_ or OLD_ column prefix for platforms that don't support column aliases.
                This is currently only used by the H2 database.  All other platforms will replace the variable with an empty string.
                For example "$(curColumnPrefix)COLUMN" becomes "NEW_COLUMN" on H2 and "COLUMN" on Oracle.
            </p>
        </dd></dl></div>

<p>The advantage of this approach over the 'subselect'
approach is that it guards against the (somewhat unlikely) possibility
that the master Order table row might have been deleted before routing
has taken place. This external select solution also is a bit more
efficient than the 'subselect' approach, although the triggers produced
do run the extra external_select SQL inline with application database
updates.</p>

</div>

</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="configuration-trigger-router"></a>4.6.3.&nbsp;Trigger / Router Mappings</h3></div></div></div>


<p>
The
<a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
table is used to define which specific combinations of triggers and
routers are needed for your configuration. The relationship between
triggers and routers is many-to-many, so this table serves as the join
table to define which combinations are valid, as well as to define
settings available at the trigger-router level of granularity.
</p>
<p>
Three important controls can be configured for a specific Trigger /
Router combination: Enabled, Initial Loads and Ping Back. The parameters
for these can be found in the Trigger / Router mapping table,
<a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
.
</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-trigger-router-enabled"></a>4.6.3.1.&nbsp;Enable / disable trigger router</h4></div></div></div>


<p>
Each individual trigger-router combination can be disabled or enabled if
needed. By default, a trigger router is enabled, but if you have a
reason you wish to define a trigger router combination prior to it being
active, you can set the
<code class="literal">enabled</code>
flag to 0. This will cause the trigger-router mapping to be sent to all
nodes, but the trigger-router mapping will not be considered active or
enabled for the purposes of capturing data changes or routing.
</p>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-initial-load"></a>4.6.3.2.&nbsp;Initial Loads</h4></div></div></div>



<p>An initial load is the process of seeding tables at a
target node with data from its parent node. When a node connects and
data is extracted, after it is registered and if an initial load was
requested, each table that is configured to synchronize to the target
node group will be given a reload event in the order defined by the end
user. A SQL statement is run against each table to get the data load
that will be streamed to the target node. The selected data is filtered
through the configured router for the table being loaded. If the data
set is going to be large, then SQL criteria can optionally be provided
to pare down the data that is selected out of the database.</p>

<p>
An initial load cannot occur until after a node is registered. An
initial load is requested by setting the
<code class="literal">initial_load_enabled</code>
column on
<a href="#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
to
<span class="emphasis"><em>1</em></span>
on the row for the target node in the parent node's database. You can
configure SymmetricDS to automatically perform an initial load when a
node registers by setting the parameter
<code class="literal">auto.reload</code>
to true. Regardless of how the initial load is initiated, the next time
the source node routes data, reload batches will be inserted. At the
same time reload batches are inserted, all previously pending batches
for the node are marked as successfully sent.
</p>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
<p>
Note that if the parent node that a node is registering with is
<span class="emphasis"><em>not</em></span>
a registration server node (as can happen with a registration redirect
or certain non-tree structure node configurations) the parent node's
<a href="#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
entry must exist at the parent node and have a non-null value for column
<code class="literal">initial_load_time</code>
. Nodes can't be registered to non-registration-server nodes without
this value being set one way or another (i.e., manually, or as a result
of an initial load occurring at the parent node).
</p>
</div>

<p>
SymmetricDS recognizes that an initial load has completed when the
<code class="literal">initial_load_time</code>
column on the target node is set to a non-null value.
</p>

<p>
An initial load is accomplished by inserting reload batches in a defined
order according to the
<code class="literal">initial_load_order</code>
column on
<a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
. If the
<code class="literal">initial_load_order</code>
column contains a negative value the associated table will
<span class="emphasis"><em>NOT</em></span>
be loaded. If the
<code class="literal">initial_load_order</code>
column contains the same value for multiple tables, SymmetricDS will
attempt to order the tables according to foreign key constraints. If
there are cyclical constraints, then foreign keys might need to be
turned off or the initial load will need to be manually configured based
on knowledge of how the data is structured.
</p>

<p>Initial load data is always queried from the source
database table. All data is passed through the configured router to
filter out data that might not be targeted at a node.</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="configuration-initial-load-options"></a>Target table prep for initial load</h5></div></div></div>

<p>There are several parameters that can be used to specify
what, if anything, should be done to the table on the target database
just prior to loading the data. Note that the parameters below specify
the desired behavior for all tables in the initial load, not just one. </p>
<div class="itemizedlist"><ul type="disc"><li>
<code class="literal">initial.load.delete.first /
initial.load.delete.first.sql</code>
<p>
By default, an initial load will not delete existing rows from a target
table before loading the data. If a delete is desired, the parameter
<code class="literal">initial.load.delete.first</code>
can be set to true. If true, the command found in
<code class="literal">initial.load.delete.first.sql</code>
will be run on each table prior to loading the data. The default value
for
<code class="literal">initial.load.delete.first.sql</code>
is
<code class="literal">delete from %s</code>
, but could be changed if needed. Note that additional reload batches
are created, in the correct order, to achieve the delete.
</p>
</li><li>
<code class="literal">initial.load.create.first</code>
<p>
By default, an initial load will not create the table on the target if
it doesn't alleady exist. If the desired behavior is to create the table
on the target if it is not present, set the parameter
<code class="literal">intial.load.create.first</code>
to true. SymmetricDS will attempt to create the table and indexes on the
target database before doing the initial load. (Additional batches are
created to represent the table schema).
</p>
</li></ul></div>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="configuration-initial-load-select"></a>Loading subsets of data</h5></div></div></div>


<p>
An efficient way to select a subset of data from a table for an initial
load is to provide an
<code class="literal">initial_load_select</code>
clause on
<a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
. This clause, if present, is applied as a
<code class="literal">where</code>
clause to the SQL used to select the data to be loaded. The clause may
use "t" as an alias for the table being loaded, if needed. The
<code class="literal">$(externalId)</code>
token can be used for subsetting the data in the where clause.
</p>

<p>
In cases where routing is done using a feature like
<a href="#configuration-subselect-router" title="4.6.2.4.&nbsp;Subselect Router">Section&nbsp;4.6.2.4, &#8220;Subselect Router&#8221;</a>
, an
<code class="literal">initial_load_select</code>
clause matching the subselect's criteria would be a more efficient
approach. Some routers will check to see if the
<code class="literal">initial_load_select</code>
clause is provided, and they will
<span class="emphasis"><em>not</em></span>
execute assuming that the more optimal path is using the
<code class="literal">initial_load_select</code>
statement.
</p>

<p>
One example of the use of an initial load select would be if you wished
to only load data created more recently than the start of year 2011.
Say, for example, the column
<code class="literal">created_time</code>
contains the creation date. Your
<code class="literal">initial_load_select</code>
would read
<code class="literal">created_time &gt; ts {'2011-01-01 00:00:00.0000'}</code>
(using whatever timestamp format works for your database). This then
gets applied as a
<code class="literal">where</code>
clause when selecting data from the table.
</p>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
<p>
When providing an
<code class="literal">initial_load_select</code>
be sure to test out the criteria against production data in a query
browser. Do an explain plan to make sure you are properly using indexes.
</p>
</div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="configuration-initial-load-batches"></a>Splitting an Initial Load for a Table Across Multiple Batches</h5></div></div></div>

<p>
By default, all data for a given table will be initial loaded in a single batch, regardless
of the max batch size parameter on the reload channel.  That is, for a table with one million
rows, all rows for that table will be initial loaded and sent to the destination node in a
single batch. For large tables, this can result in a batch that can take a long time to
extract and load.
</p>

<p>
Initial loads for a table can be broken into multiple batches by specifying
<code class="literal">initial.load.use.extract.job.enabled</code> to true.  This parameter allows
SymmetricDS to pre-extract initial load batches versus having them extracted when
the batch is pulled or pushed.  When using this parameter, there are two ways to tell
SymmetricDS the number of batches to create for a given table.  The first is to specify
a positive integer in the initial_load_batch_count column on
<a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>.  This
number will dictate the number of batches created for the initial load of the given table.
The second way is to specify 0 for initial_load_batch_count on
<a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a> and
specify a max_batch_size on the reload channel in <a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>.
When 0 is specified for
initial_load_batch_count, SymmetricDS will execute a count(*) query on the table during
the extract process and create N batches based on the total number of records found
in the table divided by the max_batch_size on the reload channel.
</p>

</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="configuration-initial-load-reverse"></a>Reverse Initial Loads</h5></div></div></div>

<p>
The default behavior for initial loads is to load data from the
registration server or parent node, to a client node. Occasionally,
there may be need to do a one-time intial load of data in the opposite
or "reverse" direction, namely from a client node to the registration
node. To achieve this, set the parameter
<code class="literal">auto.reload.reverse</code>
to be true,
<span class="emphasis"><em>but only for the specific node group representing
the client nodes</em></span>
. This will cause a onetime reverse load of data, for tables configured
with non-negative initial load orders, to be batched at the point when
registration of the client node is occurring. These batches are then
sent to the parent or registration node. This capability might be
needed, for example, if there is data already present in the client that
doesn't exist in the parent but needs to.
</p>
</div>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-dead-triggers"></a>4.6.3.3.&nbsp;Dead Triggers</h4></div></div></div>


<p>
Occasionally the decision of what data to load initially results in
additional triggers. These triggers, known as
<span class="emphasis"><em>Dead Triggers</em></span>
, are configured such that they do not capture any data changes. A
"dead" Trigger is one that does not capture data changes. In other
words, the
<code class="literal">sync_on_insert</code>
,
<code class="literal">sync_on_update</code>
, and
<code class="literal">sync_on_delete</code>
properties for the Trigger are all set to false. However, since the
Trigger is specified, it
<span class="emphasis"><em>will</em></span>
be included in the initial load of data for target Nodes.
</p>

<p>Why might you need a Dead Trigger? A dead Trigger might be
used to load a read-only lookup table, for example. It could also be
used to load a table that needs populated with example or default data.
Another use is a recovery load of data for tables that have a single
direction of synchronization. For example, a retail store records sales
transactions that synchronize in one direction by trickling back to the
central office. If the retail store needs to recover all the sales
transactions from the central office, they can be sent are part of an
initial load from the central office by setting up dead Triggers that
"sync" in that direction.</p>

<p>
The following SQL statement sets up a non-syncing dead Trigger that
sends the
<code class="literal">sale_transaction</code>
table to the "store" Node Group from the "corp" Node Group during an
initial load.
</p><pre class="programlisting"> insert into sym_trigger
(TRIGGER_ID,SOURCE_CATALOG_NAME,
SOURCE_SCHEMA_NAME,SOURCE_TABLE_NAME,CHANNEL_ID,
SYNC_ON_UPDATE,SYNC_ON_INSERT,SYNC_ON_DELETE,
SYNC_ON_INCOMING_BATCH,NAME_FOR_UPDATE_TRIGGER,
NAME_FOR_INSERT_TRIGGER,NAME_FOR_DELETE_TRIGGER,
SYNC_ON_UPDATE_CONDITION,SYNC_ON_INSERT_CONDITION,
SYNC_ON_DELETE_CONDITION,EXTERNAL_SELECT,
TX_ID_EXPRESSION,EXCLUDED_COLUMN_NAMES,
CREATE_TIME,LAST_UPDATE_BY,LAST_UPDATE_TIME) values
('SALE_TRANSACTION_DEAD',null,null, 'SALE_TRANSACTION','transaction',
0,0,0,0,null,null,null,null,null,null,null,null,null,
current_timestamp,'demo',current_timestamp); insert into sym_router
(ROUTER_ID,TARGET_CATALOG_NAME,TARGET_SCHEMA_NAME,
TARGET_TABLE_NAME,SOURCE_NODE_GROUP_ID,TARGET_NODE_GROUP_ID,ROUTER_TYPE,
ROUTER_EXPRESSION,SYNC_ON_UPDATE,SYNC_ON_INSERT,SYNC_ON_DELETE,
CREATE_TIME,LAST_UPDATE_BY,LAST_UPDATE_TIME) values
('CORP_2_STORE',null,null,null, 'corp','store',null,null,1,1,1,
current_timestamp,'demo',current_timestamp); insert into
sym_trigger_router (TRIGGER_ID,ROUTER_ID,INITIAL_LOAD_ORDER,
INITIAL_LOAD_SELECT,CREATE_TIME,LAST_UPDATE_BY,LAST_UPDATE_TIME) values
('SALE_TRANSACTION_DEAD','CORP_2_REGION',100,null,
current_timestamp,'demo',current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-trigger-router-ping-back"></a>4.6.3.4.&nbsp;Enabling "Ping Back"</h4></div></div></div>


<p>
As discussed in
<a href="#defining-data-changes-trigger-routers-ping-back" title="3.6.3.2.&nbsp;Circular References and &#34;Ping Back&#34;">Section&nbsp;3.6.3.2, &#8220;Circular References and "Ping Back"&#8221;</a>
SymmetricDS, by default, avoids circular data changes. When a trigger
fires as a result of SymmetricDS itself (such as the case when sync on
incoming batch is set), it records the originating source node of the
data change in
<code class="literal">source_node_id</code>
. During routing, if routing results in sending the data back to the
originating source node, the data is not routed by default. If instead
you wish to route the data back to the originating node, you can set the
<code class="literal">ping_back_enabled</code>
column for the needed particular trigger / router combination. This will
cause the router to "ping" the data back to the originating node when it
usually would not.
</p>
</div>
</div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-registration"></a>4.7.&nbsp;Opening Registration</h2></div></div></div>


<p>
Node registration is the act of setting up a new
<a href="#table_node" title="A.17.&nbsp;NODE">NODE</a>
and
<a href="#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
so that when the new node is brought online it is allowed to join the
system. Nodes are only allowed to register if rows exist for the node
and the
<code class="literal">registration_enabled</code>
flag is set to 1. If the
<code class="literal">auto.registration</code>
SymmetricDS property is set to true, then when a node attempts to
register, if registration has not already occurred, the node will
automatically be registered.
</p>

<p>
SymmetricDS allows you to have multiple nodes with the same
<code class="literal">external_id</code>
. Out of the box, openRegistration will open a new registration if a
registration already exists for a node with the same external_id. A new
registration means a new node with a new
<code class="literal">node_id</code>
and the same
<code class="literal">external_id</code>
will be created. If you want to re-register the same node you can use
the
<code class="literal">reOpenRegistration()</code>
JMX method which takes a
<code class="literal">node_id</code>
as an argument.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="transform-data"></a>4.8.&nbsp;Transforming Data</h2></div></div></div>


<p>New as of SymmetricDS 2.4, SymmetricDS is now able to
transform synchronized data by way of configuration (previously, for
most cases a custom data loader would need to have been written). This
transformation can take place on a source node or on a target node, as
the data is being loaded or extracted. With this new feature you can,
for example:</p>

<div class="itemizedlist"><ul type="disc"><li>
<p>Copy a column from a source table to two (or more) target
table columns,</p>
</li><li>
<p>Merge columns from two or more source tables into a single
row in a target table,</p>
</li><li>
<p>Insert constants in columns in target tables based on
source data synchronizations,</p>
</li><li>
<p>Insert multiple rows of data into a single target table
based on one change in a source table,</p>
</li><li>
<p>Apply a Bean Shell script to achieve a custom transform
when loading into the target database.</p>
</li></ul></div>

<p>These transformations can take place either on the target
or on the source, and as data is either being extracted or loaded. In
either case, the transformation is initiated due to existence of a
source synchronization trigger. The source trigger creates the
synchronization data, while the transformation configuration decides
what to do with the synchronization data as it is either being extracted
from the source or loaded into the target. You have the flexibility of
defining different transformation behavior depending on whether the
source change that triggered the synchronization was an Insert, Update,
or Delete. In the case of Delete, you even have options on what exactly
to do on the target side, be it a delete of a row, setting columns to
specific values, or absolutely nothing at all.</p>

<p>A few key concepts are important to keep in mind to
understand how SymmetricDS performs transformations. The first concept
is that of the "source operation" or "source DML type", which is the
type of operation that occurred to generate the synchronization data in
the first place (i.e., an insert, a delete, or an update). Your
transformations can be configured to act differently based on the source
DML type, if desired. When transforming, by default the DML action taken
on the target matches that of the action taken on the row in the source
(although this behavior can be altered through configuration if needed).
If the source DML type is an Insert, for example, the resulting
transformation DML(s) will be Insert(s).</p>

<p>Another important concept is the way in which transforms
are applied. Each source operation may map to one or more transforms and
result in one or more operations on the target tables. Each of these
target operations are performed as independent operations in sequence
and must be "complete" from a SQL perspective. In other words, you must
define columns for the transformation that are sufficient to fill in any
primary key or other required data in the target table if the source
operation was an Insert, for example.</p>

<p>Finally, please note that the transformation engine relies
on a source trigger / router existing to supply the source data for the
transformation. The transform configuration will never be used if the
source table and target node group does not have a defined trigger /
router combination for that source table and target node group.</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="transform-data-tables"></a>4.8.1.&nbsp;Transform Configuration Tables</h3></div></div></div>


<p>
SymmetricDS stores its transformation configuration in two configuration
tables,
<a href="#table_transform_table" title="A.36.&nbsp;TRANSFORM_TABLE">TRANSFORM_TABLE</a>
and
<a href="#table_transform_column" title="A.37.&nbsp;TRANSFORM_COLUMN">TRANSFORM_COLUMN</a>
. Defining a transformation involves configuration in both tables, with
the first table defining which source and destination tables are
involved, and the second defining the columns involved in the
transformation and the behavior of the data for those columns. We will
explain the various options available in both tables and the various
pre-defined transformation types.

</p>

<p>
To define a transformation, you will first define the source table and
target table that applies to a particular transformation. The source and
target tables, along with a unique identifier (the transform_id column)
are defined in
<a href="#table_transform_table" title="A.36.&nbsp;TRANSFORM_TABLE">TRANSFORM_TABLE</a>
. In addition, you will specify the source_node_group_id and
target_node_group_id to which the transform will apply, along with
whether the transform should occur on the Extract step or the Load step
(transform_point). All of these values are required.
</p>

<p>
Three additional configuration settings are also defined at the
source-target table level: the order of the transformations, the
behavior when deleting, and whether an update should always be attempted
first. More specifically,
</p><div class="itemizedlist"><ul type="disc"><li>transform_order: For a single source operation that
is mapped to a transformation, there could be more than one target
operation that takes place. You may control the order in which the
target operations are applied through a configuration parameter defined
for each source-target table combination. This might be important, for
example, if the foreign key relationships on the target tables require
you to execute the transformations in a particular order.</li><li>
column_policy: Indicates whether unspecified columns are passed thru or
if all columns must be explicitly defined. The options include:
<div class="itemizedlist"><ul type="circle"><li>SPECIFIED - Indicates that only the transform
columns that are defined will be the ones that end up as part of the
transformation.</li><li>IMPLIED - Indicates that if not specified, then
columns from the source are passed through to the target. This is useful
if you just want to map a table from one name to anther or from one
schema to another. It is also useful if you want to transform a table,
but also want to pass it through. You would define an implied transform
from the source to the target and would not have to configure each
column.</li></ul></div>
</li><li>
delete_action: When a source operation of Delete takes place, there are
three possible ways to handle the transformation at the target. The
options include:
<div class="itemizedlist"><ul type="circle"><li>NONE - The delete results in no target changes.</li><li>DEL_ROW - The delete results in a delete of the row
as specified by the pk columns defined in the transformation
configuration.</li><li>UPDATE_COL - The delete results in an Update
operation on the target which updates the specific rows and columns
based on the defined transformation.</li></ul></div>
</li><li>
update_first: This option overrides the default behavior for an Insert
operation. Instead of attempting the Insert first, SymmetricDS will
always perform an Update first and then fall back to an Insert if that
fails. Note that, by default, fall back logic
<span class="emphasis"><em>always</em></span>
applies for Insert and Updates. Here, all you a specifying is whether to
always do an Update first, which can have performance benefits under
certain situations you may run into.
</li></ul></div><p>
</p>

<p>
For each transformation defined in
<a href="#table_transform_table" title="A.36.&nbsp;TRANSFORM_TABLE">TRANSFORM_TABLE</a>
, the columns to be transformed (and how they are transformed) are
defined in
<a href="#table_transform_column" title="A.37.&nbsp;TRANSFORM_COLUMN">TRANSFORM_COLUMN</a>
. This column-level table typically has several rows for each
transformation id, each of which defines the source column name, the
target column name, as well as the following details:
</p><div class="itemizedlist"><ul type="disc"><li>include_on: Defines whether this entry applies to
source operations of Insert (I), Update (U), or Delete (D), or any
source operation.</li><li>pk: Indicates that this mapping is used to define
the "primary key" for identifying the target row(s) (which may or may
not be the true primary key of the target table). This is used to define
the "where" clause when an Update or Delete on the target is occurring.
At least one row marked as a pk should be present for each transform_id.</li><li>transform_type, transform_expression: Specifies how
the data is modified, if at all. The available transform types are
discussed below, and the default is 'copy', which just copies the data
from source to target.</li><li>transform_order: In the event there are more than
one columns to transform, this defines the relative order in which the
transformations are applied.</li></ul></div><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="transform-data-types"></a>4.8.2.&nbsp;Transformation Types</h3></div></div></div>


<p>
There are several pre-defined transform types available in SymmetricDS.
Additional ones can be defined by creating and configuring an extension
point which implements the
<code class="code">IColumnTransform</code>
interface. The pre-defined transform types include the following (the
transform_type entry is shown in parentheses):
</p><div class="itemizedlist"><ul type="disc"><li>Copy Column Transform ('copy'): This transformation
type copies the source column value to the target column. This is the
default behavior.</li><li>Remove Column Transform ('remove'): This
transformation type removes the source column. This transform type is
only valid for a table transformation type of 'IMPLIED' where all the
columns from the source are automatically copied to the target.</li><li>Constant Transform ('const'): This transformation
type allows you to map a constant value to the given target column. The
constant itself is placed in transform_expression.</li><li>
Variable Transform ('variable'): This transformation type allows you to
map a built-in dynamic variable to the given target column. The variable
name is placed in transform_expression. The following variables are
available:
<code class="code">system_date</code>
is the current system date,
<code class="code">system_timestamp</code>
is the current system date and time,
<code class="code">source_node_id</code>
is the node id of the source,
<code class="code">target_node_id</code>
is the node id of the target,
<code class="code">null</code>
is a null value, and <code class="code">old_column_value</code> is the column's old value prior to the DML operation.
</li><li>Additive Transform ('additive'): This
transformation type is used for numeric data. It computes the change
between the old and new values on the source and then adds the change to
the existing value in the target column. That is, target = target +
multiplier (source_new - source_old), where multiplier is a constant
found in the transform_expression (default is 1 if not specified). For
example, if the source column changed from a 2 to a 4, the target column
is currently 10, and the multiplier is 3, the effect of the transform
will be to change the target column to a value of 16 ( 10+3*(4-2) =&gt;
16 ). Note that, in the case of deletes, the new column value is
considered 0 for the purposes of the calculation.</li><li>
Substring Transform ('substr'): This transformation computes a substring
of the source column data and uses the substring as the target column
value. The transform_expression can be a single integer (
<code class="code">n</code>
, the beginning index), or a pair of comma-separated integers (
<code class="code">n,m</code>
- the beginning and ending index). The transform behaves as the Java
substring function would using the specified values in
transform_expression.
</li><li>Multiplier Transform ('multiply'): This
transformation allows for the creation of multiple rows in the target
table based on the transform_expression. This transform type can only be
used on a primary key column. The transform_expression is a SQL
statement that returns the list to be used to create the multiple
targets.</li><li>Lookup Transform ('lookup'): This transformation
determines the target column value by using a query, contained in
transform_expression to lookup the value in another table. The query
must return a single row, and the first column of the query is used as
the value. Your query references source column names by prefixing with a
colon (e.g., :MY_COLUMN).</li><li>
Shell Script Transform ('bsh'): This transformation allows you to
provide a Bean Shell script in transform_expression and executes the
script at the time of transformation. Some variables are provided to the
script:
<code class="code">COLUMN_NAME</code>
is a variable for a source column in the row, where the variable name is
the column name in uppercase;
<code class="code">currentValue</code>
is the value of the current source column;
<code class="code">oldValue</code>
is the old value of the source column for an updated row;
<code class="code">sqlTemplate</code>
is a
<code class="code">org.jumpmind.db.sql.ISqlTemplate</code>
object for querying or updating the database;
<code class="code">channelId</code>
is a reference to the channel on which the transformation is happening;
<code class="code">sourceNode</code>
is a
<code class="code">org.jumpmind.symmetric.model.Node</code>
object that represents the node from where the data came;
<code class="code">targetNode</code>
is a
<code class="code">org.jumpmind.symmetric.model.Node</code>
object that represents the node where the data is being loaded.
</li><li>Identity Transform ('identity'): This
transformation allows you to insert into an identity column by computing
a new identity, not copying the actual identity value from the source.
</li><li>
Mathematical Transform ('math'): This transformation allows you to 
perform mathematical equations in the transform expression. Some 
variables are provided to the script:
<code class="code">#{COLUMN_NAME}</code>
is a variable for a source column in the row, where the variable name
is the column name in uppercase;
<code class="code">#{currentValue}</code>
is the value of the current source column;
<code class="code">#{oldValue}</code>
is the old value of the source column for an updated row.
</li><li>
Copy If Changed Transform ('copyIfChanged'):  This transformation will copy the value to the target column if the source value has changed.  More
specifically, the copy will occur if the the old value of the source does not equal the new value.  If the old and new are, in fact, equal, then either
the column will be ignored or the row will be ignored, based on the setting of the transform expression.  If the transform expression is euqal
to the string 'IgnoreColumn', the column will be ignored; otherwise, the row will be ignored.
</li><li>
Value Map Transform ('valueMap'):  This transformation allows for simple value substitutions through use of the transform expression.
The transform expresion should consist of a space separated list of value pairs of the format sourceValue=TargetValue.  The column value is used to 
locate the correct sourceValue, and the transform will change the value into the corresponding targetValue.  A sourceValue of * can be used to
represent a default target value in the event that the sourceValue is not found.  Otherwise, if no default value is found,
the result will be null.  For example, consider the following transform expression:  s1=t1 s2=t2 s3=t3 *=t4.  A source value of
s1 will be transformed to t1, s2 to t2, s3 to t3, s4 to t4, s5 to t4, null to t4, etc.
</li></ul></div><p>
</p>
</div>


</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="data-load-filter"></a>4.9.&nbsp;Data Load Filters</h2></div></div></div>


<p>
New as of SymmetricDS 3.1, SymmetricDS is now capable of taking actions
upon the load of certain data via configurable load filters. This new
configurable option is in additon to the already existing option of
writing a class that implements
<a href="#extensions-data-loader-filter" title="5.10.2.&nbsp;IDatabaseWriterFilter">IDatabaseWriterFilter</a>
. A configurable load filter watches for specific data that is being
loaded and then takes action based on the load of that data.
</p>

<p>Specifying which data to action is done by specifying a
souce and target node group (data extracted from this node group, and
loaded into that node group), and a target catalog, schema and table
name. You can decide to take action on rows that are inserted, updated
and/or deleted, and can also further delineate which rows of the target
table to take action on by specifying additional criteria in the bean
shell script that is executed in response to the loaded data. As an
example, old and new values for the row of data being loaded are
available in the bean shell script, so you can action rows with a
certain column value in old or new data.</p>

<p>The action taken is based on a bean shell script that you
can provide as part of the configuration. Actions can be taken at
different points in the load process including before write, after
write, at batch complete, at batch commit and/or at batch rollback.</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="data-load-filter-config"></a>4.9.1.&nbsp;Load Filter Configuration Table</h3></div></div></div>


<p>
SymmetricDS stores its load filter configuration in a single table
called
<a href="#table_load_filter" title="A.15.&nbsp;LOAD_FILTER">LOAD_FILTER</a>
. The load filter table allows you to specify the following:
</p><div class="itemizedlist"><ul type="disc"><li>Load Filter Type ('load_filter_type'): The type of
load filter. Today only Bean Shell is supported ('BSH'), but SQL scripts
may be added in a future release.</li><li>Source Node Group ('source_node_group_id'): The
source node group for which you would like to watch for changes.</li><li>Target Node Group ('target_node_group_id'): The
target node group for which you would like to watch for changes. The
source and target not groups are used together to identify the node
group link for which you would like to watch for changes (i.e. When the
Server node group sends data to a Client node group).</li><li>Target Catalog ('target_catalog_name'): The name of
the target catalog for which you would like to watch for changes.</li><li>Target Schema ('target_schema_name'): The name of
the target schema for which you would like to watch for changes.</li><li>Target Table ('target_table_name'): The name of the
target table for which you would like to watch for changes. The target
catalog, target schema and target table name are used together to fully
qualify the table for which you would like to watch for changes.</li><li>Filter on Update ('filter_on_update'): Determines
whether the load filter takes action (executes) on a database update
statement.</li><li>Filter on Insert ('filter_on_insert'): Determines
whether the load filter takes action (executes) on a database insert
statement.</li><li>Filter on Delete ('filter_on_delete'): Determines
whether the load filter takes action (executes) on a database delete
statement.</li><li>Before Write Script ('before_write_script'): The
script to execute before the database write occurs.</li><li>After Write Script ('after_write_script'): The
script to execute after the database write occurs.</li><li>Batch Complete Script ('batch_complete_script'):
The script to execute after the entire batch completes.</li><li>Batch Commit Script ('batch_commit_script'): The
script to execute after the entire batch is committed.</li><li>Batch Rollback Script ('batch_rollback_script'):
The script to execute if the batch rolls back.</li><li>Handle Error Script ('handle_error_script'): A
script to execute if data cannot be processed.</li><li>Load Filter Order ('load_filter_order'): The order
in which load filters should execute if there are multiple scripts
pertaining to the same source and target data.</li></ul></div><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="data-load-filter-variables"></a>4.9.2.&nbsp;Variables available to Data Load Filters</h3></div></div></div>


<p>
As part of the bean shell load filters, SymmetricDS provides certain
variables for use in the bean shell script. Those variables include:
</p><div class="itemizedlist"><ul type="disc"><li>Symmetric Engine ('ENGINE'): The Symmetric engine
object.</li><li>Source Values ('&lt;COLUMN_NAME&gt;'): The source
values for the row being inserted, updated or deleted.</li><li>Old Values ('OLD_&lt;COLUMN_NAME&gt;'): The old
values for the row being inserted, updated or deleted.</li><li>Data Context ('CONTEXT'): The data context object
for the data being inserted, updated or deleted. .</li><li>Table Data ('TABLE'): The table object for the
table being inserted, updated or deleted.</li></ul></div><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="data-load-filter-examples"></a>4.9.3.&nbsp;Data Load Filter Example</h3></div></div></div>


<p>
The following is an example of a load filter that watches a table named
TABLE_TO_WATCH being loaded from the Server Node Group to the Client
Node Group for inserts or updates, and performs an initial load on a
table named "TABLE_TO_RELOAD" for KEY_FIELD on the reload table equal to
a column named KEY_FIELD on the TABLE_TO_WATCH table.
</p><pre class="programlisting"> insert into sym_load_filter
(LOAD_FILTER_ID, LOAD_FILTER_TYPE, SOURCE_NODE_GROUP_ID,
TARGET_NODE_GROUP_ID, TARGET_CATALOG_NAME, TARGET_SCHEMA_NAME,
TARGET_TABLE_NAME, FILTER_ON_UPDATE, FILTER_ON_INSERT, FILTER_ON_DELETE,
BEFORE_WRITE_SCRIPT, AFTER_WRITE_SCRIPT, BATCH_COMPLETE_SCRIPT,
BATCH_COMMIT_SCRIPT, BATCH_ROLLBACK_SCRIPT, HANDLE_ERROR_SCRIPT,
CREATE_TIME, LAST_UPDATE_BY, LAST_UPDATE_TIME, LOAD_FILTER_ORDER,
FAIL_ON_ERROR) values
('TABLE_TO_RELOAD','BSH','Client','Server',NULL,NULL,
'TABLE_TO_WATCH',1,1,0,null,
'engine.getDataService().reloadTable(context.getBatch().getSourceNodeId(),
table.getCatalog(), table.getSchema(), "TABLE_TO_RELOAD","KEY_FIELD=''"
+ KEY_FIELD + "''");'
,null,null,null,null,sysdate,'userid',sysdate,1,1); </pre><p>
</p>
</div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="conflicts"></a>4.10.&nbsp;Conflict Detection and Resolution</h2></div></div></div>
    
    <p> Conflict detection and resolution is new as of SymmetricDS 3.0. Conflict detection is the act of determining if an
        insert, update or delete is in "conflict" due to the target data row not being consistent with the data at the source
        prior to the insert/update/delete. Conflict resolution is the act of figuring out what to do when a conflict is
        detected.
    </p>
    <p>
        Conflict detection and resolution strategies are configured in the
        <a href="#table_conflict" title="A.2.&nbsp;CONFLICT">CONFLICT</a>
        table. They are configured at minimum for a specific
        <a href="#table_node_group_link" title="A.22.&nbsp;NODE_GROUP_LINK">NODE_GROUP_LINK</a>
        . The configuration can also be specific to a
        <a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
        and/or table.
    </p>
    <p>
        Conflict detection is configured in the
        <code class="literal">detect_type</code>
        and
        <code class="literal">detect_expression</code>
        columns of
        <a href="#table_conflict" title="A.2.&nbsp;CONFLICT">CONFLICT</a>
        . The value for
        <code class="literal">detect_expression</code>
        depends on the
        <code class="literal">detect_type</code>
        . Conflicts are detected while data is being loaded into a target system.
        </p><div class="variablelist"><dl><dt><span class="term">
                    <span><strong class="command">USE_PK_DATA</strong></span>
                </span></dt><dd>
                    <p>Indicates that only the primary key is used to detect a conflict. If a row exists with the same
                        primary key, then no conflict is detected during an update or a delete. Updates and deletes rows are
                        resolved using only the primary key columns. If a row already exists during an insert then a conflict
                        has been detected.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">USE_OLD_DATA</strong></span>
                </span></dt><dd>
                    <p>Indicates that all of the old data values are used to detect a conflict. Old data is the data
                        values of the row on the source system prior to the change. If a row exists with the same old values
                        on the target system as they were on the source system, then no conflict is detected during an update
                        or a delete. If a row already exists during an insert then a conflict has been detected.
                    </p>
                    <p>Note that some platforms do not support comparisons of binary columns. Conflicts in binary column
                    values will not be detected on the following platforms: DB2, DERBY, ORACLE, and SQLSERVER.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">USE_CHANGED_DATA</strong></span>
                </span></dt><dd>
                    <p>Indicates that the primary key plus any data that has changed on the source system will be used to
                        detect a conflict. If a row exists with the same old values on the target system as they were on the
                        source system for the columns that have changed on the source system, then no conflict is detected
                        during an update or a delete. If a row already exists during an insert then a conflict has been
                        detected.
                    </p>
                    <p>Note that some platforms do not support comparisons of binary columns. Conflicts in binary column
                    values will not be detected on the following platforms: DB2, DERBY, ORACLE, and SQLSERVER.
                    </p>
                    <p>The detect_expression can be used to exclude certain column names from being used.  In order to 
                    exclude column1 and column2, the expression would
                    be: <code class="literal">excluded_column_names=column1,column2</code> 
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">USE_TIMESTAMP</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that the primary key plus a timestamp column (as configured in
                        <code class="literal">detect_expression</code>
                        ) will indicate whether a conflict has occurred. If the target timestamp column is not equal to the
                        old source timestamp column, then a conflict has been detected. If a row already exists during an
                        insert then a conflict has been detected.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">USE_VERSION</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that the primary key plus a version column (as configured in
                        <code class="literal">detect_expression</code>
                        ) will indicate whether a conflict has occurred. If the target version column is not equal to the old
                        source version column, then a conflict has been detected. If a row already exists during an insert
                        then a conflict has been detected.
                    </p>
                </dd></dl></div><p>
    </p>
          <div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
            <p>Be aware that conflict detection will <span class="emphasis"><em>not</em></span> detect changes to binary columns in
            the case where <code class="literal">use_stream_lobs</code> is true in the trigger for the table.  In addition, some
            databases do not allow comparisons of binary columns whether <code class="literal">use_stream_lobs</code> is true or not. 
           </p>
      </div>
      
    <p>
        The choice of how to resolve a detected conflict is configured via the <code class="literal">resolve_type</code> column. Depending on the setting, two additional boolean settings
        may also be configured, namely <code class="literal">resolve_row_only</code> and <code class="literal">resolve_changes_only</code>, as discussed in the resolution settings below.
        </p><div class="variablelist"><dl><dt><span class="term">
                    <span><strong class="command">FALLBACK</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that when a conflict is detected the system should automatically apply the changes anyways.
                        If the source operation was an insert, then an update will be attempted. If the source operation was
                        an update and the row does not exist, then an insert will be attempted. If the source operation was a
                        delete and the row does not exist, then the delete will be ignored. The
                        <code class="literal">resolve_changes_only</code>
                        flag controls whether all columns will be updated or only columns that have changed will be updated
                        during a fallback operation.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">IGNORE</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that when a conflict is detected the system should automatically ignore the incoming
                        change. The
                        <code class="literal">resolve_row_only</code>
                        column controls whether the entire batch should be ignore or just the row in conflict.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command"><a name="conflict-resolution-manual"></a>MANUAL</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that when a conflict is detected the batch will remain in error until manual intervention
                        occurs. A row in error is inserted into the
                        <a href="#table_incoming_error" title="A.14.&nbsp;INCOMING_ERROR">INCOMING_ERROR</a>
                        table.  The conflict detection id that detected the conflict is recorded (i.e., the <code class="literal">conflict_id</code> value from 
                          <a href="#table_conflict" title="A.2.&nbsp;CONFLICT">CONFLICT</a>), along with the old data, new data, and the "current data" 
                          (by current data, we mean the unexpected data at the target which doesn't match the old data as expected)
                            in columns <code class="literal">old_data, new_data,</code> and <code class="literal">cur_data</code>. 
                        In order to resolve, the
                        <code class="literal">resolve_data</code>
                        column can be manually filled out which will be used on the next load attempt instead of the original
                        source data. The
                        <code class="literal">resolve_ignore</code>
                        flag can also be used to indicate that the row should be ignored on the next load attempt.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">NEWER_WINS</strong></span>
                </span></dt><dd>
                    <p>Indicates that when a conflict is detected by USE_TIMESTAMP or USE_VERSION that the either the
                        source or the target will win based on the which side has the newer timestamp or higher version
                        number.  The
                        <code class="literal">resolve_row_only</code>
                        column controls whether the entire batch should be ignore or just the row in conflict.
                    </p>
                </dd></dl></div><p>
    </p>
     <p>
        For each configured conflict, you also have the ability to control if and how much "resolved" data is sent back to the node who's data change is in conflict.  This "ping back" behavior
        is specified by the setting of the <code class="literal">ping_back</code>
        column and can be one of the following values:
        </p><div class="variablelist"><dl><dt><span class="term">
                    <span><strong class="command">OFF</strong></span>
                </span></dt><dd>
                    <p>
                       No data is sent back to the originating node, even if the resolved data doesn't match the data the node sent.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">SINGLE_ROW</strong></span>
                </span></dt><dd>
                    <p>
                       The resolved data of the single row in the batch that caused the conflict is sent back to the originating node.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">REMAINING_ROWS.</strong></span>
                </span></dt><dd>
                    <p>
                       The resolved data of the single row in the batch in conflict, along with the entire remainder of the batch, is sent back to the originating node.
                    </p>
                </dd></dl></div><p>
        </p>
           
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="file-sync"></a>4.11.&nbsp;File Synchronization</h2></div></div></div>
           

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="filesync-overview"></a>4.11.1.&nbsp;Overview</h3></div></div></div>


<p> SymmetricDS not only supports the synchronization of
database tables, but it also supports the synchronization of files and folders 
from one node to another. </p>
<p>
File synchronization features include:

</p><div class="itemizedlist"><ul type="disc"><li> Monitoring one or more file system directory locations for file and folder changes </li><li> Support synchronizing a different target directory than the source directory</li><li> Use of wild card expressions to &#8220;include&#8221; or
&#8220;exclude&#8221; files </li><li> Choice of whether to recurse into subfolders
of monitored directories </li><li> Use of existing SymmetricDS routers to subset
target nodes based on file and directory metadata </li><li> Ability to specify if files will be synchronized on
creation, or deletion, and/or modification </li><li> Ability to specify the frequency with which file systems are
monitored for changes </li><li> Ability to extend file synchronization through
scripts that run before or after a file is copied to its source location
</li><li> Support for bidirectional file synchronization </li></ul></div><p>
</p>
<p> Like database synchronization, file synchronization is
configured in a series of database tables. The configuration was
designed to be similar to database synchronization in order to maintain
consistency and to give database synchronization users a sense of
familiarity. </p>
<p>For database synchronization, SymmetricDS uses
<a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a> to configure which tables will capture data for synchronization
and <a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a> to designate which nodes will be the source of data changes
and which nodes will receive the data changes.
<a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a> links triggers to routers. </p>
<p> Likewise, for file synchronization, SymmetricDS uses <a href="#table_file_trigger" title="A.9.&nbsp;FILE_TRIGGER">FILE_TRIGGER</a> to designate which base directories will be monitored.
Each entry in <a href="#table_file_trigger" title="A.9.&nbsp;FILE_TRIGGER">FILE_TRIGGER</a> designates one base directory to monitor for changes on
the source system. The columns on <a href="#table_file_trigger" title="A.9.&nbsp;FILE_TRIGGER">FILE_TRIGGER</a> provide additional
settings for choosing specific files in the base directory that will be monitored, and whether to recurse into subdirectories, etc.  File triggers are linked to routers by
<a href="#table_file_trigger_router" title="A.10.&nbsp;FILE_TRIGGER_ROUTER">FILE_TRIGGER_ROUTER</a>. The file trigger router not only links the source
and the target node groups, but it also optionally provides the ability to
override the base directory name at the target. <a href="#table_file_trigger_router" title="A.10.&nbsp;FILE_TRIGGER_ROUTER">FILE_TRIGGER_ROUTER</a> also
provides a flag that indicates if the target node should be seeded with
the files from the source node during SymmetricDS's initial load
process. </p>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="filesync-operation"></a>4.11.2.&nbsp;Operation</h3></div></div></div>

<p> Not only is file synchronization configured similar to database synchronization, but it also operates in a very similar way. The file system is monitored for changes via a
background job that tracks the file system changes
(this parallels the use of triggers to monitor for changes when synchronizing database changes).
When a change is detected it is written to the <a href="#table_file_snapshot" title="A.8.&nbsp;FILE_SNAPSHOT">FILE_SNAPSHOT</a>
table. The file snapshot table represents the most recent known state of the
monitored files. The file snapshot table has a SymmetricDS database trigger automatically installed
on it so that when it is updated the changes are captured by SymmetricDS on an internal
channel named <code class="literal">filesync</code>. </p>
<p> The changes to <a href="#table_file_snapshot" title="A.8.&nbsp;FILE_SNAPSHOT">FILE_SNAPSHOT</a> are then routed and batched by a file-synchronization-specific router
that delegates to the configured router
based on the <a href="#table_file_trigger_router" title="A.10.&nbsp;FILE_TRIGGER_ROUTER">FILE_TRIGGER_ROUTER</a> configuration. The
 file sync router can
make routing decisions based on the column data of the snapshot table, columns which contain attributes of the file like the name, path,
size, and last modified time. Both old and new file snapshot data are also
available. The router can, for example, parse the path or name of the
file and use it as the node id to route to. </p>
<p> Batches of file snapshot changes are stored on the
<code class="literal">filesync</code> channel in <a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>. The existing SymmetricDS pull and
push jobs ignore the <code class="literal">filesync</code> channel. Instead, they are processed by
file-synchronization-specific push and pull jobs. </p>
<p> When transferring data, the file sync push and pull jobs build a zip
file dynamically based on the batched snapshot data. The
zip file contains a directory per batch. The directory name is the
<code class="literal">batch_id</code>. A <code class="literal">sync.bsh</code> Bean Shell
script is generated and placed in the root of each batch directory. The Bean Shell script contains the commands to copy
or delete files at their file destination from an extracted zip in the staging directory on the
target node. The zip file is downloaded in the
case of a pull, or, in the case of a push, is uploaded as an HTTP multi-part attachment.
Outgoing zip files are written and transferred from the
outgoing staging directory. Incoming zip files are staged in the
<code class="literal">filesync_incoming</code> staging directory by source node id. The
<code class="literal">filesync_incoming/{node_id}</code> staging directory is cleared out before each
subsequent delivery of files. </p>
<p> The acknowledgement of a batch happens the same way it is acknowledged in database synchronization. The client responds with an acknowledgement as part of the response
during a file push or pull. </p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="filesync-beanshell"></a>4.11.3.&nbsp;File Sync Bean Shell Scripts</h3></div></div></div>

<p> There are two types of Bean Shell scripts that can be
leveraged to customize file synchronization behavior: <code class="literal">before_copy_script</code>
and <code class="literal">after_copy_script</code>. </p>
<p>
Each of these scripts have access to local variables that can be read or
set to affect the behavior of copying files.

</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">targetBaseDir</strong></span>
</span></dt><dd>
<p> The preset base directory as configured in <a href="#table_file_trigger" title="A.9.&nbsp;FILE_TRIGGER">FILE_TRIGGER</a> or
overwritten in <a href="#table_file_trigger_router" title="A.10.&nbsp;FILE_TRIGGER_ROUTER">FILE_TRIGGER_ROUTER</a>. This variable can be set by the
<code class="literal">before_copy_script</code> to set a different target directory. </p>
</dd><dt><span class="term">
<span><strong class="command">targetFileName</strong></span>
</span></dt><dd>
<p> The name of the file that is being synchronized. This variable can be overwritten by the
<code class="literal">before_copy_script</code> to rename a file at the target. </p>
</dd><dt><span class="term">
<span><strong class="command">targetRelativeDir</strong></span>
</span></dt><dd>
<p> The name of a directory relative to the target base directory to which the target file will be copied.  The 
default value of this variable is the relative directory of the source.  For example, if the source base directory is 
<code class="literal">/src</code> and the target base directory is <code class="literal">/tgt</code> and the file <code class="literal">/src/subfolder/1.txt</code>
is changed, then the default targetRelativeDir will be <code class="literal">subfolder</code>.
This variable can be overwritten by the
<code class="literal">before_copy_script</code> to change the relative directory at the target. In the above example, if the variable is
set to blank using the following script, then the target file will be copied to <code class="literal">/tgt/1.txt</code>.
</p><pre class="programlisting">
targetRelativeDir = "";
</pre><p>
</p>
</dd><dt><span class="term">
<span><strong class="command">processFile</strong></span>
</span></dt><dd>
<p>This is a variable that is set to true by default. A custom
<code class="literal">before_copy_script</code> may process the file itself and set this variable to
false to indicate that the file should NOT be copied to its target
location. </p>
</dd><dt><span class="term">
<span><strong class="command">sourceFileName</strong></span>
</span></dt><dd>
<p>This is the name of the file.</p>
</dd><dt><span class="term">
<span><strong class="command">sourceFilePath</strong></span>
</span></dt><dd>
<p>This is the path where the file can be found relative to
the batch directory.</p>
</dd><dt><span class="term">
<span><strong class="command">batchDir</strong></span>
</span></dt><dd>
<p>This is the staging directory where the batch has been
extracted. The batchDir + sourceFilePath + sourceFileName can be used to
locate the extracted file. </p>
</dd><dt><span class="term">
<span><strong class="command">engine</strong></span>
</span></dt><dd>
<p>This is the bound instance of the ISymmetricEngine that is
processing a file. It gives access to all of the APIs available in
SymmetricDS. </p>
</dd><dt><span class="term">
<span><strong class="command">sourceNodeId </strong></span>
</span></dt><dd>
<p>This is a bound variable that represents the nodeId that is
the source of the file.</p>
</dd><dt><span class="term">
<span><strong class="command">log</strong></span>
</span></dt><dd>
<p>This is the bound instance of an <code class="literal">org.slf4j.Logger</code> that can
be used to log to the SymmetricDS log file.</p>
</dd></dl></div><p>

</p>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="filesync-examples"></a>4.11.4.&nbsp;File Sync Examples</h3></div></div></div>


<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="filesync-example-1"></a>4.11.4.1.&nbsp;Sync Text Files From Server To Client</h4></div></div></div>

<p>
The following example is for a configuration with client and server node
groups. Creation, modification, and deletion of files with the extension
of <code class="literal">txt</code> will be captured recursively
in the <code class="literal">/filesync/server/all</code>
directory. A before copy script will set the targetBaseDir to
<code class="literal">/filesync/clients/{externalId}</code>.

</p><pre class="programlisting">INSERT INTO sym_file_trigger
  (trigger_id,base_dir,recurse,includes_files,excludes_files,sync_on_create,
   sync_on_modified,sync_on_delete,before_copy_script,after_copy_script,
   create_time,last_update_by,last_update_time)
VALUES ('sync_directory','/filesync/server/all',1,'*.txt',null,1,1,1,
  'targetBaseDir = "/filesync/clients/" +
  engine.getParameterService().getExternalId();',null,current_timestamp,'example',
  current_timestamp);

INSERT INTO sym_file_trigger_router
 (trigger_id,router_id,enabled,initial_load_enabled,target_base_dir,
  conflict_strategy,create_time,last_update_by,last_update_time)
VALUES
  ('sync_directory','server_2_client',1,1,'','SOURCE_WINS',current_timestamp,
  'example',current_timestamp);

INSERT INTO sym_router
  (router_id,target_catalog_name,target_schema_name,target_table_name,
  source_node_group_id,target_node_group_id,
  router_type,router_expression,sync_on_update,sync_on_insert,sync_on_delete,
  create_time,last_update_by,last_update_time)
VALUES
  ('server_2_client',null,null,null,'server','client','default',null,1,1,1,
   current_timestamp,'example',current_timestamp);
</pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="filesync-example-2"></a>4.11.4.2.&nbsp;Route changes to a specific node based on a directory
name</h4></div></div></div>

<p>
The following example is also for a configuration with client and server
node groups. This example monitors the <code class="literal">/filesync/server/nodes</code> directory.
It expects the directory to contain subdirectories that are named by the node_ids
in the client group. Any files put directly into a folder with the name
of the node will be routed to that node.
</p>
<p>
Note that the router is a <a href="#configuration-column-match-router" title="4.6.2.2.&nbsp;Column Match Router">Section&nbsp;4.6.2.2, &#8220;Column Match Router&#8221;</a> that is matching the client node_id with the value of the RELATIVE_DIR column in
<a href="#table_file_snapshot" title="A.8.&nbsp;FILE_SNAPSHOT">FILE_SNAPSHOT</a>.  Because the router is looking for an exact match any files in subdirectories would result in a path
of node_id/subdir which would not match.
</p><pre class="programlisting">

INSERT INTO sym_file_trigger
  (trigger_id,base_dir,recurse,includes_files,excludes_files,sync_on_create,
  sync_on_modified,sync_on_delete,before_copy_script,after_copy_script,create_time,
  last_update_by,last_update_time)
VALUES
  ('node_specific','/filesync/server/nodes',1,null,null,1,1,1,'',null,
  current_timestamp,'example',current_timestamp);

INSERT INTO sym_file_trigger_router
  (trigger_id,router_id,enabled,initial_load_enabled,target_base_dir,
  conflict_strategy,create_time,last_update_by,last_update_time)
VALUES
  ('node_specific','router_files_to_node',1,1,'/filesync/clients','SOURCE_WINS',
  current_timestamp,'example',current_timestamp);

INSERT INTO sym_router
  (router_id,target_catalog_name,target_schema_name,target_table_name,
   source_node_group_id,target_node_group_id,router_type,router_expression,
   sync_on_update,sync_on_insert,sync_on_delete,create_time,last_update_by,
   last_update_time)
VALUES
  ('router_files_to_node',null,null,null,'server','client','column',
  'RELATIVE_DIR = :NODE_ID ',1,1,1,current_timestamp,'example', current_timestamp);

</pre><p>
</p>
</div>
</div>



</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="jobs"></a>4.12.&nbsp;Jobs</h2></div></div></div>

<p>
Work done by SymmetricDS is initiated by jobs. Jobs are tasks that are
started and scheduled by a job manager. Jobs are enabled by the
<code class="literal">start.{name}.job</code>
property. Most jobs are enabled by default. The frequency at which a job
runs in controlled by one of two properties:
<code class="literal">job.{name}.period.time.ms</code>
or
<code class="literal">job.{name}.cron</code>
. If a valid cron property exists in the configuration, then it will be
used to schedule the job. Otherwise, the job manager will attempt to use
the period.time.ms property.
</p>
<p>
The frequency of jobs can be configured in either the engines properties
file or in
<a href="#table_parameter" title="A.30.&nbsp;PARAMETER">PARAMETER</a>
. When managed in
<a href="#table_parameter" title="A.30.&nbsp;PARAMETER">PARAMETER</a>
the frequency properties can be changed in the registration server and
when the updated settings sync to the nodes in the system the job
manager will restart the jobs at the new frequency settings.
</p>
<p>
SymmetricDS utilizes Spring's CRON support, which includes seconds as
the first parameter. This differs from the typical Unix-based
implementation, where the first parameter is usually minutes. For
example,
<code class="literal">*/15 * * * * *</code>
means every 15 seconds, not every 15 minutes. See
<a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://static.springsource.org/spring/docs/3.0.x/javadoc-api/org/springframework/scheduling/support/CronSequenceGenerator.html" target="_top">Spring's
documentation</a>
for more details.
</p>
<p>
Some jobs cannot be run in parallel against a single node. When running
on a cluster these jobs use the
<a href="#table_lock" title="A.16.&nbsp;LOCK">LOCK</a>
table to get an exclusive semaphore to run the job. In order to use this
table the
<code class="literal">cluster.lock.enabled</code>
must be set to true.
</p>
<p> The three main jobs in SymmetricDS are the route, push and
pull jobs. The route job decides what captured data changes should be
sent to which nodes. It also decides what captured data changes should
be transported and loaded together in a batch. The push and pull jobs
are responsible for initiating HTTP communication with linked nodes to
push or pull data changes that have been routed. </p>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="routing-job"></a>4.12.1.&nbsp;Route Job</h3></div></div></div>

<p>
After data is captured in the
<a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
table, it is routed to specific nodes in batches by the
<span class="emphasis"><em>Route Job</em></span>
. It is a single background task that inserts into
<a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
and
<a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
.
</p>
<p>
The job processes each enabled channel, one at a time, collecting a list
of data ids from
<a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
which have not been routed (see
<a href="#data-gaps" title="4.12.1.1.&nbsp;Data Gaps">Section&nbsp;4.12.1.1, &#8220;Data Gaps&#8221;</a>
for much more detail about this step), up to a limit specified by the
channel configuration (
<code class="literal">max_data_to_route</code>
, on
<a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
). The data is then batched based on the
<code class="literal">batch_algorithm</code>
defined for the channel and as documented in
<a href="#configuration-channel" title="4.5.&nbsp;Channel">Section&nbsp;4.5, &#8220;Channel&#8221;</a>
. Note that, for the
<code class="literal">default</code>
and
<code class="literal">transactional</code>
algorithm, there may actually be more than
<code class="literal">max_data_to_route</code>
included depending on the transaction boundaries. The mapping of data to
specific nodes, organized into batches, is then recorded in
<a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
with a status of "RT" in each case (representing the fact that the Route
Job is still running). Once the routing algorithms and batching are
completed, the batches are organized with their corresponding data ids
and saved in
<a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
. Once
<a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
is updated, the rows in
<a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
are updated to a status of New "NE".
</p>
<p>
The route job will respect the
<code class="literal">max_batch_size</code>
on
<a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
. If the max batch size is reached before the end of a database
tranaction and the batch algorithm is set to something other than
<code class="literal">nontransactional</code>
the batch may exceed the specified max size.
</p>
<p>
The route job delegates to a router defined by the
<code class="literal">router_type</code>
and configured by the
<code class="literal">router_expression</code>
in the
<a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table. Each router that has a
<code class="literal">source_node_group_id</code>
that matches the current node's source node group id and is linked to
the
<a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
that captured the data gets an opportunity to choose a list of nodes the
data should be sent to. Data can only be routed to nodes that belong to
the router's
<code class="literal">target_node_group_id</code>
.
</p>
<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="data-gaps"></a>4.12.1.1.&nbsp;Data Gaps</h4></div></div></div>

<p>
On the surface, the first Route Job step of collecting unrouted data ids
seems simple: assign sequential data ids for each data row as it's
inserted and keep track of which data id was last routed and start from
there. The difficulty arises, however, due to the fact that there can be
multiple transactions inserting into
<a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
simultaneously. As such, a given section of rows in the
<a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
table may actually contain "gaps" in the data ids when the Route Job is
executing. Most of these gaps are only temporarily and fill in at some
point after routing and need to be picked up with the next run of the
Route Job. Thus, the Route Job needs to remember to route the filled-in
gaps. Worse yet, some of these gaps are actually permanent and result
from a transaction that is rolled back for some reason. In this case,
the Route Job must continue to watch for the gap to fill in and, at some
point, eventually gives up and assumes the gap is permanent and can be
skipped. All of this must be done in some fashion that guarantees that
gaps are routed when they fill in while also keeping routing as
efficient as possible.
</p>
<p>
SymmetricDS handles the issue of data gaps by making use of a table,
<a href="#table_data_gap" title="A.5.&nbsp;DATA_GAP">DATA_GAP</a>
, to record gaps found in the data ids. In fact, this table completely
defines the entire range of data tha can be routed at any point in time.
For a brand new instance of SymmetricDS, this table is empty and
SymmetricDS creates a gap starting from data id of zero and ending with
a very large number (defined by
<code class="literal">routing.largest.gap.size</code>
). At the start of a Route Job, the list of valid gaps (gaps with status
of 'GP') is collected, and each gap is evaluated in turn. If a gap is
sufficiently old (as defined by
<code class="literal">routing.stale.dataid.gap.time.ms</code>
, the gap is marked as skipped (status of 'SK') and will no longer be
evaluated in future Route Jobs (note that the 'last' gap (the one with
the highest starting data id) is never skipped). If not skipped, then
<a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
is searched for data ids present in the gap. If one or more data ids is
found in
<a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
, then the current gap is marked with a status of OK, and new gap(s) are
created to represent the data ids still missing in the gap's range. This
process is done for all gaps. If the very last gap contained data, a new
gap starting from the highest data id and ending at (highest data id +
<code class="literal">routing.largest.gap.size</code>
) is then created. This process has resulted in an updated list of gaps
which may contain new data to be routed.
</p>
</div>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="push-pull-job"></a>4.12.2.&nbsp;Push and Pull Jobs for Database changes</h3></div></div></div>

<p>
After database-change data is routed, it awaits transport to the target nodes. Transport
can occur when a client node is configured to pull data or when the host
node is configured to push data. These events are controlled by the
<span class="emphasis"><em>push</em></span>
and the
<span class="emphasis"><em>pull jobs</em></span>
. When the
<code class="literal">start.pull.job</code>
SymmetricDS property is set to
<code class="literal">true</code>
, the frequency that data is pulled is controlled by the
<code class="literal">job.pull.period.time.ms</code>
. When the
<code class="literal">start.push.job</code>
SymmetricDS property is set to
<code class="literal">true</code>
, the frequency that data is pushed is controlled by the
<code class="literal">job.push.period.time.ms</code>
.
</p>
<p>
Data is extracted by channel from the source database's
<a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
table at an interval controlled by the
<code class="literal">extract_period_millis</code>
column on the
<a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
table. The
<code class="literal">last_extract_time</code>
is always recorded, by channel, on the
<a href="#table_node_channel_ctl" title="A.19.&nbsp;NODE_CHANNEL_CTL">NODE_CHANNEL_CTL</a>
table for the host node's id. When the Pull and Push Job run, if the
extract period has not passed according to the last extract time, then
the channel will be skipped for this run. If the
<code class="literal">extract_period_millis</code>
is set to zero, data extraction will happen every time the jobs run.
</p>
<p>
The maximum number of batches to extract per synchronization is
controlled by
<code class="literal">max_batch_to_send</code>
on the
<a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
table. There is also a setting that controls the max number of bytes to
send in one synchronization. If SymmetricDS has extracted the more than
the number of bytes configured by the
<code class="literal">transport.max.bytes.to.sync</code>
parameter, then it will finish extracting the current batch and finish
synchronization so the client has a chance to process and acknowlege the
"big" batch. This may happen before the configured max number of batches
has been reached.
</p>
<p>
Both the push and pull jobs can be configured to push and pull multiple
nodes in parallel. In order to take advantage of this the
<code class="literal">pull.thread.per.server.count</code>
or
<code class="literal">push.thread.per.server.count</code>
should be adjusted (from their default value of 10) to the number to the
number of concurrent push/pulls you want to occur per period on each
SymmetricDS instance. Push and pull activity is recorded in the
<a href="#table_node_communication" title="A.18.&nbsp;NODE_COMMUNICATION">NODE_COMMUNICATION</a>
table. This table is also used to lock push and pull activity across
multiple servers in a cluster.
</p>
<p>
SymmetricDS also provides the ability to configure windows of time when
synchronization is allowed. This is done using the
<a href="#table_node_group_channel_wnd" title="A.21.&nbsp;NODE_GROUP_CHANNEL_WND">NODE_GROUP_CHANNEL_WND</a>
table. A list of allowed time windows can be specified for a node group
and a channel. If one or more windows exist, then data will only be
extracted and transported if the time of day falls within the window of
time specified. The configured times are always for the target node's
local time. If the
<code class="literal">start_time</code>
is greater than the
<code class="literal">end_time</code>
, then the window crosses over to the next day.
</p>
<p>
All data loading may be disabled by setting the
<code class="literal">dataloader.enable</code>
property to false. This has the effect of not allowing incoming
synchronizations, while allowing outgoing synchronizations. All data
extractions may be disabled by setting the
<code class="literal">dataextractor.enable</code>
property to false. These properties can be controlled by inserting into
the root server's
<a href="#table_parameter" title="A.30.&nbsp;PARAMETER">PARAMETER</a>
table. These properties affect every channel with the exception of the
'config' channel.
</p>
<p> Node communication over HTTP is represented in the
following figure. </p>
<p>
</p><div class="figure"><a name="d4e1605"></a><div class="figure-contents">

<div class="mediaobject"><img src="images/seq-node-communication.gif" alt="Node Communication"></div>
</div><p class="title"><b>Figure&nbsp;4.1.&nbsp;Node Communication</b></p></div><p><br class="figure-break">
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="file-sync-push-pull"></a>4.12.3.&nbsp;File Sync Push and Pull Jobs</h3></div></div></div>

<p>
The File Sync Push and Pull jobs (introduced in version 3.5) are responsible for synchronizing file changes.
These jobs work with batches on the <code class="literal">filesync</code> channel and create ZIP files of changed files
to be sent and applied on other nodes.
The parameters <code class="literal">job.file.sync.push.period.time.ms</code> and <code class="literal">job.file.sync.pull.period.time.ms</code>
control how often the jobs runs, which default to every 60 seconds.
See also <a href="#jobs" title="4.12.&nbsp;Jobs">Section&nbsp;4.12, &#8220;Jobs&#8221;</a> and <a href="#filesync-operation" title="4.11.2.&nbsp;Operation">Section&nbsp;4.11.2, &#8220;Operation&#8221;</a>.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="file-sync-tracker-job"></a>4.12.4.&nbsp;File System Tracker Job</h3></div></div></div>

<p>
The File System Tracker job (introduced in version 3.5) is responsible for monitoring and
recording the events of files being created, modified, or deleted.
It records the current state of files to the <a href="#table_file_snapshot" title="A.8.&nbsp;FILE_SNAPSHOT">FILE_SNAPSHOT</a> table.
The parameter <code class="literal">job.file.sync.tracker.cron</code> controls how often the job runs,
which defaults to every 5 minutes.
See also <a href="#jobs" title="4.12.&nbsp;Jobs">Section&nbsp;4.12, &#8220;Jobs&#8221;</a> and <a href="#file-sync" title="4.11.&nbsp;File Synchronization">Section&nbsp;4.11, &#8220;File Synchronization&#8221;</a>.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="sync-triggers"></a>4.12.5.&nbsp;Sync Triggers Job</h3></div></div></div>

<p>
SymmetricDS examines the current configuration, corresponding database
triggers, and the underlying tables to determine if database triggers
need created or updated. The change activity is recorded on the
<a href="#table_trigger_hist" title="A.39.&nbsp;TRIGGER_HIST">TRIGGER_HIST</a>
table with a reason for the change. The following reasons for a change
are possible:

</p><div class="itemizedlist"><ul type="disc"><li>
<p>N - New trigger that has not been created before</p>
</li><li>
<p>S - Schema changes in the table were detected</p>
</li><li>
<p>C - Configuration changes in Trigger</p>
</li><li>
<p>T - Trigger was missing</p>
</li></ul></div><p>

A configuration entry in Trigger without any history in Trigger Hist
results in a new trigger being created (N). The Trigger Hist stores a
hash of the underlying table, so any alteration to the table causes the
trigger to be rebuilt (S). When the
<code class="literal">last_update_time</code>
is changed on the Trigger entry, the configuration change causes the
trigger to be rebuilt (C). If an entry in Trigger Hist is missing the
corresponding database trigger, the trigger is created (T).
</p>
<p>
The process of examining triggers and rebuilding them is automatically
run during startup and each night by the SyncTriggersJob. The user can
also manually run the process at any time by invoking the
<code class="literal">syncTriggers()</code>
method over JMX.
</p>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="purge-job"></a>4.12.6.&nbsp;Purge Jobs</h3></div></div></div>

<p>
Purging is the act of cleaning up captured data that is no longer needed
in SymmetricDS's runtime tables. Data is purged through delete
statements by the
<span class="emphasis"><em>Purge Job</em></span>
. Only data that has been successfully synchronized will be purged.
Purged tables include:
</p><div class="itemizedlist"><ul type="disc"><li>
<a href="#table_data" title="A.3.&nbsp;DATA">DATA</a>
</li><li>
<a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
</li><li>
<a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
</li><li>
<a href="#table_incoming_batch" title="A.13.&nbsp;INCOMING_BATCH">INCOMING_BATCH</a>
</li><li>
<a href="#table_data_gap" title="A.5.&nbsp;DATA_GAP">DATA_GAP</a>
</li><li>
<a href="#table_node_host_stats" title="A.26.&nbsp;NODE_HOST_STATS">NODE_HOST_STATS</a>
</li><li>
<a href="#table_node_host_channel_stats" title="A.24.&nbsp;NODE_HOST_CHANNEL_STATS">NODE_HOST_CHANNEL_STATS</a>
</li><li>
<a href="#table_node_host_job_stats" title="A.25.&nbsp;NODE_HOST_JOB_STATS">NODE_HOST_JOB_STATS</a>
</li></ul></div><p>
The purge job is enabled by the
<code class="literal">start.purge.job</code>
SymmetricDS property. The timing of the three purge jobs (incoming,
outgoing, and data gaps) is controlled by a cron expression as specified
by the following properties:
<code class="literal">job.purge.outgoing.cron</code>
,
<code class="literal">job.purge.incoming.cron</code>
, and
<code class="literal">job.purge.datagaps.cron</code>
. The default is
<code class="literal">0 0 0 * * *</code>
, or once per day at midnight.
</p>

<p>
Two retention period properties indicate how much history SymmetricDS
will retain before purging. The
<code class="literal">purge.retention.minutes</code>
property indicates the period of history to keep for synchronization
tables. The default value is 5 days. The
<code class="literal">statistic.retention.minutes</code>
property indicates the period of history to keep for statistics. The
default value is also 5 days.
</p>
<p> The purge properties should be adjusted according to how
much data is flowing through the system and the amount of storage space
the database has. For an initial deployment it is recommended that the
purge properties be kept at the defaults, since it is often helpful to
be able to look at the captured data in order to triage problems and
profile the synchronization patterns. When scaling up to more nodes, it
is recomended that the purge parameters be scaled back to 24 hours or
less. </p>
</div>

</div>

</div>
    <div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="advanced-topics"></a>Chapter&nbsp;5.&nbsp;Advanced Topics</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#advanced-sync">5.1. Advanced Synchronization</a></span></dt><dd><dl><dt><span class="section"><a href="#bi-direction-sync">5.1.1. Bi-Directional Synchronization</a></span></dt><dt><span class="section"><a href="#multi-tier">5.1.2. Multi-Tiered Synchronization</a></span></dt><dd><dl><dt><span class="section"><a href="#registration-redirect">5.1.2.1. Registration Redirect</a></span></dt></dl></dd></dl></dd><dt><span class="section"><a href="#jms-publishing">5.2. JMS Publishing</a></span></dt><dt><span class="section"><a href="#deployment-options">5.3. Deployment Options</a></span></dt><dd><dl><dt><span class="section"><a href="#deployment-options-web-archive">5.3.1. Web Archive (WAR)</a></span></dt><dt><span class="section"><a href="#deployment-options-embedded">5.3.2. Embedded</a></span></dt></dl></dd><dt><span class="section"><a href="#deployment-options-standalone">5.4. Standalone</a></span></dt><dt><span class="section"><a href="#running-service">5.5. Running SymmetricDS as a Service</a></span></dt><dd><dl><dt><span class="section"><a href="#running-service-windows">5.5.1. Running as a Windows Service</a></span></dt><dt><span class="section"><a href="#running-service-unix">5.5.2. Running as a *nix Service</a></span></dt></dl></dd><dt><span class="section"><a href="#clustering">5.6. Clustering</a></span></dt><dt><span class="section"><a href="#encrypted-passwords">5.7. Encrypted Passwords</a></span></dt><dt><span class="section"><a href="#secure-transport">5.8. Secure Transport</a></span></dt><dd><dl><dt><span class="section"><a href="#secure-transport-sym">5.8.1. Sym Launcher</a></span></dt><dt><span class="section"><a href="#secure-transport-tomcat">5.8.2. Tomcat</a></span></dt><dt><span class="section"><a href="#secure-transport-keystore">5.8.3. Keystores</a></span></dt><dt><span class="section"><a href="#secure-transport-keys">5.8.4. Generating Keys</a></span></dt></dl></dd><dt><span class="section"><a href="#basic-auth">5.9. Basic Authentication</a></span></dt><dt><span class="section"><a href="#extensions">5.10. Extension Points</a></span></dt><dd><dl><dt><span class="section"><a href="#extensions-parameter-filter">5.10.1. IParameterFilter</a></span></dt><dt><span class="section"><a href="#extensions-data-loader-filter">5.10.2. IDatabaseWriterFilter</a></span></dt><dt><span class="section"><a href="#extensions-databasewriter-errorhandler">5.10.3. IDatabaseWriterErrorHandler</a></span></dt><dt><span class="section"><a href="#extensions-dataloader-factory">5.10.4. IDataLoaderFactory</a></span></dt><dt><span class="section"><a href="#extensions-acknowledge-event-listener">5.10.5. IAcknowledgeEventListener</a></span></dt><dt><span class="section"><a href="#extensions-reload-listener">5.10.6. IReloadListener</a></span></dt><dt><span class="section"><a href="#extensions-sync-url-extension">5.10.7. ISyncUrlExtension</a></span></dt><dt><span class="section"><a href="#extensions-column-transforms">5.10.8. IColumnTransform</a></span></dt><dt><span class="section"><a href="#extensions-node-id-generator">5.10.9. INodeIdCreator</a></span></dt><dt><span class="section"><a href="#extensions-trigger-creation-listener">5.10.10. ITriggerCreationListener</a></span></dt><dt><span class="section"><a href="#extensions-batch-algorithm">5.10.11. IBatchAlgorithm</a></span></dt><dt><span class="section"><a href="#extensions-data-router">5.10.12. IDataRouter</a></span></dt><dt><span class="section"><a href="#extensions-heartbeat-listener">5.10.13. IHeartbeatListener</a></span></dt><dt><span class="section"><a href="#extensions-offline-client-listener">5.10.14. IOfflineClientListener</a></span></dt><dt><span class="section"><a href="#extensions-offline-server-listener">5.10.15. IOfflineServerListener</a></span></dt><dt><span class="section"><a href="#extensions-node-password">5.10.16. INodePasswordFilter</a></span></dt></dl></dd><dt><span class="section"><a href="#android">5.11. Synchronization to and from Android Devices </a></span></dt></dl></div>
    
    <p>
       This chapter focuses on a variety of topics, including deployment options, jobs, clustering, encryptions, synchronization control,
       and configuration of SymmetricDS.
    </p>

 <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="advanced-sync"></a>5.1.&nbsp;Advanced Synchronization</h2></div></div></div>
    
 <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="bi-direction-sync"></a>5.1.1.&nbsp;Bi-Directional Synchronization</h3></div></div></div>
        
        <p>
            SymmetricDS allows tables to be synchronized bi-directionally.  Note that an outgoing
            synchronization does not process changes during an incoming synchronization on the same node unless the trigger
            was created with the <code class="literal">sync_on_incoming_batch</code> flag set.  If the <code class="literal">sync_on_incoming_batch</code> flag
            is set, then update loops are prevented by a feature that is available in most database dialects.
            More specifically, during an incoming synchronization the source <code class="literal">node_id</code> is put into a database session variable that is
            available to the database trigger.  Data events are not generated if the target <code class="literal">node_id</code>
            on an outgoing synchronization is equal to the source <code class="literal">node_id</code>.
        </p>
        <p>
            By default, only the columns that changed will be updated in the target system.
        </p>
        <p>
            Conflict resolution strategies can be configured for specific links and/or sets of tables.
        </p>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="multi-tier"></a>5.1.2.&nbsp;Multi-Tiered Synchronization</h3></div></div></div>
        
        <p>
            As shown in <a href="#organizing-nodes" title="3.2.&nbsp;Organizing Nodes">Section&nbsp;3.2, &#8220;Organizing Nodes&#8221;</a>, there may be
            scenarios where data needs to flow through multiple tiers of nodes that
            are organized in a tree-like network with each tier requiring a different subset of data.  For example,
            you may have a system where the lowest tier may be a computer or device located in a store.  Those devices
            may connect to a server located physically at that store.  Then the store server may communicate with
            a corporate server for example.  In this case, the three tiers would be device, store, and corporate.
            Each tier is typically represented by a node group.  Each node in
            the tier would belong to the node group representing that tier.
        </p>
        <p>
            A node can only pull and push data to other nodes that are represented in the node's <a href="#table_node" title="A.17.&nbsp;NODE">NODE</a>
            table and in cases where that node's <code class="literal">sync_enabled</code> column is set to 1.
            Because of this, a tree-like
            hierarchy of nodes can be created by having only a subset of nodes belonging to the same node group represented at the different branches of the tree.
        </p>
        <p>
            If auto registration is turned <span class="emphasis"><em>off</em></span>, then this setup must occur manually by opening registration
            for the desired nodes at the desired parent node and by configuring each node's <code class="literal">registration.url</code>
             to be the parent node's URL.
            The parent node is always tracked by the setting of the parent's <code class="literal">node_id</code> in the <code class="literal">created_at_node_id</code> column of the new node.
            When a node registers and downloads its configuration it is always provided the configuration for nodes
            that might register with the node itself based on the Node Group Links defined in the parent node.
        </p>


    <div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="registration-redirect"></a>5.1.2.1.&nbsp;Registration Redirect</h4></div></div></div>
        
        <p>
            When deploying a multi-tiered system it may be advantageous to have only one registration server, even though the parent node of a registering node
            could be any of a number of nodes in the system.  In SymmetricDS the parent node is always the node that a child registers with.  The
            <a href="#table_registration_redirect" title="A.31.&nbsp;REGISTRATION_REDIRECT">REGISTRATION_REDIRECT</a> table allows a single node, usually the root server in the network, to
            redirect registering nodes to their true parents.  It does so based on a mapping found in the table of the external id (<code class="literal">registrant_external_id</code>) to the parent's node
            id (<code class="literal">registration_node_id</code>).
        </p>
        <p>
            For example, if it is desired to have a series of regional servers that workstations at retail stores get assigned to based on their <code class="literal">external_id</code>, the store number, then
            you might insert into <a href="#table_registration_redirect" title="A.31.&nbsp;REGISTRATION_REDIRECT">REGISTRATION_REDIRECT</a> the store number as the <code class="literal">registrant_external_id</code> and the <code class="literal">node_id</code> of
            the assigned region as the <code class="literal">registration_node_id</code>.  When a workstation at the store registers, the root server sends an HTTP redirect to the <code class="literal">sync_url</code> of the node
            that matches the <code class="literal">registration_node_id</code>.
        </p>
        <div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
            <p>Please see <a href="#configuration-initial-load" title="4.6.3.2.&nbsp;Initial Loads">Section&nbsp;4.6.3.2, &#8220;Initial Loads&#8221;</a> for important details around initial loads
            and registration when using registration redirect.
            </p>
            </div>

    </div>
    </div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="jms-publishing"></a>5.2.&nbsp;JMS Publishing</h2></div></div></div>
        
        <p>
            With the proper configuration SymmetricDS can publish XML messages of captured data changes to
            JMS during routing or transactionally while data loading synchronized data into a target database.
            The following explains how to publish to JMS during synchronization to the target database.
       </p>
       <p>
            The XmlPublisherDatabaseWriterFilter is a
            <a href="#extensions-data-loader-filter" title="5.10.2.&nbsp;IDatabaseWriterFilter">IDatabaseWriterFilter</a> that may be configured to
            publish specific tables as an XML message to a JMS provider.
            See <a href="#extensions" title="5.10.&nbsp;Extension Points">Section&nbsp;5.10, &#8220;Extension Points&#8221;</a> for information on how
            to configure an extension point.  If the publish to JMS fails, the batch will be marked in error,
            the loaded data for the batch will be rolled back
            and the batch will be retried during the next synchronization run.
        </p>
        <p>
        The following is an example extension point configuration that will publish four tables in XML with a root
        tag of <span class="emphasis"><em>'sale'</em></span>.  Each XML message will be grouped by the batch and the column names identified by
        the groupByColumnNames property which have the same values.
                </p><pre class="programlisting">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:context="http://www.springframework.org/schema/context"
    xsi:schemaLocation="http://www.springframework.org/schema/beans
           http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
           http://www.springframework.org/schema/context
           http://www.springframework.org/schema/context/spring-context-3.0.xsd"&gt;

    &lt;bean id="configuration-publishingFilter"
      class="org.jumpmind.symmetric.integrate.XmlPublisherDatabaseWriterFilter"&gt;
        &lt;property name="xmlTagNameToUseForGroup" value="sale"/&gt;
        &lt;property name="tableNamesToPublishAsGroup"&gt;
            &lt;list&gt;
               &lt;value&gt;SALE_TX&lt;/value&gt;
               &lt;value&gt;SALE_LINE_ITEM&lt;/value&gt;
               &lt;value&gt;SALE_TAX&lt;/value&gt;
               &lt;value&gt;SALE_TOTAL&lt;/value&gt;
            &lt;/list&gt;
        &lt;/property&gt;
        &lt;property name="groupByColumnNames"&gt;
            &lt;list&gt;
               &lt;value&gt;STORE_ID&lt;/value&gt;
               &lt;value&gt;BUSINESS_DAY&lt;/value&gt;
               &lt;value&gt;WORKSTATION_ID&lt;/value&gt;
               &lt;value&gt;TRANSACTION_ID&lt;/value&gt;
            &lt;/list&gt;
        &lt;/property&gt;
        &lt;property name="publisher"&gt;
           &lt;bean class="org.jumpmind.symmetric.integrate.SimpleJmsPublisher"&gt;
               &lt;property name="jmsTemplate" ref="definedSpringJmsTemplate"/&gt;
           &lt;/bean&gt;
        &lt;/property&gt;
    &lt;/bean&gt;
&lt;/beans&gt;</pre><p>
        </p>
        <p>
          The publisher property on the XmlPublisherDatabaseWriterFilter takes an interface of type IPublisher.  The implementation
          demonstrated here is an implementation that publishes to JMS using Spring's
          <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://static.springsource.org/spring/docs/3.0.x/spring-framework-reference/html/jms.html#jms-jmstemplate" target="_top">JMS template</a>.
          Other implementations of IPublisher could easily publish the XML to other targets like an HTTP server, the file system or secure copy it to another server.
        </p>
        <p>
          The above configuration will publish XML similar to the following:
            </p><pre class="programlisting">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;sale xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  id="0012010-01-220031234" nodeid="00001" time="1264187704155"&gt;
  &lt;row entity="SALE_TX" dml="I"&gt;
    &lt;data key="STORE_ID"&gt;001&lt;/data&gt;
    &lt;data key="BUSINESS_DAY"&gt;2010-01-22&lt;/data&gt;
    &lt;data key="WORKSTATION_ID"&gt;003&lt;/data&gt;
    &lt;data key="TRANSACTION_ID"&gt;1234&lt;/data&gt;
    &lt;data key="CASHIER_ID"&gt;010110&lt;/data&gt;
  &lt;/row&gt;
  &lt;row entity="SALE_LINE_ITEM" dml="I"&gt;
    &lt;data key="STORE_ID"&gt;001&lt;/data&gt;
    &lt;data key="BUSINESS_DAY"&gt;2010-01-22&lt;/data&gt;
    &lt;data key="WORKSTATION_ID"&gt;003&lt;/data&gt;
    &lt;data key="TRANSACTION_ID"&gt;1234&lt;/data&gt;
    &lt;data key="SKU"&gt;9999999&lt;/data&gt;
    &lt;data key="PRICE"&gt;10.00&lt;/data&gt;
    &lt;data key="DESC" xsi:nil="true"/&gt;
  &lt;/row&gt;
  &lt;row entity="SALE_LINE_ITEM" dml="I"&gt;
    &lt;data key="STORE_ID"&gt;001&lt;/data&gt;
    &lt;data key="BUSINESS_DAY"&gt;2010-01-22&lt;/data&gt;
    &lt;data key="WORKSTATION_ID"&gt;003&lt;/data&gt;
    &lt;data key="TRANSACTION_ID"&gt;1234&lt;/data&gt;
    &lt;data key="SKU"&gt;9999999&lt;/data&gt;
    &lt;data key="PRICE"&gt;10.00&lt;/data&gt;
    &lt;data key="DESC" xsi:nil="true"/&gt;
  &lt;/row&gt;
  &lt;row entity="SALE_TAX" dml="I"&gt;
    &lt;data key="STORE_ID"&gt;001&lt;/data&gt;
    &lt;data key="BUSINESS_DAY"&gt;2010-01-22&lt;/data&gt;
    &lt;data key="WORKSTATION_ID"&gt;003&lt;/data&gt;
    &lt;data key="TRANSACTION_ID"&gt;1234&lt;/data&gt;
    &lt;data key="AMOUNT"&gt;1.33&lt;/data&gt;
  &lt;/row&gt;
  &lt;row entity="SALE_TOTAL" dml="I"&gt;
    &lt;data key="STORE_ID"&gt;001&lt;/data&gt;
    &lt;data key="BUSINESS_DAY"&gt;2010-01-22&lt;/data&gt;
    &lt;data key="WORKSTATION_ID"&gt;003&lt;/data&gt;
    &lt;data key="TRANSACTION_ID"&gt;1234&lt;/data&gt;
    &lt;data key="AMOUNT"&gt;21.33&lt;/data&gt;
  &lt;/row&gt;
&lt;/sale&gt;
            </pre><p>
            To publish JMS messages during routing
            the same pattern is valid, with the exception that the extension point would be the XmlPublisherDataRouter and the router
            would be configured by setting the <code class="literal">router_type</code> of a <a href="#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a> to the Spring bean
            name of the registered extension point.  Of course, the router would need to be linked through <a href="#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>s
            to each <a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>  table that needs published.
        </p>
    </div>
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="deployment-options"></a>5.3.&nbsp;Deployment Options</h2></div></div></div>
        
        <p>An instance of SymmetricDS can be deployed in several ways:</p>
        <div class="itemizedlist"><ul type="disc"><li>
                <p>Web application archive (WAR) deployed to an application server</p>
                <p>
                    This option means packaging a WAR file and deploying to your favorite
                    web server, like Apache Tomcat.  It's a little more work, but you
                    can configure the web server to do whatever you need.  SymmetricDS can also
                    be embedded in an existing web application, if desired.
                </p>
            </li><li>
                <p>Standalone service that embeds Jetty web server</p>
                <p>
                    This option means running the <span class="emphasis"><em>sym</em></span> command line, which launches the built-in Jetty web server.
                    This is a simple option because it is already provided, but you lose the flexibility to configure
                    the web server any further.
                </p>
            </li><li>
                <p>Embedded as a Java library in an application</p>
                <p>
                    This option means you must write a wrapper Java program that runs
                    SymmetricDS.  You would probably use Jetty web server, which is also embeddable.
                    You could bring up an embedded database like Derby or H2.  You could configure the
                    web server, database, or SymmetricDS to do whatever you needed, but it's also
                    the most work of the three options discussed thus far.
                </p>
            </li></ul></div>
        <p>
            The deployment model you choose depends on how much flexibility you need versus how easy you
            want it to be.  Both Jetty and Tomcat are excellent, scalable web servers that
            compete with each other and have great performance.  Most people choose either
            the <span class="emphasis"><em>Standalone</em></span> or <span class="emphasis"><em>Web Archive</em></span> with Tomcat 5.5 or 6.  Deploying to Tomcat
            is a good middle-of-the-road decision that requires a little more work for more flexibility.
        </p>
        <p>Next, we will go into a little more detail on the first three deployment options listed above.</p>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="deployment-options-web-archive"></a>5.3.1.&nbsp;Web Archive (WAR)</h3></div></div></div>
            
            <p>
                As a web application archive, a WAR is deployed to an application server,
                such as Tomcat, Jetty, or JBoss.  The structure of the archive will have a <code class="literal">web.xml</code>
                file in the <code class="literal">WEB-INF</code> folder, an appropriately configured <code class="filename">symmetric.properties</code> file in the <code class="literal">WEB-INF/classes</code> folder,
                and the required JAR files in the <code class="literal">WEB-INF/lib</code> folder.
            </p>
            <div class="mediaobject"><img src="images/symmetric_war.gif"></div>
            <p>
                A war file can be generated using the standalone installation's <code class="literal">symadmin</code> utility and the
                <code class="literal">create-war</code> subcommand.  The command requires the name of the war file to generate.  It
                essentially packages up the web directory, the conf directory and includes an optional
                properties file.  Note that if a properties file is included, it will be copied to
                WEB-INF/classes/symmetric.properties.  This is the same location conf/symmetric.properties
                would have been copied to.  The generated war distribution uses the same web.xml as the standalone
                deployment.
            </p>
            <p>
                <span><strong class="command">../bin/symadmin -p my-symmetric-ds.properties create-war /some/path/to/symmetric-ds.war</strong></span>
            </p>
            <p>
                The <code class="literal">web.base.servlet.path</code> property in <code class="filename">symmetric.properties</code> can be set if the SymmetricServlet needs to
                coexist with other Servlets.  By default, the value is blank.  If you set it to, say, <code class="literal">web.base.servlet.path=sync</code> for example,
                <code class="literal">registration.url</code> would be <code class="literal">http://server:port/sync</code>.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="deployment-options-embedded"></a>5.3.2.&nbsp;Embedded</h3></div></div></div>
            
            <p>
                A Java application with the SymmetricDS Java Archive (JAR) library on its
                classpath can use the <code class="literal">SymmetricWebServer</code> to start the server.
            </p>
            <pre class="programlisting">
import org.jumpmind.symmetric.SymmetricWebServer;

public class StartSymmetricEngine {

    public static void main(String[] args) throws Exception {

        SymmetricWebServer node = new SymmetricWebServer(
                                   "classpath://my-application.properties", "conf/web_dir");

        // this will create the database, sync triggers, start jobs running
        node.start(8080);

        // this will stop the node
        node.stop();
    }

}</pre>
            <p>
                This example starts the SymmetricDS server on port 8080.
                The configuration properties file, <code class="filename">my-application.properties</code>,
                is packaged in the application to provide properties that override the SymmetricDS
                default values.  The second parameter to the constructor points to the web directory.
                The default location is <code class="code">../web</code>.  In this example the web directory is located
                at <code class="code">conf/web_dir</code>.  The web.xml is expected to be found at <code class="code">conf/web_dir/WEB-INF/web.xml</code>.
            </p>
        </div>
    </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="deployment-options-standalone"></a>5.4.&nbsp;Standalone</h2></div></div></div>
            
            <p>
                The <code class="literal">sym</code> command line utility starts a standalone web server with
                SymmetricDS pre-deployed.  The standalone server uses an embedded instance of the
                Jetty application server to handle web requests.  The web server can be configured
                using command line options or the web server can be configured by changing properties in the
                <code class="code">conf/symmetric-server.properties</code> file.
            </p>
            <p>
                The following example starts the SymmetricDS server on port 8080 with the startup
                properties found in the <code class="filename">root.properties</code> file.
            </p>
            <pre class="programlisting">/symmetric/bin/sym --properties root.properties --port 8080 --server
</pre>
            <p>
                Even though the port and properties settings can be passed in on the command line, the preferred
                configuration approach is to put each hosted node's properties file in the <code class="code">engines</code> directory
                and to modify port settings and enable secure mode using the <code class="code">conf/symmetric-server.properties</code>.
            </p>
            <p>
                It is also suggested that SymmetricDS be configured to run as a service according to the instructions for your platform as documented in the following section.
            </p>
        </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="running-service"></a>5.5.&nbsp;Running SymmetricDS as a Service</h2></div></div></div>
    
        <p>
    SymmetricDS can be configured to start and run as a service in both Windows and *nix platforms.
    </p>
    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="running-service-windows"></a>5.5.1.&nbsp;Running as a Windows Service</h3></div></div></div>
        
        <p>
            SymmetricDS uses the
            <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://wrapper.tanukisoftware.org/" target="_top">Java Service Wrapper</a>
            product from Tanuki Software to run in the background as a Windows system service.
            The Java Service Wrapper executable is named <code class="filename">sym_service.exe</code>
            so it can be easily identified from a list of running processes.
            To install the service, use the provided script:
            </p><pre class="programlisting">bin\install_service.bat</pre><p>
        </p>
        <p>
            The service configuration is found in <code class="filename">conf/sym_service.conf</code>.
            Edit this file if you want to change the default port number (8080), initial memory size
            (256 MB), log file size (10 MB), or other settings.
            When started, the server will look in the <code class="filename">conf</code> directory
            for the <code class="filename">symmetric.properties</code> file
            and the  <code class="filename">log4j.xml</code> file.
            Logging for standard out, error, and application are written to the
            <code class="filename">logs</code> directory.
        </p>
        <p>
            Most configuration changes do not require the service to be re-installed.
            To un-install the service, use the provided script:
            </p><pre class="programlisting">bin\uninstall_service.bat</pre><p>
        </p>
        <p>
            Use the <span><strong class="command">net</strong></span> command to start and stop the service:
            </p><pre class="programlisting">net start symmetricds
net stop symmetricds</pre><p>
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="running-service-unix"></a>5.5.2.&nbsp;Running as a *nix Service</h3></div></div></div>
        
        <p>
            SymmetricDS uses the 32 bit
            <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://wrapper.tanukisoftware.org/" target="_top">Java Service Wrapper</a>
            product from Tanuki Software to run in the background as a Unix system service.
            The Java Service Wrapper executable is named <code class="filename">sym_service</code>
            so it can be easily identified from a list of running processes.
            The service configuration is found in <code class="filename">conf/sym_service.conf</code>.
            Edit this file if you want to change the initial memory size
            (256 MB), log file size (10 MB), or other settings.
        </p>
        <p>If you happen to need a 64 bit wrapper, you'll need to download the Java Service Wrapper 64 bit version, 
            then do the following:
           </p><div class="orderedlist"><ol type="1"><li>Unzip the download to some directory, say /tmp</li><li>Change directory to the unzip location</li><li>Run the following three commands:
                <pre class="programlisting">
cp ./bin/wrapper /opt/symmetric-ds/bin/sym_service
cp ./lib/wrapper.jar /opt/symmetric-ds/lib/wrapper.jar
cp ./lib/libwrapper.so /opt/symmetric-ds/lib/libwrapper.so
                </pre>
                where <code class="literal">/opt/symmetric-ds</code> should be replaced with wherever you have installed SymmetricDS.
                </li></ol></div><p>
        </p>
        <p>
            An init script is provided to work with standard Unix run configuration levels.
            The <code class="filename">sym_service.initd</code> file follows the
            Linux Standard Base specification, which should work on many systems, including
            Fedora and Debian-based distributions.
            To install the script, copy it into the system init directory:
        </p>
        <p>
            </p><pre class="programlisting">cp bin/sym_service.initd /etc/init.d/sym_service</pre><p>
        </p>
        <p>
            Edit the init script to set the SYM_HOME variable to the directory
            where SymmetricDS is located.  The init script calls the
            <code class="filename">sym_service</code> executable.
        </p>
        <p>Enabling the service varies based on the version of Linux in use.  Three possible approaches are listed below:</p>
        <div class="orderedlist"><ol type="1"><li>Using <code class="literal">chkconfig</code> command:
        <p>
            To enable the service to run automatically when the system is started:
            </p><pre class="programlisting">/sbin/chkconfig --add sym_service</pre><p>
        </p>
        <p>
            To disable the service from running automatically:
            </p><pre class="programlisting">/sbin/chkconfig --del sym_service</pre><p>
        </p>
        </li><li>Using <code class="literal">install_initd</code> command (CentOS Linux, Oracle Linux, SUSE Linux):
        <p>
            On CentOS Linux, Oracle Linux, and SUSE Linux install the service by calling:
            </p><pre class="programlisting">/usr/lib/lsb/install_initd sym_service</pre><p>
            Remove the service by calling:
            </p><pre class="programlisting">/usr/lib/lsb/remove_initd sym_service</pre><p>
        </p></li><li>
            Using <code class="literal">sysv-rc-conf</code> command (Ubuntu Linux):
        <p>
            On Ubuntu Linux, you might need to use sysv-rc-conf instead of chkconfig.
            Try running sys-rc-conf as a super user (consider utilizing apt-get to install sysv-rc-conf
            if it is not present:  <code class="literal">sudo apt-get install sysv-rc-conf</code>).
            Run sysv-rc-conf with the following command:
            </p><pre class="programlisting">sudo sysv-rc-conf </pre><p>
            You should see a list of the scripts residing in your /etc/init.d folder.
            Use control-N to navigate through the list to locate sym_service, then activate the service
            for the desired run-levels (most likely 2-5).
        </p>
        </li></ol></div>
        <p>
            Finally, you can use the <span><strong class="command">service</strong></span> command to start, stop, and query
            the status of the service:
            </p><pre class="programlisting">/sbin/service sym_service start
/sbin/service sym_service stop
/sbin/service sym_service status</pre><p>
        </p>
        <p>
            Alternatively, call the init.d script directly:
            </p><pre class="programlisting">/etc/init.d/sym_service start
/etc/init.d/sym_service stop
/etc/init.d/sym_service status
            </pre><p>
        </p>
    </div>
    </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="clustering"></a>5.6.&nbsp;Clustering</h2></div></div></div>
        
        <p>
        A single SymmetricDS node may be clustered across a series of instances, creating a web farm.  A node might be clustered to provide load balancing and failover, for example.
        </p>
        <p>
        When clustered, a hardware load balancer is typically used
        to round robin client requests to the cluster.  The load balancer should be configured for stateless connections.
        Also, the <code class="literal">sync.url</code> (discussed in <a href="#configuration-node-properties" title="4.1.&nbsp;Node Properties">Section&nbsp;4.1, &#8220;Node Properties&#8221;</a>)
        SymmetricDS property should be set to the URL of the load balancer.
        </p>
        <p>
        If the cluster will be running any of the SymmetricDS jobs, then the <code class="literal">cluster.lock.enabled</code> property should be set to <code class="literal">true</code>.
        By setting this property to true, SymmetricDS will use a row in the <a href="#table_lock" title="A.16.&nbsp;LOCK">LOCK</a> table as a semaphore to make sure that only one instance at a time
        runs a job.  When a lock is acquired, a row is updated in the lock table with the time of the lock and the server id of the locking job.  The lock time is set back to null
        when the job is finished running.  Another instance of SymmetricDS cannot aquire a lock until the locking instance (according to the server id) releases the lock.  If an
        instance is terminated while the lock is still held, an instance with the same server id is allowed to reaquire the lock.  If the locking instance remains down, the lock can be
        broken after a period of time, specified by the <code class="literal">cluster.lock.timeout.ms</code> property, has expired.  Note that if the job is still running and the lock
        expires, two jobs could be running at the same time which could cause database deadlocks.
        </p>
        <p>
        By default, the locking server id is the hostname of the server.  If two clustered instances are running on the same server, then the <code class="literal">cluster.server.id</code> property
        may be set to indicate the name that the instance should use for its server id.
        </p>
        <p>
        When deploying SymmetricDS to an application server like Tomcat or JBoss, no special session clustering needs to be configured for the application server.
        </p>
    </div>
      <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="encrypted-passwords"></a>5.7.&nbsp;Encrypted Passwords</h2></div></div></div>
        
        <p>
            The <code class="literal">db.user</code> and <code class="literal">db.password</code> properties will accept encrypted text, which protects
            against casual observation.  The text is prefixed with <code class="literal">enc:</code> to indicate
            that it is encrypted.  To encrypt text, use the following command:

            </p><pre class="programlisting">symadmin -e {engine name} encrypt-text text-to-encrypt</pre><p>
            or
            </p><pre class="programlisting">symadmin -p {properties file} encrypt-text text-to-encrypt</pre><p>

            The text is encrypted using a secret key named "sym.secret" that is retrieved from a keystore file.
            By default, the keystore is located in <code class="filename">security/keystore</code>.
            The location and filename of the keystore can be overridden by setting the "sym.keystore.file" system property.
            If the secret key is not found, the system will generate and install a secret key for use with Triple DES cipher.
        </p>
        <p>
            Generate a new secret key for encryption using the <code class="literal">keytool</code>
            command that comes with the JRE.  If there is an existing key in the keystore, first remove it:

            </p><pre class="programlisting">keytool -keystore keystore -storepass changeit -storetype jceks \
   -alias sym.secret -delete</pre><p>

            Then generate a secret key, specifying a cipher algorithm and key size.
            Commonly used algorithms that are supported include aes, blowfish, desede, and rc4.

            </p><pre class="programlisting">keytool -keystore keystore -storepass changeit -storetype jceks \
   -alias sym.secret -genseckey -keyalg aes -keysize 128</pre><p>

            If using an alternative provider, place the provider JAR file in the SymmetricDS <code class="filename">lib</code> folder.
            The provider class name should be installed in the JRE security properties or specified on the command line.
            To install in the JRE, edit the JRE <code class="filename">lib/security/java.security</code> file
            and set a <code class="literal">security.provider.i</code> property for the provider class name.
            Or, the provider can be specified on the command line instead.
            Both <code class="literal">keytool</code> and <code class="literal">sym</code> accept command line arguments for the provider class name.
            For example, using the Bouncy Castle provider, the command line options would look like:

            </p><pre class="programlisting">keytool -keystore keystore -storepass changeit -storetype jceks \
   -alias sym.secret -genseckey -keyalg idea -keysize 56 \
   -providerClass org.bouncycastle.jce.provider.BouncyCastleProvider \
   -providerPath ..\lib\bcprov-ext.jar</pre><p>
            </p><pre class="programlisting">symadmin -providerClass org.bouncycastle.jce.provider.BouncyCastleProvider -e secret</pre><p>

            To customize the encryption, write a Java class that implements the ISecurityService or extends the default SecurityService, and place
            the class on the classpath in either <code class="filename">lib</code> or
            <code class="filename">web/WEB-INF/lib</code> folders.
            Then, in the <code class="filename">symmetric.properties</code> specify your class name for the security service.

            </p><pre class="programlisting">security.service.class.name=org.jumpmind.security.SecurityService</pre><p>

            Remember to specify your properties file when encrypting passwords, so it will use your custom ISecurityService.

            </p><pre class="programlisting">symadmin -p symmetric.properties -e secret</pre><p>
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="secure-transport"></a>5.8.&nbsp;Secure Transport</h2></div></div></div>
        
        <p>
            By specifying the "https" protocol for a URL, SymmetricDS will communicate over
            Secure Sockets Layer (SSL) for an encrypted transport.  The following properties
            need to be set with "https" in the URL:
            </p><div class="variablelist"><dl><dt><span class="term">
                        <span><strong class="command">sync.url</strong></span>
                    </span></dt><dd>
                        <p>
                            This is the URL of the current node, so if you want to force other
                            nodes to communicate over SSL with this node, you specify "https" in the URL.
                        </p>
                    </dd><dt><span class="term">
                        <span><strong class="command">registration.url</strong></span>
                    </span></dt><dd>
                        <p>
                            This is the URL where the node will connect for registration when it
                            first starts up.  To protect the registration with SSL, you specify
                            "https" in the URL.
                        </p>
                    </dd></dl></div><p>
            For incoming HTTPS connections, SymmetricDS depends on the webserver where
            it is deployed, so the webserver must be configured for HTTPS.
            As a standalone deployment, the "sym" launcher command provides options for
            enabling HTTPS support.
        </p>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="secure-transport-sym"></a>5.8.1.&nbsp;Sym Launcher</h3></div></div></div>
            
            <p>
                The "sym" launch command uses Jetty as an embedded web server.
                Using command line options, the web server can be told to listen for
                HTTP, HTTPS, or both.
            </p>
            <p>
                <span><strong class="command">sym --port 8080 --server</strong></span>
            </p>
            <p>
                <span><strong class="command">sym --secure-port 8443 --secure-server</strong></span>
            </p>
            <p>
                <span><strong class="command">sym --port 8080 --secure-port 8443 --mixed-server</strong></span>
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="secure-transport-tomcat"></a>5.8.2.&nbsp;Tomcat</h3></div></div></div>
            
            <p>
                If you deploy SymmetricDS to Apache Tomcat, it can be secured by editing the
                <code class="filename">TOMCAT_HOME/conf/server.xml</code>
                configuration file.  There is already a line that can be uncommented
                and changed to the following:

                </p><pre class="programlisting">
&lt;Connector port="8443" protocol="HTTP/1.1" SSLEnabled="true"
  maxThreads="150" scheme="https" secure="true"
  clientAuth="false" sslProtocol="TLS"
  keystoreFile="/symmetric-ds-1.x.x/security/keystore" /&gt;</pre><p>
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="secure-transport-keystore"></a>5.8.3.&nbsp;Keystores</h3></div></div></div>
            
            <p>
                When SymmetricDS connects to a URL with HTTPS, Java checks the validity of the
                certificate using the built-in trusted keystore located at
                <code class="filename">JRE_HOME/lib/security/cacerts</code>.
                The "sym" launcher command overrides the trusted keystore to use its own
                trusted keystore instead, which is located at
                <code class="filename">security/cacerts</code>.
                This keystore contains the certificate aliased as "sym" for use in testing
                and easing deployments.
                The trusted keystore can be overridden
                by specifying the <code class="literal">javax.net.ssl.trustStore</code> system property.
            </p>
            <p>
                When SymmetricDS is run as a secure server with the "sym" launcher,
                it accepts incoming requests using the key installed in the keystore
                located at
                <code class="filename">security/keystore</code>.
                The default key is provided for convenience of testing, but should be
                re-generated for security.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="secure-transport-keys"></a>5.8.4.&nbsp;Generating Keys</h3></div></div></div>
            
            <p>
                To generate new keys and install a server certificate, use the
                following steps:
            </p>
            <div class="procedure"><ol type="1"><li>
                    <p>
                        Open a command prompt and navigate to the
                        <code class="filename">security</code>
                        subdirectory of your SymmetricDS installation on the server to which
                        communication will be secured (typically the "root" or "central office" server).
                    </p>
                </li><li>
                    <p>Delete the old key pair and certificate.</p>
                    <p>
                        <span><strong class="command">keytool -keystore keystore -delete -alias sym</strong></span>
                    </p>
                    <p>
                        <span><strong class="command">keytool -keystore cacerts -delete -alias sym</strong></span>
                    </p>
                    <pre class="programlisting">Enter keystore password:  changeit</pre>
                </li><li>
                    <p>Generate a new key pair.  Note that the first name/last name (the "CN") must match
                    the fully qualified hostname the client will be using to communcate to the server.</p>
                    <p>
                        <span><strong class="command">keytool -keystore keystore -alias sym -genkey -keyalg RSA -validity 10950</strong></span>
                    </p>
                    <pre class="programlisting">
Enter keystore password:  changeit
What is your first and last name?
  [Unknown]:  localhost
What is the name of your organizational unit?
  [Unknown]:  SymmetricDS
What is the name of your organization?
  [Unknown]:  JumpMind
What is the name of your City or Locality?
  [Unknown]:
What is the name of your State or Province?
  [Unknown]:
What is the two-letter country code for this unit?
  [Unknown]:
Is CN=localhost, OU=SymmetricDS, O=JumpMind, L=Unknown, ST=Unknown, C=Unknown
correct?
  [no]:  yes

Enter key password for &lt;sym&gt;
        (RETURN if same as keystore password):</pre>
                </li><li>
                    <p>Export the certificate from the private keystore.</p>
                    <p>
                        <span><strong class="command">keytool -keystore keystore -export -alias sym -rfc -file sym.cer</strong></span>
                    </p>
                </li><li>
                    <p>Install the certificate in the trusted keystore.</p>
                    <p>
                        <span><strong class="command">keytool -keystore cacerts -import -alias sym -file sym.cer</strong></span>
                    </p>
                </li><li>
                    <p>Copy the cacerts file that is generated by this process to
                    the <code class="filename">security</code> directory of each client's SymmetricDS installation.</p>
                </li></ol></div>
        </div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="basic-auth"></a>5.9.&nbsp;Basic Authentication</h2></div></div></div>
        
        <p>
            SymmetricDS supports basic authentication for client and server nodes.
        </p>
        <p>
            To configure a client node to use basic authentication when communicating with a server node,
            specify the following startup parameters:
        </p>
            <div class="variablelist"><dl><dt><span class="term">
                        <span><strong class="command">http.basic.auth.username</strong></span>
                    </span></dt><dd>
                        <p>
                            username for client node basic authentication.
                            [&nbsp;Default:&nbsp;]
                        </p>
                    </dd><dt><span class="term">
                        <span><strong class="command">http.basic.auth.password</strong></span>
                    </span></dt><dd>
                        <p>
                            password for client node basic authentication.
                            [&nbsp;Default:&nbsp;]
                        </p>
                    </dd></dl></div>
        <p>
            The SymmetricDS Standalone Web Server also supports Basic Authentication.  It can be enabled by
            passing the following arguments to the startup program
        </p>
            <div class="variablelist"><dl><dt><span class="term">
                        <span><strong class="command">--http-basic-auth-user</strong></span>
                    </span></dt><dd>
                        <p>
                            username for basic authentication
                            [&nbsp;Default:&nbsp;]
                        </p>
                    </dd><dt><span class="term">
                        <span><strong class="command">--http-basic-auth-password</strong></span>
                    </span></dt><dd>
                        <p>
                            password for basic authentication
                            [&nbsp;Default:&nbsp;]
                        </p>
                    </dd></dl></div>
        <p>
            If the server node is deployed to Tomcat or another application server as a WAR or EAR file, then
            basic authentication is setup with the standard configuration in the WEB.xml file.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="extensions"></a>5.10.&nbsp;Extension Points</h2></div></div></div>
    
        <p>
             SymmetricDS has a pluggable architecture that can be extended. A Java class that implements
             the appropriate extension point interface, can implement custom logic and change the behavior
             of SymmetricDS to suit special needs.  All supported extension
             points extend the <code class="literal">IExtensionPoint</code> interface.  The available extension points are documented in the following sections.
        </p>
        <p>
             When SymmetricDS starts up, the <code class="literal">ExtensionPointManager</code> searches a <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://springframework.org" target="_top">Spring Framework</a>
             context for classes that implement the <code class="literal">IExtensionPoint</code> interface, then creates and registers
             the class with the appropriate SymmetricDS component.
        </p>
        <p>
             Extensions should be configured in the <code class="literal">conf/symmetric-extensions.xml</code> file as Spring beans.  The jar file that contains
             the extension should be placed in the web/WEB-INF/lib directory.
        </p>        
        <p>
             If an extension point needs access to SymmetricDS services or needs to connect to the database
             it may implement the <code class="literal">ISymmetricEngineAware</code> interface in order to
             get a handle to the <code class="literal">ISymmetricEngine</code>.
        </p>
        <p>
             The <code class="literal">INodeGroupExtensionPoint</code> interface may be optionally implemented to indicate that a registered
             extension point should only be registered with specific node groups.
             </p><pre class="programlisting">/**
 * Only apply this extension point to the 'root' node group.
 */
 public String[] getNodeGroupIdsToApplyTo() {
     return new String[] { "root" };
 }
</pre><p>
        </p>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-parameter-filter"></a>5.10.1.&nbsp;IParameterFilter</h3></div></div></div>
            
            <p>
                Parameter values can be specified in code using a parameter filter.  Note that there can be only one parameter
                filter per engine instance.  The IParameterFilter replaces the deprecated IRuntimeConfig from prior releases.
                </p><pre class="programlisting">public class MyParameterFilter
    implements IParameterFilter, INodeGroupExtensionPoint {

    /**
     * Only apply this filter to stores
     */
    public String[] getNodeGroupIdsToApplyTo() {
        return new String[] { "store" };
    }

    public String filterParameter(String key, String value) {
        // look up a store number from an already existing properties file.
        if (key.equals(ParameterConstants.EXTERNAL_ID)) {
            return StoreProperties.getStoreProperties().
              getProperty(StoreProperties.STORE_NUMBER);
        }
        return value;
    }

    public boolean isAutoRegister() {
        return true;
    }

}</pre><p>
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-data-loader-filter"></a>5.10.2.&nbsp;IDatabaseWriterFilter</h3></div></div></div>
            
            <p>
                Data can be filtered or manipulated before it is loaded into the target database.
                A filter can change the
                data in a column, save it somewhere else or do something else with the data entirely.
                It can also specify by the
                return value of the function call that the data loader should continue on
                and load the data (by returning true) or ignore it (by returning false). One
                possible use of the filter, for example, might be to
                route credit card data to a secure database and blank it out as it loads
                into a less-restricted reporting database.
            </p>
            <p>
                A <code class="literal">DataContext</code> is passed to each of the callback methods.  A new
                context is created for each synchronization.  The context provides a mechanism
                to share data during the load of a batch between different rows of data that are
                committed in a single database transaction.
            </p>
            <p>
                The filter also provides callback methods for the batch lifecycle.  The <code class="literal">DatabaseWriterFilterAdapter</code>
                may be used if not all methods are required.
            </p>
            <p>
                A class implementing the IDatabaseWriterFilter interface is injected onto the
                DataLoaderService in order to receive callbacks when data is inserted,
                updated, or deleted.

                </p><pre class="programlisting">public class MyFilter extends DatabaseWriterFilterAdapter {

    @Override
    public boolean beforeWrite(DataContext context, Table table, CsvData data) {
        if (table.getName().equalsIgnoreCase("CREDIT_CARD_TENDER")
                &amp;&amp; data.getDataEventType().equals(DataEventType.INSERT)) {
            String[] parsedData = data.getParsedData(CsvData.ROW_DATA);
            // blank out credit card number
            parsedData[table.getColumnIndex("CREDIT_CARD_NUMBER")] = null;
        }
        return true;
    }
}</pre><p>
            </p>
            <p>
                The filter class should be specified in <code class="literal">conf/symmetric-extensions.xml</code> as follows.

                </p><pre class="programlisting">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:context="http://www.springframework.org/schema/context"
    xsi:schemaLocation="http://www.springframework.org/schema/beans
           http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
           http://www.springframework.org/schema/context
           http://www.springframework.org/schema/context/spring-context-3.0.xsd"&gt;

    &lt;bean id="myFilter" class="com.mydomain.MyFilter"/&gt;

&lt;/beans&gt;</pre><p>
            </p>
        </div>

        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-databasewriter-errorhandler"></a>5.10.3.&nbsp;IDatabaseWriterErrorHandler</h3></div></div></div>
            
            <p>
            Implement this extension point to override how errors are handled.  You can use this extension point to ignore rows that produce foreign key errors.
            </p>
        </div>

        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-dataloader-factory"></a>5.10.4.&nbsp;IDataLoaderFactory</h3></div></div></div>
            
            <p>
            Implement this extension point to provide a different implementation of the <code class="code">org.jumpmind.symmetric.io.data.IDataWriter</code> that
            is used by the SymmetricDS data loader.  Data loaders are configured for a channel.  After this extension point is registered it can
            be activated for a <a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a> by indicating the data loader name in the <code class="code">data_loader_type</code> column.
            </p>
            <p>
            SymmetricDS has two out of the box extensions of IDataLoaderFactory already implemented in its PostgresBulkDataLoaderFactory 
            and OracleBulkDataLoaderFactory classes.  These extension points implement bulk data loading capabilities for Oracle, 
            Postgres and Greenplum dialects.  See Appendix C. Database Notes for details.
            </p>
            <p>
            Another possible use of this extension point is to route data to a NOSQL data sink.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-acknowledge-event-listener"></a>5.10.5.&nbsp;IAcknowledgeEventListener</h3></div></div></div>
            
            <p>
            Implement this extension point to receive callback events when a batch is acknowledged.
            The callback for this listener happens at the point of extraction.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-reload-listener"></a>5.10.6.&nbsp;IReloadListener</h3></div></div></div>
            
            <p>
            Implement this extension point to listen in and take
            action before or after a reload is requested for a Node.  The callback for this listener
            happens at the point of extraction.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-sync-url-extension"></a>5.10.7.&nbsp;ISyncUrlExtension</h3></div></div></div>
            
            <p>
             This extension point is used to select an appropriate URL based on
             the URI provided in the <code class="literal">sync_url</code> column of <code class="literal">sym_node</code>.
            </p>
            <p>
             To use this extension point configure the sync_url for a node with the
             protocol of ext://beanName. The beanName is the name you give the extension
             point in the extension xml file.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-column-transforms"></a>5.10.8.&nbsp;IColumnTransform</h3></div></div></div>
            
            <p>
             This extension point allows custom column transformations to be created.  There are a handful of
             out-of-the-box implementations.  If any of these do not meet the column transformation needs of
             the application, then a custom transform can be created and registered.  It can be activated
             by referencing the column transform's name <code class="code">transform_type</code> column of
             <a href="#table_transform_column" title="A.37.&nbsp;TRANSFORM_COLUMN">TRANSFORM_COLUMN</a>
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-node-id-generator"></a>5.10.9.&nbsp;INodeIdCreator</h3></div></div></div>
            
            <p>
             This extension point allows SymmetricDS users to implement their own algorithms for how
             node ids and passwords are generated or selected during the registration process.  There may be
             only one node creator per SymmetricDS instance (Please note that the node creator extension has replaced the node generator extension).
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-trigger-creation-listener"></a>5.10.10.&nbsp;ITriggerCreationListener</h3></div></div></div>
            
            <p>
            Implement this extension point to get status callbacks during trigger creation.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-batch-algorithm"></a>5.10.11.&nbsp;IBatchAlgorithm</h3></div></div></div>
            
            <p>
            Implement this extension point and set the name of the Spring bean on the batch_algorithm column of the Channel table to use.
            This extension point gives fine grained control over how a channel is batched.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-data-router"></a>5.10.12.&nbsp;IDataRouter</h3></div></div></div>
            
            <p>
            Implement this extension point and set the name of the Spring bean on the router_type column
            of the Router table to use.  This extension point gives the ability to programmatically decide
            which nodes data should be routed to.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-heartbeat-listener"></a>5.10.13.&nbsp;IHeartbeatListener</h3></div></div></div>
            
            <p>
            Implement this extension point to get callbacks during the heartbeat job.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-offline-client-listener"></a>5.10.14.&nbsp;IOfflineClientListener</h3></div></div></div>
            
            <p>
            Implement this extension point to get callbacks for offline events on client nodes.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-offline-server-listener"></a>5.10.15.&nbsp;IOfflineServerListener</h3></div></div></div>
            
            <p>
            Implement this extension point to get callbacks for offline events detected on a server node during monitoring of client nodes.
            </p>
        </div>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="extensions-node-password"></a>5.10.16.&nbsp;INodePasswordFilter</h3></div></div></div>
            
            <p>
            Implement this extension point to intercept the saving and rendering of the node password.
            </p>
        </div>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="android"></a>5.11.&nbsp;Synchronization to and from Android Devices </h2></div></div></div>
	

	<p>
		SymmetricDS now has its web-enabled, fault-tolerant, database
		synchronization
		software available on the Android mobile computing
		platform. The Android client follows all of the same concepts and
		brings to Android
		all of the same core SymmetricDS features as the
		full-featured,
		Java-based SymmetricDS client. The Android client is a
		little bit different
		in that it is not a stand-alone application, but
		is designed to
		be referenced
		as a library to run in-process with an
		Android
		application
		requiring
		synchronization for its SQLite database.
	</p>
	<p>
		By using SymmetricDS, mobile application development is
		simplified, in that the mobile application developer can now focus
		solely on interacting with their local SQLite database. SymmetricDS
		takes care of capturing and moving data changes to and from a
		centralized database when the network is available
	</p>
	<p>
		One of the main goals of the SymmetricDS 3 release was to support
		deployment to Android devices. SymmetricDS's overall footprint was
		reduced by eliminating a number of external dependencies in order to
		better deploy to Android. Also, the database access layer was
		abstracted so that the Android specific database access layer could be
		used. This allows SymmetricDS to be efficient in accessing the SQLite
		database on the Android device.
	</p>
	<p>
		In order to convey how to use the SymmetricDS Android libraries,
		the example below will show how to integrate SymmetricDS into the NotePad
		sample application that comes with the Android ADK.
	</p>
	<p>
		The NotePad sample application is a very simple task list
		application
		that persists &#8220;notes&#8221; to a SQLite database table called
		Notes. The
		Notes table will be configured to synchronize to a
		centralized version
		of the table.  The Notes table looks as follows:
	</p>
	<p>
		</p><div class="table"><a name="d4e2081"></a><div class="table-contents">
			
			<table summary="Notes Table" border="1"><colgroup><col width="50%"><col width="50%"></colgroup><thead><tr><th>Column Name</th><th>Column Type</th></tr></thead><tbody><tr><td>_ID(PK)</td><td>INTEGER</td></tr><tr><td>TITLE</td><td>TEXT</td></tr><tr><td>NOTES</td><td>TEXT</td></tr><tr><td>CREATED</td><td>INTEGER</td></tr><tr><td>MODIFIED</td><td>INTEGER</td></tr></tbody></table>
		</div><p class="title"><b>Table&nbsp;5.1.&nbsp;Notes Table</b></p></div><p><br class="table-break">
	</p>
	<p>
		Next, we will describe how to embed SymmetricDS in the NotePad
		application.  Eclipse 3.7.2 and Android ADK 20.0.3 were used for this
		example.
	</p>
	<p>
		To start,create the NotePad project. You do
		this by adding a new Android Sample Project. Select the NotePad
		project.
	</p>
	<p>
		</p><div class="figure"><a name="New Sample NotePad Project"></a><div class="figure-contents">
			
			<div class="mediaobject"><img src="images/sync-android-1.png" alt="New Sample NotePad Project"></div>
		</div><p class="title"><b>Figure&nbsp;5.1.&nbsp;New Sample NotePad Project</b></p></div><p><br class="figure-break">
	</p>
	<p>
		SymmetricDS for Android comes as a zip file of Java archives (jar
		files) that are required by the SymmetricDS client at runtime. This
		zip file ()symmetric-ds-3.4.7-android.zip) can be downloaded from 
		the SymmetricDS.org website.  The first step to using SymmetricDS in an Android
		application is to unzip the jar files into a location where the
		project will recognize them. The latest Android SDK and the Eclipse
		ADK requires that these jar files be put into a libs directory under
		the Android application project.
	</p>
	<p>
		</p><div class="figure"><a name="Sample NotePad Project"></a><div class="figure-contents">
			
			<div class="mediaobject" align="center"><table border="0" summary="manufactured viewport for HTML img" cellspacing="0" cellpadding="0" width="855"><tr><td align="center"><img src="images/sync-android-2.png" align="middle" width="855" alt="New Sample NotePad Project"></td></tr></table></div>
		</div><p class="title"><b>Figure&nbsp;5.2.&nbsp;New Sample NotePad Project</b></p></div><p><br class="figure-break">
	</p>
	<p>
		Unzip the symmetric-ds-x.x.x-android.zip file to the NotePad
		project directory. Refresh the NotePad project in Eclipse. You should
		end up with a libs directory that is automatically added to the Android
		Dependencies.
	</p>
	<p>
		</p><div class="figure"><a name="Jar Files Added to Libs"></a><div class="figure-contents">
			
			<div class="mediaobject" align="center"><table border="0" summary="manufactured viewport for HTML img" cellspacing="0" cellpadding="0" width="855"><tr><td align="center"><img src="images/sync-android-3.png" align="middle" width="855" alt="Jar Files Added to Libs"></td></tr></table></div>
		</div><p class="title"><b>Figure&nbsp;5.3.&nbsp;Jar Files Added to Libs</b></p></div><p><br class="figure-break">
	</p>
	<p>
		The Android version of the SymmetricDS engine is a Java class that can
		be
		instantiated directly or wired into an application via a provided
		Android service. Whether you are using the service or the engine
		directly you need to provide a few required startup parameters to the
		engine:
		</p><div class="itemizedlist"><ul type="disc"><li><span><strong class="command">SQLiteOpenHelper</strong></span> &#8211; It is best (but not required) if the
				SQLiteOpenHelper is shared with the application that will be sharing
				the SQLite database. This core Android Java class provides software
				synchronization around the access to the database and minimizes
				locking errors.
			</li><li><span><strong class="command">registrationUrl</strong></span> &#8211; This is the URL of where the centralized
				SymmetricDS instance is hosted.
			</li><li><span><strong class="command">externalId</strong></span> &#8211; This is the identifier that can be used by the
				centralized SymmetricDS server to identify whether this instance
				should get data changes that happen on the server. It could be the
				serial number of the device, an account username, or some other
				business concept like store number.
			</li><li><span><strong class="command">nodeGroupId</strong></span> &#8211; This is the group id for the mobile device in
				the synchronization configuration. For example, if the nodeGroupId
				is 'handheld', then the SymmetricDS configuration might have a group
				called 'handheld' and a group called 'corp' where 'handheld' is
				configured to push and pull data from 'corp.'
			</li><li><span><strong class="command">properties</strong></span> &#8211; Optionally tweak the settings for SymmetricDS.
			</li></ul></div><p>
	</p>
	<p>
		In order to integrate SymmetricDS into the NotePad application,
		the
		Android-specific SymmetricService will be used, and we need to tell
		the Android application this by adding the service to the
		AndroidManifest.xml file. Add the following snipped to the Manifest as
		the last entry under the &lt;application&gt;
		tag.
	</p>
	<p>
		</p><pre class="programlisting">
&lt;service android:name="org.jumpmind.symmetric.android.SymmetricService" android:enabled="true" &gt;           
    &lt;intent-filter&gt;
  		&lt;action android:name="org.jumpmind.symmetric.android.SymmetricService" /&gt;
  	&lt;/intent-filter&gt;
&lt;/service&gt;
		</pre><p>
	</p>

	<p>
		The other change required in the Manifest is to give the application
		permission to use the Internet. Add this as the first entry in the
		AndroidManifest.xml right before the
		&lt;application&gt; tag.
	</p>

	<p>
		</p><pre class="programlisting">
&lt;uses-permission android:name="android.permission.INTERNET"&gt;&lt;/uses-permission&gt; 
		</pre><p>
	</p>

	<p>
		The only additional change needed is the call to start the service in the
		application. The service needs to be started manually because we need
		to give the application a chance to provide configuration information
		to the service.
	</p>

	<p>
		In NotePadProvider.java add the following code snippet in the onCreate
		method.
	</p>

	<p>
		</p><div class="figure"><a name="NotePadProvider.java"></a><div class="figure-contents">
			
			<div class="mediaobject" align="center"><table border="0" summary="manufactured viewport for HTML img" cellspacing="0" cellpadding="0" width="855"><tr><td align="center"><img src="images/sync-android-4.png" align="middle" width="855" alt="NotePadProvider.java"></td></tr></table></div>
		</div><p class="title"><b>Figure&nbsp;5.4.&nbsp;NotePadProvider.java</b></p></div><p><br class="figure-break">
	</p>

	<p>
		</p><pre class="programlisting">
		
final String HELPER_KEY = "NotePadHelperKey";

// Register the database helper, so it can be shared with the
SymmetricService
SQLiteOpenHelperRegistry.register(HELPER_KEY, mOpenHelper);

Intent intent = new Intent(getContext(), SymmetricService.class);

// Notify the service of the database helper key
intent.putExtra(SymmetricService.INTENTKEY_SQLITEOPENHELPER_REGISTRY_KEY,
HELPER_KEY);
intent.putExtra(SymmetricService.INTENTKEY_REGISTRATION_URL,
"http://10.0.2.2:31415/sync/server");
intent.putExtra(SymmetricService.INTENTKEY_EXTERNAL_ID,
"android-simulator");
intent.putExtra(SymmetricService.INTENTKEY_NODE_GROUP_ID, "client");
intent.putExtra(SymmetricService.INTENTKEY_START_IN_BACKGROUND,
true);

Properties properties = new Properties();
// initial load existing notes from the Client to the Server
properties.setProperty(ParameterConstants.AUTO_RELOAD_REVERSE_ENABLED,
"true");
intent.putExtra(SymmetricService.INTENTKEY_PROPERTIES, properties);

getContext().startService(intent);
			
		</pre><p>
	</p>

	<p>
		This code snippet shows how the SQLiteOpenHelper is shared. The
		application's SQLiteOpenHelper is registered in a static registry
		provided by the SymmetricDS Android library. When the service is
		started, the key used to store the helper is passed to the service so
		that the service may pull the helper back out of the registry.
	</p>

	<p>
		The various parameters needed by SymmetricDS are being set in the Intent
		which will be used by the SymmetricService to start the engine.
	</p>

	<p>
		Most of the parameters will be familiar to SymmetricDS users. In this case
		a property is being set which will force an initial load of the
		existing Notes from the client to the server. This allows the user of
		the application to enter Notes for the first time offline or while the
		SymmetricDS engine is unregistered and still have them arrive at the
		centralized server once the SymmetricDS engine does get registered.
	</p>

	<p>
		That's all you have to do to integrate SymmetricDS with your Android
		application. 
	</p>	
</div>
</div>    
    <div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="administration"></a>Chapter&nbsp;6.&nbsp;Administration</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#solving-synchronization-issues">6.1. Solving Synchronization Issues</a></span></dt><dd><dl><dt><span class="section"><a href="#solving-synchronization-issues-analysis-outgoing">6.1.1. Analyzing the Issue - Outgoing Batches</a></span></dt><dt><span class="section"><a href="#solving-synchronization-issues-analysis-incoming">6.1.2. Analyzing the Issue - Incoming Batches</a></span></dt><dt><span class="section"><a href="#solving-synchronization-issues-resolution-outgoing">6.1.3. Resolving the Issue - Outgoing Batches</a></span></dt><dt><span class="section"><a href="#solving-synchronization-issues-resolution-incoming">6.1.4. Resolving the Issue - Incoming Batches</a></span></dt></dl></dd><dt><span class="section"><a href="#changing-triggers">6.2. Changing Triggers</a></span></dt><dt><span class="section"><a href="#grouplet">6.3. Maintaining multiple synchronization configurations through Grouplets</a></span></dt><dd><dl><dt><span class="section"><a href="#grouplet-example">6.3.1. Grouplet Example</a></span></dt></dl></dd><dt><span class="section"><a href="#resync-data">6.4. Re-synchronizing Data</a></span></dt><dt><span class="section"><a href="#changing-configuration">6.5. Changing Configuration</a></span></dt><dt><span class="section"><a href="#logging">6.6. Logging Configuration</a></span></dt><dt><span class="section"><a href="#admin-jmx">6.7. Java Management Extensions</a></span></dt><dt><span class="section"><a href="#temporary-files">6.8. Temporary Files</a></span></dt></dl></div>
    

    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="solving-synchronization-issues"></a>6.1.&nbsp;Solving Synchronization Issues</h2></div></div></div>
        

       <p>
       By design, whenever SymmetricDS encounters an issue with a synchronization, the batch containing the error is marked as being in
       an error state, and all subsequent batches <span class="emphasis"><em>for that particular channel to that particular node</em></span> are held and not
       synchronized until the error batch is resolved.  SymmetricDS will retry the batch in error until the situation creating the
       error is resolved (or the data for the batch itself is changed).
       </p>

       <p>
       Analyzing and resolving issues can take place on the outgoing or incoming side.  The techniques for analysis are slightly different in
       the two cases, however, due to the fact that the node with outgoing batch data also has the data and data events associated with the batch in
       the database.  On the incoming node, however, all that is available is the incoming batch header and data present in an incoming error table.

       </p>
        <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="solving-synchronization-issues-analysis-outgoing"></a>6.1.1.&nbsp;Analyzing the Issue - Outgoing Batches</h3></div></div></div>
        

       <p>
       The first step in analyzing the cause of a failed batch is to locate information about the data in the batch, starting with
       <a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
       To locate batches in error, use:
       </p><pre class="programlisting">select * from sym_outgoing_batch where error_flag=1;</pre><p>
       Several useful pieces of information are available from this query:
       </p><div class="itemizedlist"><ul type="disc"><li>
       The batch number of the failed batch, available in column <code class="literal">BATCH_ID</code>.
       </li><li>
       The node to which the batch is being sent, available in column <code class="literal">NODE_ID</code>.
       </li><li>
       The channel to which the batch belongs, available in column <code class="literal">CHANNEL_ID</code>.
       All subsequent batches on this channel to this node will be held until the error condition is resolved.
       </li><li>
       The specific data id in the batch which is causing the failure, available in column <code class="literal">FAILED_DATA_ID</code>.
       </li><li>
       Any SQL message, SQL State, and SQL Codes being returned during the synchronization attempt, available in columns <code class="literal">SQL_MESSAGE</code>,
       <code class="literal">SQL_STATE</code>, and <code class="literal">SQL_CODE</code>, respectively.
       </li></ul></div><p>
       </p>
       <div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3>
       Using the <code class="literal">error_flag</code> on the batch table, as shown above, is more reliable than using the
       <code class="literal">status</code> column.  The status column can change from 'ER' to a different status temporarily as
       the batch is retried.
       </div>
       <div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3>The query above will also show you any recent batches that
       were originally in error and were changed to be manually skipped.  See the end of  <a href="#solving-synchronization-issues-resolution-outgoing" title="6.1.3.&nbsp;Resolving the Issue - Outgoing Batches">Section&nbsp;6.1.3, &#8220;Resolving the Issue - Outgoing Batches&#8221;</a> for more details.
       </div>
       <p>
       To get a full picture of the batch, you can query for information representing the complete
       list of all data changes associated with the failed batch by joining
       <a href="#table_data" title="A.3.&nbsp;DATA">DATA</a> and  <a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>, such as:
       </p><pre class="programlisting">select * from sym_data where data_id in
        (select data_id from sym_data_event where batch_id='XXXXXX');</pre><p>
       where XXXXXX is the batch id of the failing batch.
       </p>
       <p>
       This query returns a wealth of information about each data change in a batch, including:
       </p><div class="itemizedlist"><ul type="disc"><li>
       The table involved in each data change, available in column <code class="literal">TABLE_NAME</code>,</li><li>
       The event type (Update [U], Insert [I], or Delete [D]), available in column <code class="literal">EVENT_TYPE</code>,
       </li><li>
       A comma separated list of the new data and (optionally) the old data, available in columns <code class="literal">ROW_DATA</code> and
       <code class="literal">OLD_DATA</code>, respectively.
       </li><li>
       The primary key data, available in column <code class="literal">PK_DATA</code>
       </li><li>
       The channel id, trigger history information, transaction id if available, and other information.
       </li></ul></div><p>
       </p>
       <p>
       More importantly, if you narrow your query to just the failed data id you can determine the exact data change that is causing the failure:
       </p><pre class="programlisting">select * from sym_data where data_id in
        (select failed_data_id from sym_outgoing_batch where batch_id='XXXXX'
        and node_id='YYYYY');</pre><p>
       where XXXXXX is the batch id and YYYYY is the node id of the batch that is failing.
       </p>
       <p>The queries above usually yield enough information to be able to determine why a
       particular batch is failing. Common reasons a batch might be failing include:
            </p><div class="itemizedlist"><ul type="disc"><li>
            The schema at the destination has a column that is not nullable yet the source
            has the column defined as nullable and a data change was sent with the column as null.</li><li>
            A foreign key constraint at the destination is preventing an insertion or update, which could be caused from
            data being deleted at the destination or the foreign key constraint is not in place at the source.
            </li><li>
            The data size of a column on the destination is smaller than the data size in the source, and data that
            is too large for the destination has been synced.
            </li></ul></div><p>
            </p>

    </div>

      <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="solving-synchronization-issues-analysis-incoming"></a>6.1.2.&nbsp;Analyzing the Issue - Incoming Batches</h3></div></div></div>
        

       <p>
        Analysis using an incoming batch is different than that of outgoing batches.  For incoming batches, you will rely on two tables,
        <a href="#table_incoming_batch" title="A.13.&nbsp;INCOMING_BATCH">INCOMING_BATCH</a> and  <a href="#table_incoming_error" title="A.14.&nbsp;INCOMING_ERROR">INCOMING_ERROR</a>.

       The first step in analyzing the cause of an incoming failed batch is to locate information about the batch, starting with
       <a href="#table_incoming_batch" title="A.13.&nbsp;INCOMING_BATCH">INCOMING_BATCH</a>
        To locate batches in error, use:
       </p><pre class="programlisting">select * from sym_incoming_batch where error_flag=1;</pre><p>
       Several useful pieces of information are available from this query:
       </p><div class="itemizedlist"><ul type="disc"><li>
       The batch number of the failed batch, available in column <code class="literal">BATCH_ID</code>.  Note that this is the batch number of the
       outgoing batch on the outgoing node.
       </li><li>
       The node the batch is being sent from, available in column <code class="literal">NODE_ID</code>.
       </li><li>
       The channel to which the batch belongs, available in column <code class="literal">CHANNEL_ID</code>.
       All subsequent batches on this channel from this node will be held until the error condition is resolved.
       </li><li>
        The data_id that was being processed when the batch failed, available in column <code class="literal">FAILED_DATA_ID</code>.
       </li><li>
       Any SQL message, SQL State, and SQL Codes being returned during the synchronization attempt, available in columns <code class="literal">SQL_MESSAGE</code>,
       <code class="literal">SQL_STATE</code>, and <code class="literal">SQL_CODE</code>, respectively.
       </li></ul></div><p>
       </p>

       <p>
       For incoming batches, we do not have data and data event entries in the database we can query.
       We do, however, have a table,  <a href="#table_incoming_error" title="A.14.&nbsp;INCOMING_ERROR">INCOMING_ERROR</a>, which provides some information about the batch.


       </p><pre class="programlisting">select * from sym_incoming_error
            where batch_id='XXXXXX' and node_id='YYYYY';</pre><p>
       where XXXXXX is the batch id and YYYYY is the node id of the failing batch.


       </p>

         <p>
       This query returns a wealth of information about each data change in a batch, including:
       </p><div class="itemizedlist"><ul type="disc"><li>
       The table involved in each data change, available in column <code class="literal">TARGET_TABLE_NAME</code>,</li><li>
       The event type (Update [U], Insert [I], or Delete [D]), available in column <code class="literal">EVENT_TYPE</code>,
       </li><li>
       A comma separated list of the new data and (optionally) the old data, available in columns <code class="literal">ROW_DATA</code> and
       <code class="literal">OLD_DATA</code>, respectively,</li><li>
       The column names of the table, available in column <code class="literal">COLUMN_NAMES</code>,</li><li>
       The primary key column names of the table, available in column <code class="literal">PK_COLUMN_NAMES</code>,</li></ul></div><p>
       </p>


    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="solving-synchronization-issues-resolution-outgoing"></a>6.1.3.&nbsp;Resolving the Issue - Outgoing Batches</h3></div></div></div>
            

            <p>
            Once you have decided upon the cause of the issue, you'll have to decide the best course of action to fix the issue.  If, for example,
            the problem is due to a database schema mismatch, one possible solution would be to alter the destination database
            in such a way that the SQL error no longer occurs.  Whatever approach you take to remedy the issue, once you have
            made the change, on the next push or pull SymmetricDS will retry the batch
            and the channel's data will start flowing again.
            </p>
            <p>
            If you have instead decided that the batch itself is wrong, or does not need synchronized, or you wish to remove a
            particular data change from a batch, you do have the option of changing the data associated with the batch directly.

            </p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3>
            Be cautious when using the following two approaches to resolve synchronization issues.  By far, the
            best approach to solving a synchronization error is to resolve what is truly causing the
            error at the destination database.  Skipping a batch or removing a data id as discussed below should be your
            solution of last resort, since doing so results in differences between the source and destination databases.
            </div><p>

            Now that you've read the warning, if you <span class="emphasis"><em>still</em></span> want to change the batch
            data itself, you do have several options, including:
            </p><div class="itemizedlist"><ul type="disc"><li>Causing SymmetricDS to skip the batch completely.  This is accomplished by setting the
                batch's status to 'OK', as in:
                <pre class="programlisting">update sym_outgoing_batch set status='OK' where batch_id='XXXXXX'</pre>
                where XXXXXX is the failing batch. On the next pull or push, SymmetricDS will skip this batch since
                it now thinks the batch has already been synchronized.  Note that you can still distinguish between successful
                batches and ones that you've artificially marked as 'OK', since the <code class="literal">error_flag</code> column on
                the failed batch will still be set to '1' (in error).
                </li><li>
                Removing the failing data id from the batch by deleting the corresponding row in <a href="#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>.
                Eliminating the data id from the list of data ids in the batch will cause future synchronization attempts
                of the batch to no longer include that particular data change as part of the batch.  For example:
                  <pre class="programlisting">delete from sym_data_event where batch_id='XXXXXX' and data_id='YYYYYY'</pre>
                where XXXXXX is the failing batch and YYYYYY is the data id to longer be included in the batch.
                </li></ul></div><p>
            </p>
   </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="solving-synchronization-issues-resolution-incoming"></a>6.1.4.&nbsp;Resolving the Issue - Incoming Batches</h3></div></div></div>
            

            <p>
            For batches in error, from the incoming side you'll also have to decide the best course of action to fix the issue.
            Incoming batch errors <span class="emphasis"><em>that are in conflict</em></span> can by fixed by taking advantage of two columns in <a href="#table_incoming_error" title="A.14.&nbsp;INCOMING_ERROR">INCOMING_ERROR</a> which are examined each time
            batches are processed.  The first column, <code class="literal">resolve_data</code> if filled in will be used in place of <code class="literal">row_data</code>.
            The second column, <code class="literal">resolve_ignore</code> if set will cause this particular data item to be ignored and batch processing to continue.  This is the same
            two columns used when a manual conflict resolution strategy is chosen, as discussed in <a href="#conflicts" title="4.10.&nbsp;Conflict Detection and Resolution">Section&nbsp;4.10, &#8220;Conflict Detection and Resolution&#8221;</a>.
            </p>
            </div>
   </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="changing-triggers"></a>6.2.&nbsp;Changing Triggers</h2></div></div></div>
        
        <p>
            A trigger row may be updated using SQL to change a synchronization definition.
            SymmetricDS will look for changes each night or whenever the Sync Triggers Job
            is run (see below).  For example, a change to place the table <code class="literal">price_changes</code>
            into the price channel would be accomplished with the following statement:
            </p><pre class="programlisting">
update SYM_TRIGGER
set channel_id = 'price',
    last_update_by = 'jsmith',
    last_update_time = current_timestamp
where source_table_name = 'price_changes';
</pre><p>
            All configuration changes should be managed centrally at the registration node.  If enabled, configuration
            changes will be synchronized out to client nodes.  When trigger changes reach the client
            nodes the Sync Triggers Job will run automatically.
         </p>
         <p>
            Centrally, the trigger changes will not take effect until the Sync Triggers Job runs.
            Instead of waiting for the Sync Triggers Job to run overnight after making a Trigger
            change, you can invoke the syncTriggers() method over JMX or simply restart the SymmetricDS
            server.  A complete record of trigger changes is kept in the table  <a href="#table_trigger_hist" title="A.39.&nbsp;TRIGGER_HIST">TRIGGER_HIST</a>,
            which was discussed in <a href="#sync-triggers" title="4.12.5.&nbsp;Sync Triggers Job">Section&nbsp;4.12.5, &#8220;Sync Triggers Job&#8221;</a>.
        </p>
    </div>

    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="grouplet"></a>6.3.&nbsp;Maintaining multiple synchronization configurations through Grouplets</h2></div></div></div>
        

        <p>
        As you probably know by now, SymmetricDS stores its single configuration centrally and distributes it to all nodes.   By default, a trigger-router is in effect for all nodes in the source node group or target node group.  Triggers will be established
        on each node that is a member of the source node, and changes will be routed to all relevant nodes that are members of the target node group.  If, for example, the router routes to "all" nodes,
        "all" means every node that is in the target node group.  This is the default behavior of SymmetricDS.
        </p>
        <p>
        Once in production, however, you will likely find you need or want to make configuration changes to triggers and routers as new features are rolled out to your network of SymmetricDS nodes.
        You may, for example, wish to "pilot" a new configuration, containing new synchronizations, only on specific nodes initially, and then increase the size of the pilot over time.
        SymmetricDS' does provide the ability to specify that only particular trigger-router combinations are applicable to particular nodes for this purpose.  It does this
        by allowing you to define an arbitray collection of nodes, called a "grouplet", and then choosing which trigger-routers apply to the normal set of nodes (the default behavior)
        and which apply just to nodes in one or more "grouplets".  This allows you, essentially, to filter the list of nodes that would otherwise be included as source nodes and/or target nodes.
        Through the use of grouplets, you can, for example, specify a subset of nodes on which a given trigger would be created.  It also allows you to
        specify a subset of the normal set of nodes a change would be routed to.  This behaviour is in addition to, and occurs before, any subsetting or filtering the router might otherwise do.
        </p>
        <p>
        In its simplest form, a grouplet is just an arbitrary collection of nodes.  To define a grouplet, you start by creating a grouplet with a unique id, a description, and a link policy,
        as defined in  <a href="#table_grouplet" title="A.11.&nbsp;GROUPLET">GROUPLET</a>.  To defined which nodes are members of (or are not members of) a grouplet, you provide a list of external ids of the nodes
        in <a href="#table_grouplet_link" title="A.12.&nbsp;GROUPLET_LINK">GROUPLET_LINK</a>.  How those external ids are used varies based on the grouplet link policy.
        The <code class="literal">grouplet_link_policy</code> can be either I or E, representing an "inclusive" list of nodes or an "exclusive" list of
        nodes, respectively.  In the case of "inclusive", you'll be listing each external id to be included in the grouplet.  In the case of exclusive, all nodes will be included in
        the grouplet <span class="emphasis"><em>except</em></span> ones which have an external id in the list of external ids.
        </p>

        <p>
        Once you have defined your grouplet and which nodes are members of a grouplet, you can tie a grouplet to a given trigger-router through
        the use of <a href="#table_trigger_router_grouplet" title="A.41.&nbsp;TRIGGER_ROUTER_GROUPLET">TRIGGER_ROUTER_GROUPLET</a>.
        If a particular trigger-router does not appear in this table, SymmetricDS behaves as normal.
        If, however, an entry for a particular trigger-router appears in this table,  the default behavior is overridden based on the <code class="literal">grouplet_id</code> and <code class="literal">applies_when</code> settings.
        The grouplet id provides the node list, and the <code class="literal">applies_when</code> indicates whether the grouplet nodes are to be used to filter the source node list, the target node list,
        or both (settings are "S", "T", and "B", respectively).  Nodes that survive the filtering process on as a source will have a trigger defined, and nodes that survive the filtering process
        as a target are eligible nodes that can be routed to.</p>
         <div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="grouplet-example"></a>6.3.1.&nbsp;Grouplet Example</h3></div></div></div>
            

        <p>

        At this point, an example would probably be useful.  Picture the case where you have 100 retail stores (each containing one database, and each a member of the "store" node group)
        and a central office database (external id of corp, and a member of the "corp" node group ). You wish to pilot two new trigger and routers
        for a new feature on your point-of-sale software (one which moves data from corp to store, and one which moves data from store to corp), but you only want the triggers to be installed on 10 specific stores that represent your "pilot" stores.  In this case,
        the simplest approach would be to define a grouplet with, say, a grouplet id of "pilot".  We'd use a grouplet link policy of "inclusive", and list each of the 10 external ids
        in the <a href="#table_grouplet_link" title="A.12.&nbsp;GROUPLET_LINK">GROUPLET_LINK</a> table.
        </p>
        <p>
        For the trigger-router meant to send data from corp to store, we'd create an entry in <a href="#table_trigger_router_grouplet" title="A.41.&nbsp;TRIGGER_ROUTER_GROUPLET">TRIGGER_ROUTER_GROUPLET</a> for
        our grouplet id of "pilot", and we'd specify "T" (target) as the applies-when setting.  In this way, the source node list is not filtered, but the target node list used during routing
        will filter the potential target nodes to just our pilot stores.  For the trigger-router meant to send data from a pilot store back to corp, we would have the grouplet apply when
        the node is in the source node list (i.e., <code class="literal">applies_when</code> will be "S").  This will cause the trigger to only be created for stores in the pilot list and not other stores.
        </p>
        <p>An important thing to mention in this example:  Since your grouplet only included the store nodes, you can't simply specify "both" for the applies when setting.  For the corp-to-store trigger,
        for example, if you had said "both", no trigger would have been installed in corp since the grouplet nodes represent all possible source nodes as well as target nodes, and "corp" is not in the list!
        The same is true for the store to corp trigger-router as well.  You could, however, use "both" as the applies when if you had included the "corp" external id in with the list of the 10 pilot store external ids.
        </p>
     </div>
    </div>

     <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="resync-data"></a>6.4.&nbsp;Re-synchronizing Data</h2></div></div></div>
        
        <p>
        There may be times where you find you need to re-send or re-synchronize data when the change itself was not captured.  This could be needed, for example,
        if the data changes occurred prior to SymmetricDS placing triggers on the data tables themselves, or if the data at the destination was accidentally deleted, or for
        some other reason.  Two approaches are commonly taken to re-send the data, both of which are discussed below.
        </p>

      <div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
            <p>Be careful when re-sending data using either of these two techniques.  Be sure you are only sending the rows you intend to send and,
            more importantly, be sure to re-send the data in a way that won't cause foreign key constraint issues at the destination.  In other words,
            if more than one table is involved, be sure to send any tables which are referred to by other tables by foreign keys first.  Otherwise,
            the channel's synchronization will block because SymmetricDS is unable to insert or update the row because the foreign key relationship refers to
            a non-existent row in the destination!
           </p>
      </div>

        <p>One possible approach would be to "touch" the rows in individual tables that need re-sent.  By "touch", we mean to alter the row data in such a way
        that SymmetricDS detects a data change and therefore includes the data change in the batching and synchronizing steps.  Note that you have to
        change the data in some meaningful way (e.g., update a time stamp); setting a column to its current value is not sufficient (by default, if there's not an actual data
        value change SymmetricDS won't treat the change as something which needs synched.
        </p>
        <p>A second approach would be to take advantage of SymmetricDS built-in functionality by simulating a partial "initial load" of the data.  The approach
        is to manually create "reload" events in <a href="#table_data" title="A.3.&nbsp;DATA">DATA</a> for the necessary tables, thereby resending the desired rows for the given tables.
        Again, foreign key constraints must be kept in mind when creating these reload events.  These reload events are created in the source database itself, and
        the necessary table, trigger-router combination, and channel are included to indicate the direction of synchronization.</p>
        <p>
        To create a reload event, you create a <a href="#table_data" title="A.3.&nbsp;DATA">DATA</a> row, using:
       </p><div class="itemizedlist"><ul type="disc"><li>data_id:  null</li><li>table_name:  name of table to be sent</li><li>event_type: 'R', for reload</li><li>row_data:  a "where" clause (minus the word 'where') which defines the subset of rows from the table to be sent.  To send all rows, one can use 1=1 for this value.</li><li>pk_data:  null</li><li>old_data: null</li><li>trigger_hist_id:  use the id of the most recent entry (i.e., max(trigger_hist_id) ) in <a href="#table_trigger_hist" title="A.39.&nbsp;TRIGGER_HIST">TRIGGER_HIST</a>
        for the trigger-router combination for your table and router.</li><li>channel_id:  the channel in which the table is routed</li><li>transaction_id:  pick a value, for example '1'</li><li>source_node_id: null</li><li>external_data: null</li><li>create_time:  current_timestamp</li></ul></div><p>
        </p>

        <p>
        By way of example, take our retail hands-on tutorial covered in <a href="#tutorial" title="Chapter&nbsp;2.&nbsp;Quick Start Tutorial">Chapter&nbsp;2, <i xmlns:xlink="http://www.w3.org/1999/xlink">Quick Start Tutorial</i></a>.  Let's say
        we need to re-send a particular sales transaction from the store to corp over again because we lost the data in corp due to
        an overzealous delete.  For the tutorial, all transaction-related tables start with <code class="literal">sale_</code>,
        use the <code class="literal">sale_transaction</code> channel, and are routed using the <code class="literal">store_corp_identity</code>
        router.  In addition, the trigger-routers have been set up with an initial load order based on the necessary
        foreign key relationships (i.e., transaction tables which are "parents" have a lower initial load order than those of their
        "children").  An insert statement that would create the necessary "reload" events (three in this case, one for each table) would be as follows
        (where MISSING_ID is changed to the needed transaction id):
       </p><pre class="programlisting">

insert into sym_data (
    select null, t.source_table_name, 'R', 'tran_id=''MISSING-ID''', null, null,
            h.trigger_hist_id, t.channel_id, '1', null, null, current_timestamp
        from sym_trigger t inner join sym_trigger_router tr on
            t.trigger_id=tr.trigger_id inner join sym_trigger_hist h on
            h.trigger_hist_id=(select max(trigger_hist_id) from sym_trigger_hist
                where trigger_id=t.trigger_id)
    where channel_id='sale_transaction' and
        tr.router_id like 'store_corp_identity' and
        (t.source_table_name like 'sale_%')
    order by tr.initial_load_order asc);
    </pre><p>

    This insert statement generates three rows, one for each configured sale table.  It uses the most recent
    trigger history id for the corresponding table.  Finally, it takes advantage of the initial load order for each trigger-router to
    create the three rows in the correct order (the order corresponding to the order in which the tables would have been initial loaded).

    </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="changing-configuration"></a>6.5.&nbsp;Changing Configuration</h2></div></div></div>
        
        <p>
            The configuration of your system as defined in the <code class="literal">sym_*</code> tables may be modified at runtime.  By default, any changes made to
            the <code class="literal">sym_*</code> tables (with the exception of <code class="literal">sym_node</code>) should be made at the registration server.  The changes will
            be synchronized out to the leaf nodes by SymmetricDS triggers that are automatically created on the tables.
         </p>
         <p>
            If this behavior is not desired, the feature can be turned off using a parameter.  Custom triggers may be added
            to the <code class="literal">sym_*</code> tables when the auto syncing feature is disabled.
        </p>
    </div>

     <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="logging"></a>6.6.&nbsp;Logging Configuration</h2></div></div></div>
        
        <p>
        The standalone SymmetricDS installation uses <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://logging.apache.org/log4j/1.2/index.html" target="_top">Log4J</a> for logging.  The configuration file is  <code class="literal">conf/log4j.xml</code>.
        The <code class="literal">log4j.xml</code> file has hints as to what logging can be enabled for useful, finer-grained logging.
        </p>
        <p>
        There is a command line option to turn on preconfigured debugging levels.  When the <code class="literal">--debug</code> option is used the <code class="literal">conf/debug-log4j.xml</code> is used instead of log4j.xml.
        </p>
        <p>
        SymmetricDS proxies all of its logging through <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://www.slf4j.org/" target="_top">SLF4J</a>.  When deploying to an application server or if Log4J is not
        being leveraged, then the general rules for for SLF4J logging apply.
        </p>
    </div>

     <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="admin-jmx"></a>6.7.&nbsp;Java Management Extensions</h2></div></div></div>
        
        <p>
          Monitoring and administrative operations can be performed using Java Management Extensions (JMX).
          SymmetricDS uses MX4J to expose JMX attributes and operations that can be accessed
          from the built-in web console, Java's jconsole, or an application server.
          By default, the web management console can be opened from the following address:

          </p><pre class="programlisting">http://localhost:31416/</pre><p>

          In order to use jconsole, you must enable JMX remote management in the JVM. You can edit the startup scripts to set the following system
          parameters.

          </p><pre class="programlisting">
          -Dcom.sun.management.jmxremote.port=31417
          -Dcom.sun.management.jmxremote.authenticate=false
          -Dcom.sun.management.jmxremote.ssl=false
          </pre><p>

          More details about enabling JMX for JConsole can be found <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://docs.oracle.com/javase/6/docs/technotes/guides/management/jconsole.html" target="_top">here</a>.
          </p>
          <p>
          Using the Java jconsole command, SymmetricDS is listed as a local process named SymmetricLauncher.
          In jconsole, SymmetricDS appears under the MBeans tab under the name defined by the <code class="literal">engine.name</code>
          property.  The default value is SymmetricDS.
        </p>
        <p>
          The management interfaces under SymmetricDS are organized as follows:

            </p><div class="itemizedlist"><ul type="disc"><li>
                    <p>Node - administrative operations </p>
                </li><li>
                    <p>Parameters - access to properties set through the parameter service </p>
                </li></ul></div><p>

        </p>
    </div>



    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="temporary-files"></a>6.8.&nbsp;Temporary Files</h2></div></div></div>
        
        <p>
        SymmetricDS creates temporary extraction and data load files with the CSV payload of a synchronization when
        the value of the <code class="literal">stream.to.file.threshold.bytes</code> SymmetricDS property has been reached.  Before reaching the threshold, files
        are streamed to/from memory.  The default threshold value is 32,767 bytes. This feature may be turned off by setting the <code class="literal">stream.to.file.enabled</code>
        property to false.
        </p>
        <p>
        SymmetricDS creates these temporary files in the directory specified by the <code class="literal">java.io.tmpdir</code> Java System property.
        </p>
        <p>
        The location of the temporary directory may be changed by setting the Java System property passed into the Java program at startup.  For example,
        </p><pre class="programlisting">
  -Djava.io.tmpdir=/home/.symmetricds/tmp
        </pre><p>
        </p>
    </div>


</div>
    <div class="appendix" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="data-model"></a>Appendix&nbsp;A.&nbsp;Data Model</h2></div></div></div>
    
    <p> 
        What follows is the complete SymmetricDS data model.
        Note that all tables are prepended with a configurable prefix so that multiple instances of SymmetricDS may coexist in the
        same database. The default prefix is
        <span class="emphasis"><em>sym_</em></span>.
    </p>

    <p> 
        SymmetricDS configuration is entered by the user into the data model to control the behavior of what data is synchronized
            to which nodes.
    </p>
    <p>
            </p><div class="figure"><a name="d4e2377"></a><div class="figure-contents">
                
                <div class="mediaobject"><img src="images/data-model-config.gif" alt="Configuration Data Model"></div>
            </div><p class="title"><b>Figure&nbsp;A.1.&nbsp;Configuration Data Model</b></p></div><p><br class="figure-break">
    </p>
        
    <p> At runtime, the configuration is used to capture data changes and route them to nodes. The data changes are placed
            together in a single unit called a batch that can be loaded by another node. Outgoing batches are delivered to nodes
            and acknowledged. Incoming batches are received and loaded. History is recorded for batch status changes and
            statistics.</p>
    <p>
            </p><div class="figure"><a name="d4e2384"></a><div class="figure-contents">
                
                <div class="mediaobject"><img src="images/data-model-runtime.gif" alt="Runtime Data Model"></div>
            </div><p class="title"><b>Figure&nbsp;A.2.&nbsp;Runtime Data Model</b></p></div><p><br class="figure-break">
    </p>
		 
	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_channel"></a>A.1.&nbsp;CHANNEL</h2></div></div></div>
    
    <p>This table represents a category of data that can be synchronized independently of other channels. Channels allow control over the type of data flowing and prevents one type of synchronization from contending with another.</p>
	<div class="table"><a name="table-def-channel"></a><div class="table-contents">
    	
    	<table summary="CHANNEL" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	CHANNEL_ID                </td><td>VARCHAR  (20)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> A unique identifer, usually named something meaningful, like 'sales' or 'inventory'.</td></tr><tr><td>
                 	PROCESSING_ORDER                </td><td>INTEGER </td><td> 1</td><td>				</td><td>X</td><td> Order of sequence to process channel data.</td></tr><tr><td>
                 	MAX_BATCH_SIZE                </td><td>INTEGER </td><td> 1000</td><td>				</td><td>X</td><td> The maximum number of Data Events to process within a batch for this channel.</td></tr><tr><td>
                 	MAX_BATCH_TO_SEND                </td><td>INTEGER </td><td> 60</td><td>				</td><td>X</td><td> The maximum number of batches to send during a 'synchronization' between two nodes. A 'synchronization' is equivalent to a push or a pull. If there are 12 batches ready to be sent for a channel and max_batch_to_send is equal to 10, then only the first 10 batches will be sent.</td></tr><tr><td>
                 	MAX_DATA_TO_ROUTE                </td><td>INTEGER </td><td> 100000</td><td>				</td><td>X</td><td> The maximum number of data rows to route for a channel at a time.</td></tr><tr><td>
                 	EXTRACT_PERIOD_MILLIS                </td><td>INTEGER </td><td> 0</td><td>				</td><td>X</td><td> The minimum number of milliseconds allowed between attempts to extract data for targeted at a node_id.</td></tr><tr><td>
                 	ENABLED                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Indicates whether channel is enabled or not.</td></tr><tr><td>
                 	USE_OLD_DATA_TO_ROUTE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Indicates whether to read the old data during routing.</td></tr><tr><td>
                 	USE_ROW_DATA_TO_ROUTE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Indicates whether to read the row data during routing.</td></tr><tr><td>
                 	USE_PK_DATA_TO_ROUTE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Indicates whether to read the pk data during routing.</td></tr><tr><td>
                 	CONTAINS_BIG_LOB                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>X</td><td> Provides SymmetricDS a hint on how to treat captured data.  Currently only supported by Oracle.  If set to '0', then selects for routing and data extraction will be more efficient and lobs will be truncated at 4k in the trigger text.  When it is set to '0' there is a 4k limit on the total size of a row and on the size of a LOB column.  Note, when switching this value back and forth triggers need to be forced to regenerate.</td></tr><tr><td>
                 	BATCH_ALGORITHM                </td><td>VARCHAR  (50)</td><td> default</td><td>				</td><td>X</td><td> The algorithm to use when batching data on this channel.  Possible values are: 'default', 'transactional', and 'nontransactional'</td></tr><tr><td>
                 	DATA_LOADER_TYPE                </td><td>VARCHAR  (50)</td><td> default</td><td>				</td><td>X</td><td> Identify the type of data loader this channel should use.  Allows for the default dataloader to be swapped out via configuration for more efficient platform specific data loaders.</td></tr><tr><td>
                 	DESCRIPTION                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Description on the type of data carried in this channel.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.1.&nbsp;CHANNEL</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_conflict"></a>A.2.&nbsp;CONFLICT</h2></div></div></div>
    
    <p>Defines how conflicts in row data should be handled during the load process.</p>
	<div class="table"><a name="table-def-conflict"></a><div class="table-contents">
    	
    	<table summary="CONFLICT" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	CONFLICT_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a specific conflict detection setting.</td></tr><tr><td>
                 						 	<a href="#table-def-node_group_link" title="Table&nbsp;A.22.&nbsp;NODE_GROUP_LINK">source_node_group_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				FK</td><td>X</td><td> The source node group for which this setting will be applied to. References a node group link.</td></tr><tr><td>
                 						 	<a href="#table-def-node_group_link" title="Table&nbsp;A.22.&nbsp;NODE_GROUP_LINK">target_node_group_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				FK</td><td>X</td><td> The target node group for which this setting will be applied to.  References a node group link.</td></tr><tr><td>
                 	TARGET_CHANNEL_ID                </td><td>VARCHAR  (20)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional channel that this setting will be applied to.</td></tr><tr><td>
                 	TARGET_CATALOG_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional database catalog that the target table belongs to. Only use this if the target table is not in the default catalog.</td></tr><tr><td>
                 	TARGET_SCHEMA_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional database schema that the target table belongs to. Only use this if the target table is not in the default schema.</td></tr><tr><td>
                 	TARGET_TABLE_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional database table that this setting will apply to.  If left blank, the setting will be for any table in the channel (if set) and in the specified node group link.</td></tr><tr><td>
                 	DETECT_TYPE                </td><td>VARCHAR  (128)</td><td>&nbsp;</td><td>				</td><td>X</td><td> Indicates the strategy to use for detecting conflicts during a dml action.  The possible values are: use_pk_data (manual, fallback, ignore), use_changed_data (manual, fallback, ignore), use_old_data (manual, fallback, ignore), use_timestamp (newer_wins), use_version (newer_wins)</td></tr><tr><td>
                 	DETECT_EXPRESSION                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> An expression that provides additional information about the detection mechanism.  If the detection mechanism is use_timestamp or use_version then this expression will be the name of the timestamp or version column.</td></tr><tr><td>
                 	RESOLVE_TYPE                </td><td>VARCHAR  (128)</td><td>&nbsp;</td><td>				</td><td>X</td><td> Indicates the strategy for resolving update conflicts.  The possible values differ based on the detect_type that is specified.</td></tr><tr><td>
                 	PING_BACK                </td><td>VARCHAR  (128)</td><td>&nbsp;</td><td>				</td><td>X</td><td> Indicates the strategy for sending resolved conflicts back to the source system.  Possible values are: OFF, SINGLE_ROW, and REMAINING_ROWS.</td></tr><tr><td>
                 	RESOLVE_CHANGES_ONLY                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates that when applying changes during an update that only data that has changed should be applied.  Otherwise, all the columns will be updated.  This really only applies to updates.</td></tr><tr><td>
                 	RESOLVE_ROW_ONLY                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates that an action should take place for the entire batch if possible.  This applies to a resolve type of 'ignore'.  If a row is in conflict and the resolve type is 'ignore', then the entire batch will be ignored.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> The date and time when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> The date and time when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.2.&nbsp;CONFLICT</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_data"></a>A.3.&nbsp;DATA</h2></div></div></div>
    
    <p>The captured data change that occurred to a row in the database. Entries in data are created by database triggers.</p>
	<div class="table"><a name="table-def-data"></a><div class="table-contents">
    	
    	<table summary="DATA" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	DATA_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a data.</td></tr><tr><td>
                 	TABLE_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The name of the table in which a change occurred that this entry records.</td></tr><tr><td>
                 	EVENT_TYPE                </td><td>CHAR  (1)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The type of event captured by this entry. For triggers, this is the change that occurred, which is 'I' for insert, 'U' for update, or 'D' for delete. Other events include: 'R' for reloading the entire table (or subset of the table) to the node; 'S' for running dynamic SQL at the node, which is used for adhoc administration.</td></tr><tr><td>
                 	ROW_DATA                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The captured data change from the synchronized table. The column values are stored in comma-separated values (CSV) format.</td></tr><tr><td>
                 	PK_DATA                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The primary key values of the captured data change from the synchronized table. This data is captured for updates and deletes. The primary key values are stored in comma-separated values (CSV) format.</td></tr><tr><td>
                 	OLD_DATA                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The captured data values prior to the update.  The column values are stored in CSV format.</td></tr><tr><td>
                 	TRIGGER_HIST_ID                </td><td>INTEGER </td><td>&nbsp;</td><td>				</td><td>X</td><td> The foreign key to the trigger_hist entry that contains the primary key and column names for the table being synchronized.</td></tr><tr><td>
                 	CHANNEL_ID                </td><td>VARCHAR  (20)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The channel that this data belongs to, such as 'prices'</td></tr><tr><td>
                 	TRANSACTION_ID                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> An optional transaction identifier that links multiple data changes together as the same transaction.</td></tr><tr><td>
                 	SOURCE_NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> If the data was inserted by a SymmetricDS data loader, then the id of the source node is record so that data is not re-routed back to it.</td></tr><tr><td>
                 	EXTERNAL_DATA                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> A field that can be populated by a trigger that uses the EXTERNAL_SELECT</td></tr><tr><td>
                 	NODE_LIST                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> A field that can be populated with a comma separated subset of node ids which will be the only nodes available to the router</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.3.&nbsp;DATA</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_data_event"></a>A.4.&nbsp;DATA_EVENT</h2></div></div></div>
    
    <p>Each row represents the mapping between a data change that was captured and the batch that contains it. Entries in data_event are created as part of the routing process. </p>
	<div class="table"><a name="table-def-data_event"></a><div class="table-contents">
    	
    	<table summary="DATA_EVENT" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	DATA_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Id of the data to be routed.</td></tr><tr><td>
                 	BATCH_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Id of the batch containing the data.</td></tr><tr><td>
                 	ROUTER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Id of the router that routed this data_event.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.4.&nbsp;DATA_EVENT</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_data_gap"></a>A.5.&nbsp;DATA_GAP</h2></div></div></div>
    
    <p>Used only when routing.data.reader.type is set to 'gap.'  Table that tracks gaps in the data table so that they may be processed efficiently, if data shows up.  Gaps can show up in the data table if a database transaction is rolled back.</p>
	<div class="table"><a name="table-def-data_gap"></a><div class="table-contents">
    	
    	<table summary="DATA_GAP" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	START_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The first missing data_id from the data table where a gap is detected.  This could be the last data_id inserted plus one.</td></tr><tr><td>
                 	END_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The last missing data_id from the data table where a gap is detected.  If the start_id is the last data_id inserted plus one, then this field is filled in with a -1.</td></tr><tr><td>
                 	STATUS                </td><td>CHAR  (2)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> GP, SK, or FL.  GP means there is a detected gap.  FL means that the gap has been filled.  SK means that the gap has been skipped either because the gap expired or because no database transaction was detected which means that no data will be committed to fill in the gap.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_HOSTNAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The host who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.5.&nbsp;DATA_GAP</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_extract_request"></a>A.6.&nbsp;EXTRACT_REQUEST</h2></div></div></div>
    
    <p>This table is used internally to request the extract of initial loads asynchronously when the initial load extract job is enabled.</p>
	<div class="table"><a name="table-def-extract_request"></a><div class="table-contents">
    	
    	<table summary="EXTRACT_REQUEST" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	REQUEST_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a request.</td></tr><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The node_id of the batch being loaded.</td></tr><tr><td>
                 	STATUS                </td><td>CHAR  (2)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> NE, OK</td></tr><tr><td>
                 	START_BATCH_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>X</td><td> A load can be split across multiple batches.  This is the first of N batches the load will be split across.</td></tr><tr><td>
                 	END_BATCH_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>X</td><td> This is the last of N batches the load will be split across.</td></tr><tr><td>
                 	TRIGGER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> Unique identifier for a trigger associated with the extract request.</td></tr><tr><td>
                 	ROUTER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> Unique description of the router associated with the extract request.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a process last updated this entry.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.6.&nbsp;EXTRACT_REQUEST</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_file_incoming"></a>A.7.&nbsp;FILE_INCOMING</h2></div></div></div>
    
    <p>As files are loaded from another node the file and source node are captured here for file sync to use to prevent file ping backs in bidirectional file synchronization.</p>
	<div class="table"><a name="table-def-file_incoming"></a><div class="table-contents">
    	
    	<table summary="FILE_INCOMING" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	RELATIVE_DIR                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The path to the file starting at the base_dir and excluding the file name itself.</td></tr><tr><td>
                 	FILE_NAME                </td><td>VARCHAR  (128)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The name of the file that has been loaded.</td></tr><tr><td>
                 	LAST_EVENT_TYPE                </td><td>CHAR  (1)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The type of event that caused the file to be loaded from another node. 'C' is for create, 'M' is for modified, and 'D' is for deleted.</td></tr><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The node_id of the source of the batch being loaded.</td></tr><tr><td>
                 	FILE_MODIFIED_TIME                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The last modified time of the file at the time the file was loaded.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.7.&nbsp;FILE_INCOMING</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_file_snapshot"></a>A.8.&nbsp;FILE_SNAPSHOT</h2></div></div></div>
    
    <p>Table used to capture file changes.  Updates to the table are captured and routed according to the configured file trigger routers.</p>
	<div class="table"><a name="table-def-file_snapshot"></a><div class="table-contents">
    	
    	<table summary="FILE_SNAPSHOT" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	TRIGGER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The id of the trigger that caused this snapshot to be taken.</td></tr><tr><td>
                 	ROUTER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The id of the router that caused this snapshot to be taken.</td></tr><tr><td>
                 	RELATIVE_DIR                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The path to the file starting at the base_dir</td></tr><tr><td>
                 	FILE_NAME                </td><td>VARCHAR  (128)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The name of the file that changed.</td></tr><tr><td>
                 	LAST_EVENT_TYPE                </td><td>CHAR  (1)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The type of event captured by this entry. 'C' is for create, 'M' is for modified, and 'D' is for deleted.</td></tr><tr><td>
                 	CRC32_CHECKSUM                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> File checksum.  Can be used to determine if file content has changed.</td></tr><tr><td>
                 	FILE_SIZE                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The size in bytes of the file at the time this change was detected.</td></tr><tr><td>
                 	FILE_MODIFIED_TIME                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The last modified time of the file at the time this change was detected.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.8.&nbsp;FILE_SNAPSHOT</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_file_trigger"></a>A.9.&nbsp;FILE_TRIGGER</h2></div></div></div>
    
    <p>This table defines files or sets of files for which changes will be captured for file synchronization</p>
	<div class="table"><a name="table-def-file_trigger"></a><div class="table-contents">
    	
    	<table summary="FILE_TRIGGER" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	TRIGGER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a trigger.</td></tr><tr><td>
                 	BASE_DIR                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The base directory on the client that will be synchronized.</td></tr><tr><td>
                 	RECURSE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether to synchronize child directories.</td></tr><tr><td>
                 	INCLUDES_FILES                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Wildcard-enabled, comma-separated list of file to include in synchronization.</td></tr><tr><td>
                 	EXCLUDES_FILES                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Wildcard-enabled, comma-separated list of file to exclude from synchronization.</td></tr><tr><td>
                 	SYNC_ON_CREATE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether to capture and send files when they are created.</td></tr><tr><td>
                 	SYNC_ON_MODIFIED                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether to capture and send files when they are modified.</td></tr><tr><td>
                 	SYNC_ON_DELETE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether to capture and remove files when they are deleted.</td></tr><tr><td>
                 	BEFORE_COPY_SCRIPT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> A bsh script that is run right before the file copy.</td></tr><tr><td>
                 	AFTER_COPY_SCRIPT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> A bsh script that is run right after the file copy.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp of when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp of when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.9.&nbsp;FILE_TRIGGER</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_file_trigger_router"></a>A.10.&nbsp;FILE_TRIGGER_ROUTER</h2></div></div></div>
    
    <p>Maps a file trigger to a router.</p>
	<div class="table"><a name="table-def-file_trigger_router"></a><div class="table-contents">
    	
    	<table summary="FILE_TRIGGER_ROUTER" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 						 	<a href="#table-def-file_trigger" title="Table&nbsp;A.9.&nbsp;FILE_TRIGGER">trigger_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The id of a file trigger.</td></tr><tr><td>
                 						 	<a href="#table-def-router" title="Table&nbsp;A.33.&nbsp;ROUTER">router_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The id of a router.</td></tr><tr><td>
                 	ENABLED                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Indicates whether this file trigger router is enabled or not.</td></tr><tr><td>
                 	INITIAL_LOAD_ENABLED                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Indicates whether this file trigger should be initial loaded.</td></tr><tr><td>
                 	TARGET_BASE_DIR                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The base directory on the destination that files will be synchronized to.</td></tr><tr><td>
                 	CONFLICT_STRATEGY                </td><td>VARCHAR  (128)</td><td> source_wins</td><td>				</td><td>X</td><td> The strategy to employ when a file has been modified at both the client and the server.  Possible values are: source_wins, target_wins, manual</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.10.&nbsp;FILE_TRIGGER_ROUTER</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_grouplet"></a>A.11.&nbsp;GROUPLET</h2></div></div></div>
    
    <p>This tables defines named groups to which nodes can belong to based on their external id.  Grouplets are used to designate that synchronization should only affect an explicit subset of nodes in a node group.</p>
	<div class="table"><a name="table-def-grouplet"></a><div class="table-contents">
    	
    	<table summary="GROUPLET" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	GROUPLET_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for the grouplet.</td></tr><tr><td>
                 	GROUPLET_LINK_POLICY                </td><td>CHAR  (1)</td><td> I</td><td>				</td><td>X</td><td> Specified whether the external ids in the grouplet_link are included in the group or excluded from the grouplet.  In the case of excluded, the grouplet starts with all external ids and removes the excluded ones listed.  Use 'I' for inclusive and 'E' for exclusive.</td></tr><tr><td>
                 	DESCRIPTION                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> A description of this grouplet.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.11.&nbsp;GROUPLET</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_grouplet_link"></a>A.12.&nbsp;GROUPLET_LINK</h2></div></div></div>
    
    <p>This tables defines nodes belong to a grouplet based on their external.id</p>
	<div class="table"><a name="table-def-grouplet_link"></a><div class="table-contents">
    	
    	<table summary="GROUPLET_LINK" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 						 	<a href="#table-def-grouplet" title="Table&nbsp;A.11.&nbsp;GROUPLET">grouplet_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> Unique identifier for the grouplet.</td></tr><tr><td>
                 	EXTERNAL_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Provides a means to select the nodes that belong to a grouplet. </td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.12.&nbsp;GROUPLET_LINK</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_incoming_batch"></a>A.13.&nbsp;INCOMING_BATCH</h2></div></div></div>
    
    <p>The incoming_batch is used for tracking the status of loading an outgoing_batch from another node. Data is loaded and commited at the batch level. The status of the incoming_batch is either successful (OK) or error (ER). </p>
	<div class="table"><a name="table-def-incoming_batch"></a><div class="table-contents">
    	
    	<table summary="INCOMING_BATCH" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	BATCH_ID                </td><td>BIGINT  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The id of the outgoing_batch that is being loaded.</td></tr><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The node_id of the source of the batch being loaded.</td></tr><tr><td>
                 	CHANNEL_ID                </td><td>VARCHAR  (20)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The channel_id of the batch being loaded.</td></tr><tr><td>
                 	STATUS                </td><td>CHAR  (2)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The current status of the batch can be loading (LD), successfully loaded (OK), in error (ER) or skipped (SK)</td></tr><tr><td>
                 	ERROR_FLAG                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> A flag that indicates that this batch was in error during the last synchornization attempt.</td></tr><tr><td>
                 	NETWORK_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of milliseconds spent transfering this batch across the network.</td></tr><tr><td>
                 	FILTER_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of milliseconds spent in filters processing data.</td></tr><tr><td>
                 	DATABASE_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of milliseconds spent loading the data into the target database.</td></tr><tr><td>
                 	FAILED_ROW_NUMBER                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> This numbered data event that failed as read from the CSV.</td></tr><tr><td>
                 	FAILED_LINE_NUMBER                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The current line number in the CSV for this batch that failed.</td></tr><tr><td>
                 	BYTE_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of bytes that were sent as part of this batch.</td></tr><tr><td>
                 	STATEMENT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of statements run to load this batch.</td></tr><tr><td>
                 	FALLBACK_INSERT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of times an update was turned into an insert because the data was not already in the target database.</td></tr><tr><td>
                 	FALLBACK_UPDATE_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of times an insert was turned into an update because a data row already existed in the target database.</td></tr><tr><td>
                 	IGNORE_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of times a row was ignored.</td></tr><tr><td>
                 	MISSING_DELETE_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of times a delete did not affect the database because the row was already deleted.</td></tr><tr><td>
                 	SKIP_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of times a batch was sent and skipped because it had already been loaded according to incoming_batch.</td></tr><tr><td>
                 	SQL_STATE                </td><td>VARCHAR  (10)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> For a status of error (ER), this is the XOPEN or SQL 99 SQL State.</td></tr><tr><td>
                 	SQL_CODE                </td><td>INTEGER </td><td> 0</td><td>				</td><td>X</td><td> For a status of error (ER), this is the error code from the database that is specific to the vendor. </td></tr><tr><td>
                 	SQL_MESSAGE                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> For a status of error (ER), this is the error message that describes the error.</td></tr><tr><td>
                 	LAST_UPDATE_HOSTNAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The host name of the process that last did work on this batch.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a process last updated this entry.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.13.&nbsp;INCOMING_BATCH</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_incoming_error"></a>A.14.&nbsp;INCOMING_ERROR</h2></div></div></div>
    
    <p>The captured data change that is in error for a batch.  The user can tell the system what to do by updating the resolve columns.  Entries in data_error are created when an incoming batch encounters an error.</p>
	<div class="table"><a name="table-def-incoming_error"></a><div class="table-contents">
    	
    	<table summary="INCOMING_ERROR" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	BATCH_ID                </td><td>BIGINT  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The id of the outgoing_batch that is being loaded.</td></tr><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The node_id of the source of the batch being loaded.</td></tr><tr><td>
                 	FAILED_ROW_NUMBER                </td><td>BIGINT </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The row number in the batch that encountered an error when loading.</td></tr><tr><td>
                 	FAILED_LINE_NUMBER                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The current line number in the CSV for this batch that failed.</td></tr><tr><td>
                 	TARGET_CATALOG_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The catalog name for the table being loaded.</td></tr><tr><td>
                 	TARGET_SCHEMA_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The schema name for the table being loaded.</td></tr><tr><td>
                 	TARGET_TABLE_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The table name for the table being loaded.</td></tr><tr><td>
                 	EVENT_TYPE                </td><td>CHAR  (1)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The type of event captured by this entry. For triggers, this is the change that occurred, which is 'I' for insert, 'U' for update, or 'D' for delete. Other events include: 'R' for reloading the entire table (or subset of the table) to the node; 'S' for running dynamic SQL at the node, which is used for adhoc administration.</td></tr><tr><td>
                 	BINARY_ENCODING                </td><td>VARCHAR  (10)</td><td> HEX</td><td>				</td><td>X</td><td> The type of encoding the source system used for encoding binary data.</td></tr><tr><td>
                 	COLUMN_NAMES                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>X</td><td> The column names defined on the table. The column names are stored in comma-separated values (CSV) format.</td></tr><tr><td>
                 	PK_COLUMN_NAMES                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>X</td><td> The primary key column names defined on the table. The column names are stored in comma-separated values (CSV) format.</td></tr><tr><td>
                 	ROW_DATA                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The row data from the batch as captured from the source. The column values are stored in comma-separated values (CSV) format.</td></tr><tr><td>
                 	OLD_DATA                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The old row data prior to update from the batch as captured from the source.  The column values are stored in CSV format.</td></tr><tr><td>
                 	CUR_DATA                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The current row data that caused the error to occur.  The column values are stored in CSV format.</td></tr><tr><td>
                 	RESOLVE_DATA                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The capture data change from the user that is used instead of row_data.  This is useful when resolving a conflict manually by specifying the data that should load.</td></tr><tr><td>
                 	RESOLVE_IGNORE                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indication from the user that the row_data should be ignored and the batch can continue loading with the next row.</td></tr><tr><td>
                 	CONFLICT_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Unique identifier for the conflict detection setting that caused the error</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.14.&nbsp;INCOMING_ERROR</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_load_filter"></a>A.15.&nbsp;LOAD_FILTER</h2></div></div></div>
    
    <p>A table that allows you to dynamically define filters using bsh.</p>
	<div class="table"><a name="table-def-load_filter"></a><div class="table-contents">
    	
    	<table summary="LOAD_FILTER" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	LOAD_FILTER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The id of the load filter.</td></tr><tr><td>
                 	LOAD_FILTER_TYPE                </td><td>VARCHAR  (10)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The type of load filter.  Currently 'bsh'.  May add 'sql' in the future.</td></tr><tr><td>
                 	SOURCE_NODE_GROUP_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The source node group for the filter.</td></tr><tr><td>
                 	TARGET_NODE_GROUP_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The destination node group for the filter.</td></tr><tr><td>
                 	TARGET_CATALOG_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name for the catalog the configured table is in.</td></tr><tr><td>
                 	TARGET_SCHEMA_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name for the schema a configured table is in.</td></tr><tr><td>
                 	TARGET_TABLE_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The name of the target table that will trigger the bsh filter.</td></tr><tr><td>
                 	FILTER_ON_UPDATE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether or not the filter should apply on an update.</td></tr><tr><td>
                 	FILTER_ON_INSERT                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether or not the filter should apply on an insert.</td></tr><tr><td>
                 	FILTER_ON_DELETE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether or not the filter should apply on a delete.</td></tr><tr><td>
                 	BEFORE_WRITE_SCRIPT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The script to apply before the write is completed.</td></tr><tr><td>
                 	AFTER_WRITE_SCRIPT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The script to apply after the write is completed.</td></tr><tr><td>
                 	BATCH_COMPLETE_SCRIPT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The script to apply on batch complete.</td></tr><tr><td>
                 	BATCH_COMMIT_SCRIPT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The script to apply on batch commit.</td></tr><tr><td>
                 	BATCH_ROLLBACK_SCRIPT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The script to apply on batch rollback.</td></tr><tr><td>
                 	HANDLE_ERROR_SCRIPT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The script to apply when data cannot be processed.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr><tr><td>
                 	LOAD_FILTER_ORDER                </td><td>INTEGER </td><td> 1</td><td>				</td><td>X</td><td> Specifies the order in which to apply load filters if more than one target operation occurs.</td></tr><tr><td>
                 	FAIL_ON_ERROR                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>X</td><td> Whether we should fail the batch if the filter fails.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.15.&nbsp;LOAD_FILTER</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_lock"></a>A.16.&nbsp;LOCK</h2></div></div></div>
    
    <p>Contains semaphores that are set when processes run, so that only one server can run a process at a time.  Enable this feature by using the cluster.lock.during.xxxx parameters.</p>
	<div class="table"><a name="table-def-lock"></a><div class="table-contents">
    	
    	<table summary="LOCK" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	LOCK_ACTION                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The process that needs a lock.</td></tr><tr><td>
                 	LOCKING_SERVER_ID                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The name of the server that currently has a lock.  This is typically a host name, but it can be overridden using the -Druntime.symmetric.cluster.server.id=name System property.</td></tr><tr><td>
                 	LOCK_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The time a lock is aquired.  Use the cluster.lock.timeout.ms to specify a lock timeout period.</td></tr><tr><td>
                 	LAST_LOCK_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a process last updated this entry.</td></tr><tr><td>
                 	LAST_LOCKING_SERVER_ID                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The server id of the process that last did work on this batch.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.16.&nbsp;LOCK</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node"></a>A.17.&nbsp;NODE</h2></div></div></div>
    
    <p>Representation of an instance of SymmetricDS that synchronizes data with one or more additional nodes. Each node has a unique identifier (nodeId) that is used when communicating, as well as a domain-specific identifier (externalId) that provides context within the local system.</p>
	<div class="table"><a name="table-def-node"></a><div class="table-contents">
    	
    	<table summary="NODE" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> A unique identifier for a node.</td></tr><tr><td>
                 	NODE_GROUP_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The node group that this node belongs to, such as 'store'.</td></tr><tr><td>
                 	EXTERNAL_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> A domain-specific identifier for context within the local system. For example, the retail store number. </td></tr><tr><td>
                 	SYNC_ENABLED                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates whether this node should be sent synchronization. Disabled nodes are ignored by the triggers, so no entries are made in data_event for the node.</td></tr><tr><td>
                 	SYNC_URL                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The URL to contact the node for synchronization.</td></tr><tr><td>
                 	SCHEMA_VERSION                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The version of the database schema this node manages. Useful for specifying synchronization by version. </td></tr><tr><td>
                 	SYMMETRIC_VERSION                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The version of SymmetricDS running at this node.</td></tr><tr><td>
                 	DATABASE_TYPE                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The database product name at this node as reported by JDBC.</td></tr><tr><td>
                 	DATABASE_VERSION                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The database product version at this node as reported by JDBC.</td></tr><tr><td>
                 	HEARTBEAT_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Deprecated.  Use node_host.heartbeat_time instead.</td></tr><tr><td>
                 	TIMEZONE_OFFSET                </td><td>VARCHAR  (6)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Deprecated.  Use node_host.timezone_offset instead.</td></tr><tr><td>
                 	BATCH_TO_SEND_COUNT                </td><td>INTEGER </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of outgoing batches that have not yet been sent.  This field is updated as part of the heartbeat job if the heartbeat.update.node.with.batch.status property is set to true.</td></tr><tr><td>
                 	BATCH_IN_ERROR_COUNT                </td><td>INTEGER </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of outgoing batches that are in error at this node.  This field is updated as part of the heartbeat job if the heartbeat.update.node.with.batch.status property is set to true.</td></tr><tr><td>
                 	CREATED_AT_NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The node_id of the node where this node was created. This is typically filled automatically with the node_id found in node_identity where registration was opened for the node. </td></tr><tr><td>
                 	DEPLOYMENT_TYPE                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> An indicator as to the type of SymmetricDS software that is running.  Possible values are, but not limited to: engine, standalone, war, professional, mobile</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.17.&nbsp;NODE</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_communication"></a>A.18.&nbsp;NODE_COMMUNICATION</h2></div></div></div>
    
    <p>This table is used to coordinate communication with other nodes.</p>
	<div class="table"><a name="table-def-node_communication"></a><div class="table-contents">
    	
    	<table summary="NODE_COMMUNICATION" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a node.</td></tr><tr><td>
                 	COMMUNICATION_TYPE                </td><td>VARCHAR  (10)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The type of communication that is taking place with this node.  Valid values are: PULL, PUSH</td></tr><tr><td>
                 	LOCK_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The timestamp when this node was locked</td></tr><tr><td>
                 	LOCKING_SERVER_ID                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The name of the server that currently has a pull lock for the node.  This is typically a host name, but it can be overridden using the -Druntime.symmetric.cluster.server.id=name System property.</td></tr><tr><td>
                 	LAST_LOCK_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The timestamp when this node was last locked</td></tr><tr><td>
                 	LAST_LOCK_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The amount of time the last communication took.</td></tr><tr><td>
                 	SUCCESS_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of successive successful communication attempts.</td></tr><tr><td>
                 	FAIL_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of successive failed communication attempts.</td></tr><tr><td>
                 	TOTAL_SUCCESS_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The total number of successful communication attempts with the node.</td></tr><tr><td>
                 	TOTAL_FAIL_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The total number of failed communication attempts with the node.</td></tr><tr><td>
                 	TOTAL_SUCCESS_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The total amount of time spent during successful communication attempts with the node.</td></tr><tr><td>
                 	TOTAL_FAIL_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The total amount of time spent during failed communication attempts with the node.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.18.&nbsp;NODE_COMMUNICATION</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_channel_ctl"></a>A.19.&nbsp;NODE_CHANNEL_CTL</h2></div></div></div>
    
    <p>Used to ignore or suspend a channel. A channel that is ignored will have its data_events batched and they will immediately be marked as 'OK' without sending them. A channel that is suspended is skipped when batching data_events.</p>
	<div class="table"><a name="table-def-node_channel_ctl"></a><div class="table-contents">
    	
    	<table summary="NODE_CHANNEL_CTL" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a node.</td></tr><tr><td>
                 	CHANNEL_ID                </td><td>VARCHAR  (20)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The name of the channel_id that is being controlled.</td></tr><tr><td>
                 	SUSPEND_ENABLED                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates if this channel is suspended, which prevents its Data Events from being batched.</td></tr><tr><td>
                 	IGNORE_ENABLED                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates if this channel is ignored, which marks its Data Events as if they were actually processed.</td></tr><tr><td>
                 	LAST_EXTRACT_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Record the last time data was extract for a node and a channel.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.19.&nbsp;NODE_CHANNEL_CTL</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_group"></a>A.20.&nbsp;NODE_GROUP</h2></div></div></div>
    
    <p>A category of Nodes that synchronizes data with one or more NodeGroups. A common use of NodeGroup is to describe a level in a hierarchy of data synchronization.</p>
	<div class="table"><a name="table-def-node_group"></a><div class="table-contents">
    	
    	<table summary="NODE_GROUP" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	NODE_GROUP_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a node group, usually named something meaningful, like 'store' or 'warehouse'.</td></tr><tr><td>
                 	DESCRIPTION                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> A description of this node group.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.20.&nbsp;NODE_GROUP</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_group_channel_wnd"></a>A.21.&nbsp;NODE_GROUP_CHANNEL_WND</h2></div></div></div>
    
    <p>An optional window of time for which a node group and channel will extract and send data.</p>
	<div class="table"><a name="table-def-node_group_channel_wnd"></a><div class="table-contents">
    	
    	<table summary="NODE_GROUP_CHANNEL_WND" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	NODE_GROUP_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The node_group_id that this window applies to.</td></tr><tr><td>
                 	CHANNEL_ID                </td><td>VARCHAR  (20)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The channel_id that this window applies to.</td></tr><tr><td>
                 	START_TIME                </td><td>TIME </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The start time for the active window.</td></tr><tr><td>
                 	END_TIME                </td><td>TIME </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The end time for the active window.  Note that if the end_time is less than the start_time then the window crosses a day boundary.</td></tr><tr><td>
                 	ENABLED                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>X</td><td> Enable this window.  If this is set to '0' then this window is ignored.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.21.&nbsp;NODE_GROUP_CHANNEL_WND</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_group_link"></a>A.22.&nbsp;NODE_GROUP_LINK</h2></div></div></div>
    
    <p>A source node_group sends its data updates to a target NodeGroup using a pull, push, or custom technique.</p>
	<div class="table"><a name="table-def-node_group_link"></a><div class="table-contents">
    	
    	<table summary="NODE_GROUP_LINK" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 						 	<a href="#table-def-node_group" title="Table&nbsp;A.20.&nbsp;NODE_GROUP">source_node_group_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The node group where data changes should be captured.</td></tr><tr><td>
                 						 	<a href="#table-def-node_group" title="Table&nbsp;A.20.&nbsp;NODE_GROUP">target_node_group_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The node group where data changes will be sent.</td></tr><tr><td>
                 	DATA_EVENT_ACTION                </td><td>CHAR  (1)</td><td> W</td><td>				</td><td>X</td><td> The notification scheme used to send data changes to the target node group. (P = Push, W = Wait for Pull, ) </td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.22.&nbsp;NODE_GROUP_LINK</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_host"></a>A.23.&nbsp;NODE_HOST</h2></div></div></div>
    
    <p>Representation of an physical workstation or server that is hosting the SymmetricDS software. In a clustered environment there may be more than one entry per node in this table.</p>
	<div class="table"><a name="table-def-node_host"></a><div class="table-contents">
    	
    	<table summary="NODE_HOST" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 						 	<a href="#table-def-node" title="Table&nbsp;A.17.&nbsp;NODE">node_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> A unique identifier for a node.</td></tr><tr><td>
                 	HOST_NAME                </td><td>VARCHAR  (60)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The host name of a workstation or server. If more than one instance of SymmetricDS runs on the same server, then this value can be a 'server id' specified by -Druntime.symmetric.cluster.server.id</td></tr><tr><td>
                 	IP_ADDRESS                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The ip address for the host.</td></tr><tr><td>
                 	OS_USER                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user SymmetricDS is running under</td></tr><tr><td>
                 	OS_NAME                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The name of the OS</td></tr><tr><td>
                 	OS_ARCH                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The hardware architecture of the OS</td></tr><tr><td>
                 	OS_VERSION                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The version of the OS</td></tr><tr><td>
                 	AVAILABLE_PROCESSORS                </td><td>INTEGER </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of processors available to use.</td></tr><tr><td>
                 	FREE_MEMORY_BYTES                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The amount of free memory available to the JVM.</td></tr><tr><td>
                 	TOTAL_MEMORY_BYTES                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The amount of total memory available to the JVM.</td></tr><tr><td>
                 	MAX_MEMORY_BYTES                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The max amount of memory available to the JVM.</td></tr><tr><td>
                 	JAVA_VERSION                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The version of java that SymmetricDS is running as.</td></tr><tr><td>
                 	JAVA_VENDOR                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The vendor of java that SymmetricDS is running as.</td></tr><tr><td>
                 	SYMMETRIC_VERSION                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The version of SymmetricDS running at this node.</td></tr><tr><td>
                 	TIMEZONE_OFFSET                </td><td>VARCHAR  (6)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The time zone offset in RFC822 format at the time of the last heartbeat. </td></tr><tr><td>
                 	HEARTBEAT_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The last timestamp when the node sent a heartbeat, which is attempted every ten minutes by default.</td></tr><tr><td>
                 	LAST_RESTART_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this instance was last restarted.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.23.&nbsp;NODE_HOST</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_host_channel_stats"></a>A.24.&nbsp;NODE_HOST_CHANNEL_STATS</h2></div></div></div>
    
    <p></p>
	<div class="table"><a name="table-def-node_host_channel_stats"></a><div class="table-contents">
    	
    	<table summary="NODE_HOST_CHANNEL_STATS" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> A unique identifier for a node.</td></tr><tr><td>
                 	HOST_NAME                </td><td>VARCHAR  (60)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The host name of a workstation or server. If more than one instance of SymmetricDS runs on the same server, then this value can be a 'server id' specified by -Druntime.symmetric.cluster.server.id</td></tr><tr><td>
                 	CHANNEL_ID                </td><td>VARCHAR  (20)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The channel_id of the channel that data changes will flow through.</td></tr><tr><td>
                 	START_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The start time for the period which this row represents.</td></tr><tr><td>
                 	END_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The end time for the period which this row represents.</td></tr><tr><td>
                 	DATA_ROUTED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicate the number of data rows that have been routed during this period.</td></tr><tr><td>
                 	DATA_UNROUTED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The amount of data that has not yet been routed at the time this stats row was recorded.</td></tr><tr><td>
                 	DATA_EVENT_INSERTED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicate the number of data rows that have been routed during this period.</td></tr><tr><td>
                 	DATA_EXTRACTED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of data rows that were extracted during this time period.</td></tr><tr><td>
                 	DATA_BYTES_EXTRACTED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of bytes that were extracted during this time period.</td></tr><tr><td>
                 	DATA_EXTRACTED_ERRORS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of errors that occurred during extraction during this time period.</td></tr><tr><td>
                 	DATA_BYTES_SENT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of bytes that were sent during this time period.</td></tr><tr><td>
                 	DATA_SENT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of rows that were sent during this time period.</td></tr><tr><td>
                 	DATA_SENT_ERRORS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of errors that occurred while sending during this time period.</td></tr><tr><td>
                 	DATA_LOADED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of rows that were loaded during this time period.</td></tr><tr><td>
                 	DATA_BYTES_LOADED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of bytes that were loaded during this time period.</td></tr><tr><td>
                 	DATA_LOADED_ERRORS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of errors that occurred while loading during this time period.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.24.&nbsp;NODE_HOST_CHANNEL_STATS</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_host_job_stats"></a>A.25.&nbsp;NODE_HOST_JOB_STATS</h2></div></div></div>
    
    <p></p>
	<div class="table"><a name="table-def-node_host_job_stats"></a><div class="table-contents">
    	
    	<table summary="NODE_HOST_JOB_STATS" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> A unique identifier for a node.</td></tr><tr><td>
                 	HOST_NAME                </td><td>VARCHAR  (60)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The host name of a workstation or server. If more than one instance of SymmetricDS runs on the same server, then this value can be a 'server id' specified by -Druntime.symmetric.cluster.server.id</td></tr><tr><td>
                 	JOB_NAME                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The name of the job.</td></tr><tr><td>
                 	START_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The start time for the period which this row represents.</td></tr><tr><td>
                 	END_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The end time for the period which this row represents.</td></tr><tr><td>
                 	PROCESSED_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of items that were processed during the job run.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.25.&nbsp;NODE_HOST_JOB_STATS</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_host_stats"></a>A.26.&nbsp;NODE_HOST_STATS</h2></div></div></div>
    
    <p></p>
	<div class="table"><a name="table-def-node_host_stats"></a><div class="table-contents">
    	
    	<table summary="NODE_HOST_STATS" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> A unique identifier for a node.</td></tr><tr><td>
                 	HOST_NAME                </td><td>VARCHAR  (60)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The host name of a workstation or server. If more than one instance of SymmetricDS runs on the same server, then this value can be a 'server id' specified by -Druntime.symmetric.cluster.server.id</td></tr><tr><td>
                 	START_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The end time for the period which this row represents.</td></tr><tr><td>
                 	END_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> </td></tr><tr><td>
                 	RESTARTED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> Indicate that a restart occurred during this period.</td></tr><tr><td>
                 	NODES_PULLED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	TOTAL_NODES_PULL_TIME                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	NODES_PUSHED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	TOTAL_NODES_PUSH_TIME                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	NODES_REJECTED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	NODES_REGISTERED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	NODES_LOADED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	NODES_DISABLED                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	PURGED_DATA_ROWS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	PURGED_DATA_EVENT_ROWS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	PURGED_BATCH_OUTGOING_ROWS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	PURGED_BATCH_INCOMING_ROWS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	TRIGGERS_CREATED_COUNT                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	TRIGGERS_REBUILT_COUNT                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> </td></tr><tr><td>
                 	TRIGGERS_REMOVED_COUNT                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> </td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.26.&nbsp;NODE_HOST_STATS</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_identity"></a>A.27.&nbsp;NODE_IDENTITY</h2></div></div></div>
    
    <p>After registration, this table will have one row representing the identity of the node. For a root node, the row is entered by the user.</p>
	<div class="table"><a name="table-def-node_identity"></a><div class="table-contents">
    	
    	<table summary="NODE_IDENTITY" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 						 	<a href="#table-def-node" title="Table&nbsp;A.17.&nbsp;NODE">node_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> Unique identifier for a node.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.27.&nbsp;NODE_IDENTITY</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_node_security"></a>A.28.&nbsp;NODE_SECURITY</h2></div></div></div>
    
    <p>Security features like node passwords and open registration flag are stored in the node_security table. </p>
	<div class="table"><a name="table-def-node_security"></a><div class="table-contents">
    	
    	<table summary="NODE_SECURITY" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 						 	<a href="#table-def-node" title="Table&nbsp;A.17.&nbsp;NODE">node_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> Unique identifier for a node.</td></tr><tr><td>
                 	NODE_PASSWORD                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The password used by the node to prove its identity during synchronization.</td></tr><tr><td>
                 	REGISTRATION_ENABLED                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates whether registration is open for this node.  Re-registration may be forced for a node if this is set back to '1' in a parent database for the node_id that should be re-registred.</td></tr><tr><td>
                 	REGISTRATION_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The timestamp when this node was last registered.</td></tr><tr><td>
                 	INITIAL_LOAD_ENABLED                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates whether an initial load will be sent to this node.</td></tr><tr><td>
                 	INITIAL_LOAD_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The timestamp when an initial load was started for this node.</td></tr><tr><td>
                 	INITIAL_LOAD_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> A reference to the load_id in outgoing_batch for the last load that occurred.</td></tr><tr><td>
                 	INITIAL_LOAD_CREATE_BY                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user that created the initial load.  A null value means that the system created the batch.</td></tr><tr><td>
                 	REV_INITIAL_LOAD_ENABLED                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates that this node should send a reverse initial load.</td></tr><tr><td>
                 	REV_INITIAL_LOAD_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The timestamp when this node last sent an initial load.</td></tr><tr><td>
                 	REV_INITIAL_LOAD_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> A reference to the load_id in outgoing_batch for the last reverse load that occurred.</td></tr><tr><td>
                 	REV_INITIAL_LOAD_CREATE_BY                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user that created the reverse initial load.  A null value means that the system created the batch.</td></tr><tr><td>
                 	CREATED_AT_NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The node_id of the node where this node was created. This is typically filled automatically with the node_id found in node_identity where registration was opened for the node. </td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.28.&nbsp;NODE_SECURITY</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_outgoing_batch"></a>A.29.&nbsp;OUTGOING_BATCH</h2></div></div></div>
    
    <p>Used for tracking the sending a collection of data to a node in the system. A new outgoing_batch is created and given a status of 'NE'. After sending the outgoing_batch to its target node, the status becomes 'SE'. The node responds with either a success status of 'OK' or an error status of 'ER'. An error while sending to the node also results in an error status of 'ER' regardless of whether the node sends that acknowledgement. </p>
	<div class="table"><a name="table-def-outgoing_batch"></a><div class="table-contents">
    	
    	<table summary="OUTGOING_BATCH" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	BATCH_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> A unique id for the batch.</td></tr><tr><td>
                 	NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The node that this batch is targeted at.</td></tr><tr><td>
                 	CHANNEL_ID                </td><td>VARCHAR  (20)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The channel that this batch is part of.</td></tr><tr><td>
                 	STATUS                </td><td>CHAR  (2)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The current status of a batch can be routing (RT), newly created and ready for replication (NE), being queried from the database (QY), sent to a Node (SE), ready to be loaded (LD) and acknowledged as successful (OK), ignored (IG) or in error (ER).</td></tr><tr><td>
                 	LOAD_ID                </td><td>BIGINT </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> An id that ties multiple batches together to identify them as being part of an initial load.</td></tr><tr><td>
                 	EXTRACT_JOB_FLAG                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> A flag that indicates that this batch is going to be extracted by another job.</td></tr><tr><td>
                 	LOAD_FLAG                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> A flag that indicates that this batch is part of an initial load.</td></tr><tr><td>
                 	ERROR_FLAG                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> A flag that indicates that this batch was in error during the last synchornization attempt.</td></tr><tr><td>
                 	COMMON_FLAG                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> A flag that indicates that the data in this batch is shared by other nodes (they will have the same batch_id).  Shared batches will be extracted to a common location.</td></tr><tr><td>
                 	IGNORE_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of times a batch was ignored.</td></tr><tr><td>
                 	BYTE_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of bytes that were sent as part of this batch.</td></tr><tr><td>
                 	EXTRACT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of times this an attempt to extract this batch occurred.</td></tr><tr><td>
                 	SENT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of times this batch was sent.  A batch can be sent multiple times if an ACK is not received.</td></tr><tr><td>
                 	LOAD_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of times an attempt to load this batch occurred.</td></tr><tr><td>
                 	DATA_EVENT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of data_events that are part of this batch.</td></tr><tr><td>
                 	RELOAD_EVENT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of reload events that are part of this batch.</td></tr><tr><td>
                 	INSERT_EVENT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of insert events that are part of this batch.</td></tr><tr><td>
                 	UPDATE_EVENT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of update events that are part of this batch.</td></tr><tr><td>
                 	DELETE_EVENT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of delete events that are part of this batch.</td></tr><tr><td>
                 	OTHER_EVENT_COUNT                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of other event types that are part of this batch.  This includes any events types that are not a reload, insert, update or delete event type.</td></tr><tr><td>
                 	ROUTER_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of milliseconds spent creating this batch.</td></tr><tr><td>
                 	NETWORK_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of milliseconds spent transfering this batch across the network.</td></tr><tr><td>
                 	FILTER_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of milliseconds spent in filters processing data.</td></tr><tr><td>
                 	LOAD_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of milliseconds spent loading the data into the target database.</td></tr><tr><td>
                 	EXTRACT_MILLIS                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The number of milliseconds spent extracting the data out of the source database.</td></tr><tr><td>
                 	SQL_STATE                </td><td>VARCHAR  (10)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> For a status of error (ER), this is the XOPEN or SQL 99 SQL State.</td></tr><tr><td>
                 	SQL_CODE                </td><td>INTEGER </td><td> 0</td><td>				</td><td>X</td><td> For a status of error (ER), this is the error code from the database that is specific to the vendor. </td></tr><tr><td>
                 	SQL_MESSAGE                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> For a status of error (ER), this is the error message that describes the error.</td></tr><tr><td>
                 	FAILED_DATA_ID                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> For a status of error (ER), this is the data_id that was being processed when the batch failed.</td></tr><tr><td>
                 	FAILED_LINE_NUMBER                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The current line number in the CSV for this batch that failed.</td></tr><tr><td>
                 	LAST_UPDATE_HOSTNAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The host name of the process that last did work on this batch.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a process last updated this entry.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	CREATE_BY                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user that created the batch.  A null value means that the system created the batch.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.29.&nbsp;OUTGOING_BATCH</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_parameter"></a>A.30.&nbsp;PARAMETER</h2></div></div></div>
    
    <p>Provides a way to manage most SymmetricDS settings in the database.</p>
	<div class="table"><a name="table-def-parameter"></a><div class="table-contents">
    	
    	<table summary="PARAMETER" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	EXTERNAL_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Target the parameter at a specific external id. To target all nodes, use the value of 'ALL.'</td></tr><tr><td>
                 	NODE_GROUP_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Target the parameter at a specific node group id. To target all groups, use the value of 'ALL.'</td></tr><tr><td>
                 	PARAM_KEY                </td><td>VARCHAR  (80)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The name of the parameter.</td></tr><tr><td>
                 	PARAM_VALUE                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The value of the parameter.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.30.&nbsp;PARAMETER</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_registration_redirect"></a>A.31.&nbsp;REGISTRATION_REDIRECT</h2></div></div></div>
    
    <p>Provides a way for a centralized registration server to redirect registering nodes to their prospective parent node in a multi-tiered deployment.</p>
	<div class="table"><a name="table-def-registration_redirect"></a><div class="table-contents">
    	
    	<table summary="REGISTRATION_REDIRECT" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	REGISTRANT_EXTERNAL_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Maps the external id of a registration request to a different parent node.</td></tr><tr><td>
                 	REGISTRATION_NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The node_id of the node that a registration request should be redirected to.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.31.&nbsp;REGISTRATION_REDIRECT</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_registration_request"></a>A.32.&nbsp;REGISTRATION_REQUEST</h2></div></div></div>
    
    <p>Audits when a node registers or attempts to register.</p>
	<div class="table"><a name="table-def-registration_request"></a><div class="table-contents">
    	
    	<table summary="REGISTRATION_REQUEST" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	NODE_GROUP_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> The node group that this node belongs to, such as 'store'.</td></tr><tr><td>
                 	EXTERNAL_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> A domain-specific identifier for context within the local system. For example, the retail store number. </td></tr><tr><td>
                 	STATUS                </td><td>CHAR  (2)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The current status of the registration attempt.  Valid statuses are NR (not registered), IG (ignored), OK (sucessful)</td></tr><tr><td>
                 	HOST_NAME                </td><td>VARCHAR  (60)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The host name of a workstation or server. If more than one instance of SymmetricDS runs on the same server, then this value can be a 'server id' specified by -Druntime.symmetric.cluster.server.id</td></tr><tr><td>
                 	IP_ADDRESS                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The ip address for the host.</td></tr><tr><td>
                 	ATTEMPT_COUNT                </td><td>INTEGER </td><td> 0</td><td>				</td><td>&nbsp;</td><td> The number of registration attempts.</td></tr><tr><td>
                 	REGISTERED_NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> A unique identifier for a node.</td></tr><tr><td>
                 	ERROR_MESSAGE                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Record any errors or warnings that occurred when attempting to register.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.32.&nbsp;REGISTRATION_REQUEST</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_router"></a>A.33.&nbsp;ROUTER</h2></div></div></div>
    
    <p>Configure a type of router from one node group to another.  Note that routers are mapped to triggers through trigger_routers.</p>
	<div class="table"><a name="table-def-router"></a><div class="table-contents">
    	
    	<table summary="ROUTER" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	ROUTER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique description of a specific router</td></tr><tr><td>
                 	TARGET_CATALOG_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name for the catalog a target table is in. Only use this if the target table is not in the default catalog.  If this field is left blank, then the source_catalog_name for the trigger will be used as the target name.  If the target name should be left blank and the source name is set, then the token of $(none) may be used to force the target name to be blanked out.</td></tr><tr><td>
                 	TARGET_SCHEMA_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name of the schema a target table is in. On use this if the target table is not in the default schema.  If this field is left blank, then the source_schema_name for the trigger will be used as the target name.  If the target name should be left blank and the source name is set, then the token of $(none) may be used to force the target name to be blanked out.</td></tr><tr><td>
                 	TARGET_TABLE_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name for a target table.  Only use this if the target table name is different than the source.</td></tr><tr><td>
                 						 	<a href="#table-def-node_group_link" title="Table&nbsp;A.22.&nbsp;NODE_GROUP_LINK">source_node_group_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				FK</td><td>X</td><td> Routers with this node_group_id will install triggers that are mapped to this router.</td></tr><tr><td>
                 						 	<a href="#table-def-node_group_link" title="Table&nbsp;A.22.&nbsp;NODE_GROUP_LINK">target_node_group_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				FK</td><td>X</td><td> The node_group_id for nodes to route data to.  Note that routing can be further narrowed down by the configured router_type and router_expression.</td></tr><tr><td>
                 	ROUTER_TYPE                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The name of a specific type of router.  Out of the box routers are 'default','column','bsh', 'subselect' and 'audit.'  Custom routers can be configured as extension points.</td></tr><tr><td>
                 	ROUTER_EXPRESSION                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> An expression that is specific to the type of router that is configured in router_type.  See the documentation for each router for more details.</td></tr><tr><td>
                 	SYNC_ON_UPDATE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Flag that indicates that this router should route updates.</td></tr><tr><td>
                 	SYNC_ON_INSERT                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Flag that indicates that this router should route inserts.</td></tr><tr><td>
                 	SYNC_ON_DELETE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Flag that indicates that this router should route deletes.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.33.&nbsp;ROUTER</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_sequence"></a>A.34.&nbsp;SEQUENCE</h2></div></div></div>
    
    <p>A table that supports application level sequence numbering.</p>
	<div class="table"><a name="table-def-sequence"></a><div class="table-contents">
    	
    	<table summary="SEQUENCE" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	SEQUENCE_NAME                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier of a specific sequence.</td></tr><tr><td>
                 	CURRENT_VALUE                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> The current value of the sequence.</td></tr><tr><td>
                 	INCREMENT_BY                </td><td>INTEGER </td><td> 1</td><td>				</td><td>X</td><td> Specify the interval between sequence numbers. This integer value can be any positive or negative integer, but it cannot be 0.</td></tr><tr><td>
                 	MIN_VALUE                </td><td>BIGINT </td><td> 1</td><td>				</td><td>X</td><td> Specify the minimum value of the sequence.</td></tr><tr><td>
                 	MAX_VALUE                </td><td>BIGINT </td><td> 9999999999</td><td>				</td><td>X</td><td> Specify the maximum value the sequence can generate.</td></tr><tr><td>
                 	CYCLE                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicate whether the sequence should automatically cycle once a boundary is hit.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.34.&nbsp;SEQUENCE</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_table_reload_request"></a>A.35.&nbsp;TABLE_RELOAD_REQUEST</h2></div></div></div>
    
    <p>This table acts as a means to queue up a reload of a specific table.  Either the target or the source node may insert into this table to queue up a load.  If the target node inserts into the table, then the row will be synchronized to the source node and the reload events will be queued up during routing.</p>
	<div class="table"><a name="table-def-table_reload_request"></a><div class="table-contents">
    	
    	<table summary="TABLE_RELOAD_REQUEST" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	TARGET_NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for the node to receive the table reload.</td></tr><tr><td>
                 	SOURCE_NODE_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for the node that will be the source of the table reload.</td></tr><tr><td>
                 	TRIGGER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a trigger associated with the table reload. Note the trigger must be linked to the router.</td></tr><tr><td>
                 	ROUTER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique description of the router associated with the table reload. Note the router must be linked to the trigger.</td></tr><tr><td>
                 	RELOAD_SELECT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Overrides the initial load select.</td></tr><tr><td>
                 	RELOAD_DELETE_STMT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Overrides the initial load delete statement.</td></tr><tr><td>
                 	RELOAD_ENABLED                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates that a reload should be queued up.</td></tr><tr><td>
                 	RELOAD_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The timestamp when the reload was started for this node.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.35.&nbsp;TABLE_RELOAD_REQUEST</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_transform_table"></a>A.36.&nbsp;TRANSFORM_TABLE</h2></div></div></div>
    
    <p>Defines a data loader transformation which can be used to map arbitrary tables and columns to other tables and columns.</p>
	<div class="table"><a name="table-def-transform_table"></a><div class="table-contents">
    	
    	<table summary="TRANSFORM_TABLE" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	TRANSFORM_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier of a specific transform.</td></tr><tr><td>
                 						 	<a href="#table-def-node_group_link" title="Table&nbsp;A.22.&nbsp;NODE_GROUP_LINK">source_node_group_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The node group where data changes are captured.</td></tr><tr><td>
                 						 	<a href="#table-def-node_group_link" title="Table&nbsp;A.22.&nbsp;NODE_GROUP_LINK">target_node_group_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The node group where data changes will be sent.</td></tr><tr><td>
                 	TRANSFORM_POINT                </td><td>VARCHAR  (10)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The point during the transport of captured data that a transform happens.  Support values are EXTRACT or LOAD.</td></tr><tr><td>
                 	SOURCE_CATALOG_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name for the catalog the configured table is in.</td></tr><tr><td>
                 	SOURCE_SCHEMA_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name for the schema a configured table is in.</td></tr><tr><td>
                 	SOURCE_TABLE_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The name of the source table that will be transformed.</td></tr><tr><td>
                 	TARGET_CATALOG_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name for the catalog a target table is in. Only use this if the target table is not in the default catalog.</td></tr><tr><td>
                 	TARGET_SCHEMA_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name of the schema a target table is in. Only use this if the target table is not in the default schema.</td></tr><tr><td>
                 	TARGET_TABLE_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The name of the target table.</td></tr><tr><td>
                 	UPDATE_FIRST                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> If true, the target actions are attempted as updates first, regardless of whether the source operation was an insert or an update.</td></tr><tr><td>
                 	DELETE_ACTION                </td><td>VARCHAR  (10)</td><td>&nbsp;</td><td>				</td><td>X</td><td> An action to take upon delete of a row. Possible values are: DEL_ROW, UPDATE_COL, or NONE.</td></tr><tr><td>
                 	TRANSFORM_ORDER                </td><td>INTEGER </td><td> 1</td><td>				</td><td>X</td><td> Specifies the order in which to apply transforms if more than one target operation occurs.</td></tr><tr><td>
                 	COLUMN_POLICY                </td><td>VARCHAR  (10)</td><td> SPECIFIED</td><td>				</td><td>X</td><td> Specifies whether all columns need to be specified or whether they are implied.  Possible values are SPECIFIED or IMPLIED.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.36.&nbsp;TRANSFORM_TABLE</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_transform_column"></a>A.37.&nbsp;TRANSFORM_COLUMN</h2></div></div></div>
    
    <p>Defines the column mappings and optional data transformation for a data loader transformation.</p>
	<div class="table"><a name="table-def-transform_column"></a><div class="table-contents">
    	
    	<table summary="TRANSFORM_COLUMN" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	TRANSFORM_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier of a specific transform.</td></tr><tr><td>
                 	INCLUDE_ON                </td><td>CHAR  (1)</td><td> *</td><td>PK				</td><td>X</td><td> Indicates whether this mapping is included during an insert (I), update (U), delete (D) operation at the target based on the dml type at the source.  A value of * represents the fact that you want to map the column for all operations.</td></tr><tr><td>
                 	TARGET_COLUMN_NAME                </td><td>VARCHAR  (128)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Name of the target column.</td></tr><tr><td>
                 	SOURCE_COLUMN_NAME                </td><td>VARCHAR  (128)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Name of the source column.</td></tr><tr><td>
                 	PK                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>&nbsp;</td><td> Indicates whether this mapping defines a primary key to be used to identify the target row.  At least one row must be defined as a pk for each transform_id.</td></tr><tr><td>
                 	TRANSFORM_TYPE                </td><td>VARCHAR  (50)</td><td> copy</td><td>				</td><td>&nbsp;</td><td> The name of a specific type of transform.  Custom transformers can be configured as extension points.</td></tr><tr><td>
                 	TRANSFORM_EXPRESSION                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> An expression that is specific to the type of transform that is configured in transform_type.  See the documentation for each transformer for more details.</td></tr><tr><td>
                 	TRANSFORM_ORDER                </td><td>INTEGER </td><td> 1</td><td>				</td><td>X</td><td> Specifies the order in which to apply transforms if more than one target operation occurs.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.37.&nbsp;TRANSFORM_COLUMN</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_trigger"></a>A.38.&nbsp;TRIGGER</h2></div></div></div>
    
    <p>Configures database triggers that capture changes in the database. Configuration of which triggers are generated for which tables is stored here.  Triggers are created in a node's database if the source_node_group_id of a router is mapped to a row in this table.</p>
	<div class="table"><a name="table-def-trigger"></a><div class="table-contents">
    	
    	<table summary="TRIGGER" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	TRIGGER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a trigger.</td></tr><tr><td>
                 	SOURCE_CATALOG_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name for the catalog the configured table is in.</td></tr><tr><td>
                 	SOURCE_SCHEMA_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional name for the schema a configured table is in.</td></tr><tr><td>
                 	SOURCE_TABLE_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The name of the source table that will have a trigger installed to watch for data changes.</td></tr><tr><td>
                 						 	<a href="#table-def-channel" title="Table&nbsp;A.1.&nbsp;CHANNEL">channel_id</a>
					                </td><td>VARCHAR  (20)</td><td>&nbsp;</td><td>				FK</td><td>X</td><td> The channel_id of the channel that data changes will flow through.</td></tr><tr><td>
                 	SYNC_ON_UPDATE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether or not to install an update trigger.</td></tr><tr><td>
                 	SYNC_ON_INSERT                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether or not to install an insert trigger.</td></tr><tr><td>
                 	SYNC_ON_DELETE                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Whether or not to install an delete trigger.</td></tr><tr><td>
                 	SYNC_ON_INCOMING_BATCH                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>X</td><td> Whether or not an incoming batch that loads data into this table should cause the triggers to capture data_events. Be careful turning this on, because an update loop is possible.</td></tr><tr><td>
                 	NAME_FOR_UPDATE_TRIGGER                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Override the default generated name for the update trigger.</td></tr><tr><td>
                 	NAME_FOR_INSERT_TRIGGER                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Override the default generated name for the insert trigger.</td></tr><tr><td>
                 	NAME_FOR_DELETE_TRIGGER                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Override the default generated name for the delete trigger.</td></tr><tr><td>
                 	SYNC_ON_UPDATE_CONDITION                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Specify a condition for the update trigger firing using an expression specific to the database.</td></tr><tr><td>
                 	SYNC_ON_INSERT_CONDITION                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Specify a condition for the insert trigger firing using an expression specific to the database.</td></tr><tr><td>
                 	SYNC_ON_DELETE_CONDITION                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Specify a condition for the delete trigger firing using an expression specific to the database.</td></tr><tr><td>
                 	CUSTOM_ON_UPDATE_TEXT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Specify update trigger text to execute after the SymmetricDS trigger text runs.  This field is not applicable for H2, HSQLDB 1.x or Apachy Derby.</td></tr><tr><td>
                 	CUSTOM_ON_INSERT_TEXT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Specify insert trigger text to execute after the SymmetricDS trigger text runs.  This field is not applicable for H2, HSQLDB 1.x or Apachy Derby.</td></tr><tr><td>
                 	CUSTOM_ON_DELETE_TEXT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Specify delete trigger text to execute after the SymmetricDS trigger text runs.  This field is not applicable for H2, HSQLDB 1.x or Apachy Derby.</td></tr><tr><td>
                 	EXTERNAL_SELECT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Specify a SQL select statement that returns a single result.  It will be used in the generated database trigger to populate the EXTERNAL_DATA field on the data table.</td></tr><tr><td>
                 	TX_ID_EXPRESSION                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Override the default expression for the transaction identifier that groups the data changes that were committed together.</td></tr><tr><td>
                 	EXCLUDED_COLUMN_NAMES                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Specify a comma-delimited list of columns that should not be synchronized from this table.  Note that if a primary key is found in this list, it will be ignored.</td></tr><tr><td>
                 	SYNC_KEY_NAMES                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Specify a comma-delimited list of columns that should be used as the key for synchronization operations.  By default, if not specified, then the primary key of the table will be used.</td></tr><tr><td>
                 	USE_STREAM_LOBS                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>X</td><td> Specifies whether to capture lob data as the trigger is firing or to stream lob columns from the source tables using callbacks during extraction. A value of 1 indicates to stream from the source via callback; a value of 0, lob data is captured by the trigger.</td></tr><tr><td>
                 	USE_CAPTURE_LOBS                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>X</td><td> Provides a hint as to whether this trigger will capture big lobs data.  If set to 1 every effort will be made during data capture in trigger and during data selection for initial load to use lob facilities to extract and store data in the database.  On Oracle, this may need to be set to 1 to get around 4k concatenation errors during data capture and during initial load.</td></tr><tr><td>
                 	USE_CAPTURE_OLD_DATA                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Indicates whether this trigger should capture and send the old data (previous state of the row before the change).</td></tr><tr><td>
                 	USE_HANDLE_KEY_UPDATES                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>X</td><td> Allows handling of primary key updates (SQLServer dialect only)</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.38.&nbsp;TRIGGER</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_trigger_hist"></a>A.39.&nbsp;TRIGGER_HIST</h2></div></div></div>
    
    <p>A history of a table's definition and the trigger used to capture data from the table. When a database trigger captures a data change, it references a trigger_hist entry so it is possible to know which columns the data represents. trigger_hist entries are made during the sync trigger process, which runs at each startup, each night in the syncTriggersJob, or any time the syncTriggers() JMX method is manually invoked. A new entry is made when a table definition or a trigger definition is changed, which causes a database trigger to be created or rebuilt.</p>
	<div class="table"><a name="table-def-trigger_hist"></a><div class="table-contents">
    	
    	<table summary="TRIGGER_HIST" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 	TRIGGER_HIST_ID                </td><td>INTEGER </td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Unique identifier for a trigger_hist entry</td></tr><tr><td>
                 	TRIGGER_ID                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>X</td><td> Unique identifier for a trigger</td></tr><tr><td>
                 	SOURCE_TABLE_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The name of the source table that will have a trigger installed to watch for data changes.</td></tr><tr><td>
                 	SOURCE_CATALOG_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The catalog name where the source table resides.</td></tr><tr><td>
                 	SOURCE_SCHEMA_NAME                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The schema name where the source table resides.</td></tr><tr><td>
                 	NAME_FOR_UPDATE_TRIGGER                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The name used when the insert trigger was created.</td></tr><tr><td>
                 	NAME_FOR_INSERT_TRIGGER                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The name used when the update trigger was created.</td></tr><tr><td>
                 	NAME_FOR_DELETE_TRIGGER                </td><td>VARCHAR  (255)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The name used when the delete trigger was created.</td></tr><tr><td>
                 	TABLE_HASH                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td>  A hash of the table definition, used to detect changes in the definition.</td></tr><tr><td>
                 	TRIGGER_ROW_HASH                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> A hash of the trigger definition.  If changes are detected to the values that affect a trigger definition, then the trigger will be regenerated.</td></tr><tr><td>
                 	TRIGGER_TEMPLATE_HASH                </td><td>BIGINT </td><td> 0</td><td>				</td><td>X</td><td> A hash of the trigger text.  If changes are detected to the values that affect a trigger text then the trigger will be regenerated.</td></tr><tr><td>
                 	COLUMN_NAMES                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>X</td><td> The column names defined on the table. The column names are stored in comma-separated values (CSV) format.</td></tr><tr><td>
                 	PK_COLUMN_NAMES                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>X</td><td> The primary key column names defined on the table. The column names are stored in comma-separated values (CSV) format.</td></tr><tr><td>
                 	LAST_TRIGGER_BUILD_REASON                </td><td>CHAR  (1)</td><td>&nbsp;</td><td>				</td><td>X</td><td> The following reasons for a change are possible: New trigger that has not been created before (N); Schema changes in the table were detected (S); Configuration changes in Trigger (C); Trigger was missing (T).</td></tr><tr><td>
                 	ERROR_MESSAGE                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Record any errors or warnings that occurred when attempting to build the trigger.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	INACTIVE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The date and time when a trigger was inactivated.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.39.&nbsp;TRIGGER_HIST</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_trigger_router"></a>A.40.&nbsp;TRIGGER_ROUTER</h2></div></div></div>
    
    <p>Map a trigger to a router.</p>
	<div class="table"><a name="table-def-trigger_router"></a><div class="table-contents">
    	
    	<table summary="TRIGGER_ROUTER" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 						 	<a href="#table-def-trigger" title="Table&nbsp;A.38.&nbsp;TRIGGER">trigger_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The id of a trigger.</td></tr><tr><td>
                 						 	<a href="#table-def-router" title="Table&nbsp;A.33.&nbsp;ROUTER">router_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The id of a router.</td></tr><tr><td>
                 	ENABLED                </td><td>INTEGER  (1)</td><td> 1</td><td>				</td><td>X</td><td> Indicates whether this trigger router is enabled or not.</td></tr><tr><td>
                 	INITIAL_LOAD_ORDER                </td><td>INTEGER </td><td> 1</td><td>				</td><td>X</td><td> Order sequence of this table when an initial load is sent to a node. If this value is the same for multiple tables, then SymmetricDS will attempt to order the tables according to FK constraints.  If this value is set to a negative number, then the table will be excluded from an initial load.</td></tr><tr><td>
                 	INITIAL_LOAD_SELECT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> Optional expression that can be used to pare down the data selected from a table during the initial load process.</td></tr><tr><td>
                 	INITIAL_LOAD_DELETE_STMT                </td><td>LONGVARCHAR </td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The expression that is used to delete data when an initial load occurs.  If this field is empty, no delete will occur before the initial load.  If this field is not empty, the text will be used as a sql statement and executed for the initial load delete.</td></tr><tr><td>
                 	INITIAL_LOAD_BATCH_COUNT                </td><td>INTEGER </td><td> 1</td><td>				</td><td>&nbsp;</td><td> Only applicable if the initial load extract job is enabled. The number of batches to split an initial load of a table across.  If 0 then a select count(*) will be used to dynamically determine the number of batches based on the max_batch_size of the reload channel.</td></tr><tr><td>
                 	PING_BACK_ENABLED                </td><td>INTEGER  (1)</td><td> 0</td><td>				</td><td>X</td><td> When enabled, the node will route data that originated from a node back to that node.  This attribute is only effective if sync_on_incoming_batch is set to 1.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.40.&nbsp;TRIGGER_ROUTER</b></p></div><br class="table-break">
</div>

	  	    
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="table_trigger_router_grouplet"></a>A.41.&nbsp;TRIGGER_ROUTER_GROUPLET</h2></div></div></div>
    
    <p>This tables defines what grouplets are associated with what trigger routers.  The existence of the grouplet for a trigger_router enables nodes associated with the grouplet and at the same time it disables the trigger router for all other nodes.</p>
	<div class="table"><a name="table-def-trigger_router_grouplet"></a><div class="table-contents">
    	
    	<table summary="TRIGGER_ROUTER_GROUPLET" border="1"><colgroup><col width="115"><col width="50"><col width="30"><col width="18"><col width="18"><col width="150"></colgroup><thead><tr><th>Name</th><th>Type / Size</th><th>Default</th><th>PK FK</th><th>not null</th><th>Description</th></tr></thead><tbody><tr><td>
                 						 	<a href="#table-def-grouplet" title="Table&nbsp;A.11.&nbsp;GROUPLET">grouplet_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> Unique identifier for the grouplet.</td></tr><tr><td>
                 						 	<a href="#table-def-trigger_router" title="Table&nbsp;A.40.&nbsp;TRIGGER_ROUTER">trigger_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The id of a trigger.</td></tr><tr><td>
                 						 	<a href="#table-def-trigger_router" title="Table&nbsp;A.40.&nbsp;TRIGGER_ROUTER">router_id</a>
					                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>PK				FK</td><td>X</td><td> The id of a router.</td></tr><tr><td>
                 	APPLIES_WHEN                </td><td>CHAR  (1)</td><td>&nbsp;</td><td>PK				</td><td>X</td><td> Indicates the side that a grouplet should be applied to.  Use 'T' for target and 'S' for source and 'B' for both source and target.</td></tr><tr><td>
                 	CREATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when this entry was created.</td></tr><tr><td>
                 	LAST_UPDATE_BY                </td><td>VARCHAR  (50)</td><td>&nbsp;</td><td>				</td><td>&nbsp;</td><td> The user who last updated this entry.</td></tr><tr><td>
                 	LAST_UPDATE_TIME                </td><td>TIMESTAMP </td><td>&nbsp;</td><td>				</td><td>X</td><td> Timestamp when a user last updated this entry.</td></tr></tbody></table>
	</div><p class="title"><b>Table&nbsp;A.41.&nbsp;TRIGGER_ROUTER_GROUPLET</b></p></div><br class="table-break">
</div>

	  
</div>
    <div class="appendix" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="parameters"></a>Appendix&nbsp;B.&nbsp;Parameters</h2></div></div></div>
    
    <p>
        There are two kinds of parameters that can be used to configure the behavior of SymmetricDS:
        <span class="emphasis"><em>Startup Parameters</em></span>
        and
        <span class="emphasis"><em>Runtime Parameters</em></span>
        . Startup Parameters are required to be in a system property or a property file, while Runtime Parameters can also be
        found in the Parameter table from the database. Parameters are re-queried from their source at a configured interval
        and can also be refreshed on demand by using the JMX API. The following table shows the source of parameters and the
        hierarchy of precedence.
        </p><div class="table"><a name="d4e6677"></a><div class="table-contents">
            
            <table summary="Parameter Locations" border="1"><colgroup><col width="115"><col width="50"><col width="220"></colgroup><thead><tr><th>Location</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td>
                            <span class="emphasis"><em>symmetric-default.properties</em></span>
                        </td><td>Y</td><td> Packaged inside symmetric-core jar file. This file has all the default settings along with
                            descriptions.
                        </td></tr><tr><td>
                            <span class="emphasis"><em>conf/symmetric.properties</em></span>
                        </td><td>N</td><td> Changes to this file in the conf directory of a standalone install apply to all engines in
                            the JVM.
                        </td></tr><tr><td>
                            <span class="emphasis"><em>symmetric-override.properties</em></span>
                        </td><td>N</td><td>Changes to this file, provided by the end user in the JVM's classpath, apply to all engines
                            in the JVM.
                        </td></tr><tr><td>
                            <span class="emphasis"><em>engines/*.properties</em></span>
                        </td><td>N</td><td> Properties for a specific engine or node that is hosted in a standalone install.
                        </td></tr><tr><td>
                            <span class="emphasis"><em>Java System Properties</em></span>
                        </td><td>N</td><td> Any SymmetricDS property can be passed in as a -D property to the runtime. It will take
                            precedence over any properties file property.
                        </td></tr><tr><td>
                            <span class="emphasis"><em>Parameter table</em></span>
                        </td><td>N</td><td> A table which contains SymmetricDS parameters. Parameters can be targeted at a specific node
                            group and even at a specific external id. These settings will take precedence over all of the
                            above.
                        </td></tr><tr><td>
                            <span class="emphasis"><em>IParameterFilter</em></span>
                        </td><td>N</td><td> An extension point which allows parameters to be sourced from another location or customized.
                            These settings will take precedence over all of the above.
                        </td></tr></tbody></table>
        </div><p class="title"><b>Table&nbsp;B.1.&nbsp;Parameter Locations</b></p></div><p><br class="table-break">
    </p>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap01-startup"></a>B.1.&nbsp;Startup Parameters</h2></div></div></div>
        
        <p>
            Startup parameters are read once from properties files and apply only during start up. The following properties
            are used:
            </p><div class="variablelist"><dl><dt><span class="term"><span><strong class="command">auto.config.database</strong></span></span></dt><dd><p> If this is true, when symmetric starts up it will try to create the necessary tables. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">auto.config.registration.svr.sql.script</strong></span></span></dt><dd><p> Provide the path to a SQL script that can be run to do initial setup of a registration server.  This script will only be run on a registration server if the node_identity cannot be found. [ Default:  ]</p></dd><dt><span class="term"><span><strong class="command">auto.sync.configuration</strong></span></span></dt><dd><p> Capture and send SymmetricDS configuration changes to client nodes. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">auto.update.node.values.from.properties</strong></span></span></dt><dd><p> Update the node row in the database from the local properties during a heartbeat operation. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">cache.table.time.ms</strong></span></span></dt><dd><p> This is the amount of time table meta data will be cached before re-reading it from the database [ Default: 3600000 ]</p></dd><dt><span class="term"><span><strong class="command">cluster.server.id</strong></span></span></dt><dd><p> Set this if you want to give your server a unique name to be used to identify which server did what action.  Typically useful when running in a clustered environment.  This is currently used by the ClusterService when locking for a node. [ Default:  ]</p></dd><dt><span class="term"><span><strong class="command">db.connection.properties</strong></span></span></dt><dd><p> These are settings that will be passed to the JDBC driver as connection properties. Suggested settings by database are as follows: Oracle  db.connection.properties=oracle.net.CONNECT_TIMEOUT=300000;oracle.net.READ_TIMEOUT=300000;SetBigStringTryClob=true [ Default:  ]</p></dd><dt><span class="term"><span><strong class="command">db.delimited.identifier.mode</strong></span></span></dt><dd><p> Determines whether delimited identifiers are used or normal SQL92 identifiers (which may only contain alphanumerical characters and the underscore, must start with a letter and cannot be a reserved keyword). [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">db.driver</strong></span></span></dt><dd><p> Specify your database driver [ Default: org.h2.Driver ]</p></dd><dt><span class="term"><span><strong class="command">db.init.sql</strong></span></span></dt><dd><p> Specify a SQL statement that will be run when a database connection is created [ Default:  ]</p></dd><dt><span class="term"><span><strong class="command">db.jdbc.execute.batch.size</strong></span></span></dt><dd><p> This is the default number of rows that will be sent to the database as a batch when SymmetricDS uses the JDBC batch API.  Currently, only routing uses JDBC batch.  The data loader does not. [ Default: 100 ]</p></dd><dt><span class="term"><span><strong class="command">db.jdbc.streaming.results.fetch.size</strong></span></span></dt><dd><p> This is the default fetch size for streaming result sets. [ Default: 100 ]</p></dd><dt><span class="term"><span><strong class="command">db.jndi.name</strong></span></span></dt><dd><p> Name of a JNDI data source to use instead of using SymmetricDS's connection pool.  When this is set the db.url is ignored.  Using a JNDI data source is relevant when deploying to an application server. [ Default:  ]</p></dd><dt><span class="term"><span><strong class="command">db.metadata.ignore.case</strong></span></span></dt><dd><p> Indicates that case should be ignored when looking up references to tables using the database's metadata api. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">db.native.extractor</strong></span></span></dt><dd><p> Name of class that can extract native JDBC objects and interact directly with the driver. Spring uses this to perform operations specific to database, like handling LOBs on Oracle. [ Default: org.springframework.jdbc.support.nativejdbc.CommonsDbcpNativeJdbcExtractor ]</p></dd><dt><span class="term"><span><strong class="command">db.password</strong></span></span></dt><dd><p> Specify your database password [ Default:  ]</p></dd><dt><span class="term"><span><strong class="command">db.pool.initial.size</strong></span></span></dt><dd><p> The initial size of the connection pool [ Default: 5 ]</p></dd><dt><span class="term"><span><strong class="command">db.pool.max.active</strong></span></span></dt><dd><p> The maximum number of connections that will be allocated in the pool The http.concurrent.workers.max value should be half or less than half of this value. [ Default: 40 ]</p></dd><dt><span class="term"><span><strong class="command">db.pool.max.idle</strong></span></span></dt><dd><p> The maximum number of connections that can remain idle in the pool, without extra ones being released [ Default: 20 ]</p></dd><dt><span class="term"><span><strong class="command">db.pool.max.wait.millis</strong></span></span></dt><dd><p> This is how long a request for a connection from the datasource will wait before giving up. [ Default: 30000 ]</p></dd><dt><span class="term"><span><strong class="command">db.pool.min.evictable.idle.millis</strong></span></span></dt><dd><p> This is how long a connection can be idle before it will be evicted. [ Default: 120000 ]</p></dd><dt><span class="term"><span><strong class="command">db.pool.min.idle</strong></span></span></dt><dd><p> The minimum number of connections that can remain idle in the pool, without extra ones being created [ Default: 5 ]</p></dd><dt><span class="term"><span><strong class="command">db.read.strings.as.bytes</strong></span></span></dt><dd><p> If set to true forces database columns that contain character data to be read as bytes (bypassing JDBC driver character encoding)  so the raw values be encoded using the system default character set (usually UTF8).  This property was added to bypass MySQL character encoding so the raw data can be converted to utf8 directly. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">db.sql.query.timeout.seconds</strong></span></span></dt><dd><p> Most symmetric queries have a timeout associated with them.  This is the default. [ Default: 300 ]</p></dd><dt><span class="term"><span><strong class="command">db.url</strong></span></span></dt><dd><p> Specify your database URL [ Default: jdbc:h2:mem:setme;AUTO_SERVER=TRUE ]</p></dd><dt><span class="term"><span><strong class="command">db.user</strong></span></span></dt><dd><p> Specify your database user [ Default: please set me ]</p></dd><dt><span class="term"><span><strong class="command">db.validation.query</strong></span></span></dt><dd><p> This is the query to validate the database connection in Connection Pool. It is database specific.  The following are example statements for different databases. MySQL  db.validation.query=select 1 Oracle  db.validation.query=select 1 from dual DB2  db.validation.query=select max(1) from syscat.datatypes [ Default:  ]</p></dd><dt><span class="term"><span><strong class="command">db2.zseries.version</strong></span></span></dt><dd><p> Use to map the version string a zseries jdbc driver returns to the 'zseries' dialect [ Default: DSN08015 ]</p></dd><dt><span class="term"><span><strong class="command">engine.name</strong></span></span></dt><dd><p> This is the engine name.  This should be set if you have more than one engine running in the same JVM. It is used to name the JMX management bean.  Please do not use underscores in this name. [ Default: SymmetricDS ]</p></dd><dt><span class="term"><span><strong class="command">external.id</strong></span></span></dt><dd><p> The external id for this SymmetricDS node.  The external id is usually used as all or part of the node id. [ Default: please set me ]</p></dd><dt><span class="term"><span><strong class="command">file.sync.enable</strong></span></span></dt><dd><p> Enables File Synchronization capabilities [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">group.id</strong></span></span></dt><dd><p> The node group id that this node belongs to [ Default: please set me ]</p></dd><dt><span class="term"><span><strong class="command">hsqldb.initialize.db</strong></span></span></dt><dd><p> If using the HsqlDbDialect, this property indicates whether Symmetric should setup the embedded database properties or if an external application will be doing so. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">http.concurrent.reservation.timeout.ms</strong></span></span></dt><dd><p> This is the amount of time the host will keep a concurrent connection reservation after it has been attained by a client node while waiting for the subsequent reconnect to push. [ Default: 20000 ]</p></dd><dt><span class="term"><span><strong class="command">https.verified.server.names</strong></span></span></dt><dd><p> During SSL handshaking, if the URL's hostname and the server's identification hostname mismatch, the verification mechanism will check this comma separated list of server names to see if the cert should be accepted (see javax.net.ssl.HostnameVerifier.) Set this value equal to 'all' if all server names should be accepted. Set this value to blank if a valid SSL cert is required. [ Default:  ]</p></dd><dt><span class="term"><span><strong class="command">jmx.line.feed</strong></span></span></dt><dd><p> Specify the type of line feed to use in JMX console methods.  Possible values are: text or html. [ Default: text ]</p></dd><dt><span class="term"><span><strong class="command">job.random.max.start.time.ms</strong></span></span></dt><dd><p> When starting jobs, symmetric attempts to randomize the start time to spread out load.  This is the maximum wait period before starting a job. [ Default: 10000 ]</p></dd><dt><span class="term"><span><strong class="command">oracle.template.precision</strong></span></span></dt><dd><p> This is the precision that is used in the number template for oracle triggers [ Default: 30,10 ]</p></dd><dt><span class="term"><span><strong class="command">oracle.transaction.view.clock.sync.threshold.ms</strong></span></span></dt><dd><p> Requires access to gv$transaction.  This is the threshold by which clock can be off in an oracle rac environment.  It is only applicable when oracle.use.transaction.view is set to true. [ Default: 60000 ]</p></dd><dt><span class="term"><span><strong class="command">oracle.use.transaction.view</strong></span></span></dt><dd><p> Requires access to gv$transaction [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">registration.url</strong></span></span></dt><dd><p> This is the URL this node will use to register and pull it's configuration. If this is the root server, then this may remain blank and the configuration should be inserted directly into the database [ Default: please set me ]</p></dd><dt><span class="term"><span><strong class="command">security.service.class.name</strong></span></span></dt><dd><p> The class name for the Security Service to use for encrypting and decrypting database passwords [ Default: org.jumpmind.security.SecurityService ]</p></dd><dt><span class="term"><span><strong class="command">server.log.file</strong></span></span></dt><dd><p> The name of the active log file.  This is used by the system to locate the log file for analysis and trouble shooting.  It is set to the default log file location for the standalone server.  If deployed as a war file, you should update the value.  Note that this property does not change the actual location the log file will be written.  It just tells SymmetricDS where to find the log file. [ Default: ../logs/symmetric.log ]</p></dd><dt><span class="term"><span><strong class="command">start.heartbeat.job</strong></span></span></dt><dd><p> Whether the heartbeat job is enabled for this node.  The heartbeat job simply inserts an event to update the heartbeat_time column on the node_host table for the current node. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">start.initial.load.extract.job</strong></span></span></dt><dd><p> Whether the background initial load extractor job is started. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">start.pull.job</strong></span></span></dt><dd><p> Whether the pull job is enabled for this node. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">start.purge.job</strong></span></span></dt><dd><p> Whether the purge job is enabled for this node. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">start.push.job</strong></span></span></dt><dd><p> Whether the push job is enabled for this node. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">start.refresh.cache.job</strong></span></span></dt><dd><p> Whether the refresh cache job is enabled for this node. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">start.route.job</strong></span></span></dt><dd><p> Whether the routing job is enabled for this node. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">start.stage.management.job</strong></span></span></dt><dd><p> Whether the stage management job is enabled for this node. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">start.stat.flush.job</strong></span></span></dt><dd><p> Whether the statistic flush job is enabled for this node. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">start.synctriggers.job</strong></span></span></dt><dd><p> Whether the sync triggers job is enabled for this node. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">start.watchdog.job</strong></span></span></dt><dd><p> Whether the watchdog job is enabled for this node. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">sync.table.prefix</strong></span></span></dt><dd><p> When symmetric tables are created and accessed, this is the prefix to use for the tables. [ Default: sym ]</p></dd><dt><span class="term"><span><strong class="command">sync.url</strong></span></span></dt><dd><p> The url that can be used to access this SymmetricDS node. The default setting of http://$(hostName):31415/sync should be valid of the standalone launcher is used with the default settings The tokens of $(hostName) and $(ipAddress) are supported for this property. [ Default: http://$(hostName):31415/sync/$(engineName) ]</p></dd><dt><span class="term"><span><strong class="command">transport.type</strong></span></span></dt><dd><p> Specify the transport type.  Supported values currently include: http, internal. [ Default: http ]</p></dd><dt><span class="term"><span><strong class="command">web.batch.servlet.enable</strong></span></span></dt><dd><p> Indicate whether the batch servlet (which allows specific batches to be requested) is enabled. [ Default: true ]</p></dd></dl></div><p>
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap01-runtime"></a>B.2.&nbsp;Runtime Parameters</h2></div></div></div>
        
        <p>
            Runtime parameters are read periodically from properties files or the database. The following properties are
            used:
            </p><div class="variablelist"><dl><dt><span class="term"><span><strong class="command">auto.registration</strong></span></span></dt><dd><p> If this is true, registration is opened automatically for nodes requesting it. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">auto.reload</strong></span></span></dt><dd><p> If this is true, a reload is automatically sent to nodes when they register [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">auto.reload.reverse</strong></span></span></dt><dd><p> If this is true, a reload is automatically sent from a source node to all target nodes after the source node has registered. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">auto.reload.sym.tables.on.upgrade</strong></span></span></dt><dd><p> If this is true, when a symmetric node other than the registration server starts up and the minor release number has incremented, then the node will request a reload of key symmetric tables (because there might be new tables or columns.) [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">auto.sync.configuration.on.incoming</strong></span></span></dt><dd><p> Whether triggers should fire when changes sync into the node that this property is configured for. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">auto.sync.triggers</strong></span></span></dt><dd><p> If this is true, when symmetric starts up it will make sure the triggers in the database are up to date. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">auto.sync.triggers.after.config.change</strong></span></span></dt><dd><p> If this is true, when a configuration change is detected, symmetric will make sure all triggers in the database are up to date. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">bsh.load.filter.handles.missing.tables</strong></span></span></dt><dd><p> This parameter can be used to indicate that bean shell load filters will handle missing tables.  Useful for the case where you want to make, for example, global catalog or schema changes at the destination in the case where the catalog, schema, or table doesn't exist but the BSH will handle it. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">cache.channel.time.ms</strong></span></span></dt><dd><p> This is the amount of time channel entries will be cached before re-reading them from the database. [ Default: 60000 ]</p></dd><dt><span class="term"><span><strong class="command">cache.conflict.time.ms</strong></span></span></dt><dd><p> This is the amount of time conflict setting entries will be cached before re-reading them from the database. [ Default: 600000 ]</p></dd><dt><span class="term"><span><strong class="command">cache.grouplets.time.ms</strong></span></span></dt><dd><p> This is the amount of time grouplet entries will be cached before re-reading them from the database. [ Default: 600000 ]</p></dd><dt><span class="term"><span><strong class="command">cache.load.filter.time.ms</strong></span></span></dt><dd><p> This is the amount of time load filter entries will be cached before re-reading them from the database. [ Default: 600000 ]</p></dd><dt><span class="term"><span><strong class="command">cache.node.security.time.ms</strong></span></span></dt><dd><p> This is the amount of time node security entries will be cached before re-reading them from the database. [ Default: 0 ]</p></dd><dt><span class="term"><span><strong class="command">cache.transform.time.ms</strong></span></span></dt><dd><p> This is the amount of time transform entries will be cached before re-reading them from the database. [ Default: 600000 ]</p></dd><dt><span class="term"><span><strong class="command">cache.trigger.router.time.ms</strong></span></span></dt><dd><p> This is the amount of time trigger entries will be cached before re-reading them from the database. [ Default: 600000 ]</p></dd><dt><span class="term"><span><strong class="command">cluster.lock.enabled</strong></span></span></dt><dd><p> Enables clustering of jobs. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">cluster.lock.timeout.ms</strong></span></span></dt><dd><p> Indicate that this node is being run on a farm or cluster of servers and it needs to use the database to 'lock' out other activity when actions are taken. [ Default: 1800000 ]</p></dd><dt><span class="term"><span><strong class="command">compression.level</strong></span></span></dt><dd><p> Set the compression level this node will use when compressing synchronization payloads. @see java.util.zip.Deflater NO_COMPRESSION = 0 BEST_SPEED = 1 BEST_COMPRESSION = 9 DEFAULT_COMPRESSION = -1 [ Default: -1 ]</p></dd><dt><span class="term"><span><strong class="command">compression.strategy</strong></span></span></dt><dd><p> Set the compression strategy this node will use when compressing synchronization payloads. @see java.util.zip.Deflater FILTERED = 1 HUFFMAN_ONLY = 2 DEFAULT_STRATEGY = 0 [ Default: 0 ]</p></dd><dt><span class="term"><span><strong class="command">data.id.increment.by</strong></span></span></dt><dd><p> This is the expected increment value for the data_id in the data table. This is useful if you use auto_increment_increment and auto_increment_offset in MySQL. Note that these settings require innodb_autoinc_lock_mode=0, otherwise the increment and offset are not guaranteed. [ Default: 1 ]</p></dd><dt><span class="term"><span><strong class="command">dataextractor.enable</strong></span></span></dt><dd><p> Disable the extraction of all channels with the exception of the config channel [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">dataloader.enable</strong></span></span></dt><dd><p> Disable the loading of all channel with the exception of the config channel.  This property can be set to allow all changes to be extracted without introducing other changes in order to allow maintenance operations. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">dataloader.error.save.curval</strong></span></span></dt><dd><p> Indicates that the current value of the row should be recorded in the incoming_error table [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">dataloader.ignore.missing.tables</strong></span></span></dt><dd><p> Tables that are missing at the target database will be ignored.  This should be set to true if you expect that in some clients a table might not exist.  If set to false, the batch will fail. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">dataloader.max.rows.before.commit</strong></span></span></dt><dd><p> This is the maximum number of rows that will be supported in a single transaction.  If the database transaction row count reaches a size that is greater than this number then the transaction will be auto committed. The default value of -1 indicates that there is no size limit. [ Default: 10000 ]</p></dd><dt><span class="term"><span><strong class="command">dataloader.sleep.time.after.early.commit</strong></span></span></dt><dd><p> Amount of time to sleep before continuing data load after dataloader.max.rows.before.commit rows have been loaded. This is useful to give other application threads a chance to do work before continuing to load. [ Default: 5 ]</p></dd><dt><span class="term"><span><strong class="command">datareload.batch.insert.transactional</strong></span></span></dt><dd><p> Indicate whether the process of inserting data, data_events and outgoing_batches for a reload is transactional.  The only reason this might be marked as false is to reduce possible contention while multiple nodes connect for reloads at the same time. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">db.treat.date.time.as.varchar.enabled</strong></span></span></dt><dd><p> This is a setting that instructs the data capture and data load to treat JDBC TIME, DATE, and TIMESTAMP columns as if they were VARCHAR columns.  This means that the columns will be captured and loaded in the form that the database stores them.  Setting this to true on MySQL will allow datetime columns with the value of '0000-00-00 00:00:00' to be synchronized. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">file.pull.lock.timeout.ms</strong></span></span></dt><dd><p>null [ Default: 7200000 ]</p></dd><dt><span class="term"><span><strong class="command">file.pull.period.minimum.ms</strong></span></span></dt><dd><p>null [ Default: 0 ]</p></dd><dt><span class="term"><span><strong class="command">file.pull.thread.per.server.count</strong></span></span></dt><dd><p>null [ Default: 1 ]</p></dd><dt><span class="term"><span><strong class="command">file.push.lock.timeout.ms</strong></span></span></dt><dd><p>null [ Default: 7200000 ]</p></dd><dt><span class="term"><span><strong class="command">file.push.period.minimum.ms</strong></span></span></dt><dd><p>null [ Default: 0 ]</p></dd><dt><span class="term"><span><strong class="command">file.push.thread.per.server.count</strong></span></span></dt><dd><p>null [ Default: 1 ]</p></dd><dt><span class="term"><span><strong class="command">heartbeat.sync.on.push.enabled</strong></span></span></dt><dd><p> Specify whether to push node_host records to configured push clients.  If this is true the node for this instance and the node_host rows for all children instances will be pushed to all nodes that this node is configured to push to. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">heartbeat.sync.on.push.period.sec</strong></span></span></dt><dd><p> This is the number of seconds between when the sym_node_host table's heartbeat_time column is updated.  This property depends on the frequency of the heartbeat job.  If the heartbeat job is set to run every 10 minutes and this property is set to 10 seconds, then the heartbeat will only update every 10 minutes. [ Default: 0 ]</p></dd><dt><span class="term"><span><strong class="command">heartbeat.sync.on.startup</strong></span></span></dt><dd><p> When this property is set to true the heartbeat process will run at server startup.  Prior to 3.4 the heartbeat always happened at startup. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">heartbeat.update.node.with.batch.status</strong></span></span></dt><dd><p> When this is set to true, SymmetricDS will update fields in the sym_node table that indicate the number of outstanding errors and/or batches it has pending [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">http.compression</strong></span></span></dt><dd><p> Whether or not to use compression over HTTP connections. Currently, this setting only affects the push connection of the source node. Compression on a pull is enabled using a filter in the web.xml for the PullServlet. @see web.compression.disabled to enable/disable the filter [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">http.concurrent.workers.max</strong></span></span></dt><dd><p> This is the number of HTTP concurrent push/pull requests SymmetricDS will accept.  This is controlled by the NodeConcurrencyFilter. The number is per servlet the filter is applied to.  The db.pool.max.active value should be twice this value. [ Default: 20 ]</p></dd><dt><span class="term"><span><strong class="command">http.push.stream.output.enabled</strong></span></span></dt><dd><p> The HTTP client connection, during a push, buffers the entire outgoing pay-load locally before sending it.  Set this to true if you are getting heap space errors during a push.  Note that basic auth may not work when this is turned on. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">http.push.stream.output.size</strong></span></span></dt><dd><p> When HTTP chunking is turned on, this is the size to use for each chunk. [ Default: 30720 ]</p></dd><dt><span class="term"><span><strong class="command">http.timeout.ms</strong></span></span></dt><dd><p> Sets both the connection and read timeout on the internal HttpUrlConnection [ Default: 7200000 ]</p></dd><dt><span class="term"><span><strong class="command">incoming.batches.record.ok.enabled</strong></span></span></dt><dd><p> Indicates whether batches that have loaded successfully should be recorded in the incoming_batch table. Note that if this is set to false, then duplicate batches will NOT be skipped because SymmetricDS will have no way of knowing that a batch has already loaded. This parameter can be set to false to reduce contention on sym_incoming_batch for systems with many clients. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">incoming.batches.skip.duplicates</strong></span></span></dt><dd><p> This instructs symmetric to attempt to skip duplicate batches that are received.  Symmetric might be more efficient when recovering from error conditions if this is set to true, but you run the risk of missing data if the batch ids get reset (on one node, but not another) somehow (which is unlikely in production, but fairly likely in lab or development setups). [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">initial.load.create.first</strong></span></span></dt><dd><p> Set this if tables should be created prior to an initial load. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">initial.load.delete.first</strong></span></span></dt><dd><p> Set this if tables should be purged prior to an initial load. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">initial.load.delete.first.sql</strong></span></span></dt><dd><p> This is the SQL statement that will be used for purging a table during an initial load. [ Default: delete from %s ]</p></dd><dt><span class="term"><span><strong class="command">initial.load.extract.thread.per.server.count</strong></span></span></dt><dd><p> The number of threads available for concurrent extracts of initial load batches. [ Default: 20 ]</p></dd><dt><span class="term"><span><strong class="command">initial.load.extract.timeout.ms</strong></span></span></dt><dd><p>null [ Default: 7200000 ]</p></dd><dt><span class="term"><span><strong class="command">initial.load.reverse.first</strong></span></span></dt><dd><p> Indicate that if both the initial load and the reverse initial load are requested, then the reverse initial load should take place first. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">initial.load.use.extract.job.enabled</strong></span></span></dt><dd><p> Indicate that the extract job job should be used to extract reload batches [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">initial.load.use.reload.channel</strong></span></span></dt><dd><p> Indicate that the initial load events should be put on the reload channel. If this is set to false each table will be put on it's assigned channel during the reload. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">job.file.sync.pull.period.time.ms</strong></span></span></dt><dd><p>null [ Default: 60000 ]</p></dd><dt><span class="term"><span><strong class="command">job.file.sync.push.period.time.ms</strong></span></span></dt><dd><p>null [ Default: 60000 ]</p></dd><dt><span class="term"><span><strong class="command">job.file.sync.tracker.cron</strong></span></span></dt><dd><p>null [ Default: 0 0/5 * * * * ]</p></dd><dt><span class="term"><span><strong class="command">job.heartbeat.period.time.ms</strong></span></span></dt><dd><p> This is how often the heartbeat job runs.  Note that this doesn't mean that a heartbeat is performed this often. See heartbeat.sync.on.push.period.sec to change how often the heartbeat is sync'd [ Default: 900000 ]</p></dd><dt><span class="term"><span><strong class="command">job.initial.load.extract.period.time.ms</strong></span></span></dt><dd><p> This is how often the initial load extract queue job will run in the background [ Default: 10000 ]</p></dd><dt><span class="term"><span><strong class="command">job.pull.period.time.ms</strong></span></span></dt><dd><p> This is how often the pull job will be run to schedule pulls of nodes. [ Default: 60000 ]</p></dd><dt><span class="term"><span><strong class="command">job.purge.datagaps.cron</strong></span></span></dt><dd><p> This is how often the data gaps purge job will be run. [ Default: 0 0 0 * * * ]</p></dd><dt><span class="term"><span><strong class="command">job.purge.incoming.cron</strong></span></span></dt><dd><p> This is how often the incoming batch purge job will be run. [ Default: 0 0 0 * * * ]</p></dd><dt><span class="term"><span><strong class="command">job.purge.max.num.batches.to.delete.in.tx</strong></span></span></dt><dd><p> This is the number of batches that will be purged in one database transaction. [ Default: 5000 ]</p></dd><dt><span class="term"><span><strong class="command">job.purge.max.num.data.event.batches.to.delete.in.tx</strong></span></span></dt><dd><p> This is the number of batches that will be purged from the data_event table in one database transaction. [ Default: 5 ]</p></dd><dt><span class="term"><span><strong class="command">job.purge.max.num.data.to.delete.in.tx</strong></span></span></dt><dd><p> This is the number of data ids that will be purged in one database transaction. [ Default: 5000 ]</p></dd><dt><span class="term"><span><strong class="command">job.purge.outgoing.cron</strong></span></span></dt><dd><p> This is how often the outgoing batch and data purge job will be run. [ Default: 0 0 0 * * * ]</p></dd><dt><span class="term"><span><strong class="command">job.push.period.time.ms</strong></span></span></dt><dd><p> This is how often the push job will be run to schedule pushes to nodes. [ Default: 60000 ]</p></dd><dt><span class="term"><span><strong class="command">job.refresh.cache.cron</strong></span></span></dt><dd><p> This is when the refresh cache job will run. [ Default: 0/30 * * * * * ]</p></dd><dt><span class="term"><span><strong class="command">job.routing.period.time.ms</strong></span></span></dt><dd><p> This is how often the router will run in the background [ Default: 10000 ]</p></dd><dt><span class="term"><span><strong class="command">job.stage.management.period.time.ms</strong></span></span></dt><dd><p> This is when the stage management job will run. [ Default: 15000 ]</p></dd><dt><span class="term"><span><strong class="command">job.stat.flush.cron</strong></span></span></dt><dd><p> This is how often accumulated statistics will be flushed out to the database from memory. [ Default: 0 0/5 * * * * ]</p></dd><dt><span class="term"><span><strong class="command">job.synctriggers.cron</strong></span></span></dt><dd><p> This is when the sync triggers job will run. [ Default: 0 0 0 * * * ]</p></dd><dt><span class="term"><span><strong class="command">job.watchdog.period.time.ms</strong></span></span></dt><dd><p>null [ Default: 3600000 ]</p></dd><dt><span class="term"><span><strong class="command">jobs.synchronized.enable</strong></span></span></dt><dd><p> If jobs need to be synchronized so that only one job can run at a time, set this parameter to true [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">mysql.bulk.load.local</strong></span></span></dt><dd><p> Whether or not files are local to client only, so we must send the file to MySQL to load.   If client is running on same server as MySQL, then this can be set to false to have MySQL read file directly. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">mysql.bulk.load.max.rows.before.flush</strong></span></span></dt><dd><p> Maximum number of rows to write to file before running with 'LOAD DATA INFILE' to MySQL [ Default: 100000 ]</p></dd><dt><span class="term"><span><strong class="command">mysql.bulk.load.replace</strong></span></span></dt><dd><p> Whether or not to replace rows that already exist, based on primary key or unique key. If set to false, duplicates will be skipped.  [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">node.id.creator.script</strong></span></span></dt><dd><p> This is a bean shell script that will be used to generate the node id for a registering node [ Default:  ]</p></dd><dt><span class="term"><span><strong class="command">num.of.ack.retries</strong></span></span></dt><dd><p> This is the number of times we will attempt to send an ACK back to the remote node when pulling and loading data. [ Default: 5 ]</p></dd><dt><span class="term"><span><strong class="command">offline.node.detection.period.minutes</strong></span></span></dt><dd><p> This is the number of minutes that a node has been offline before taking action A value of -1 (or any negative value) disables the feature. [ Default: -1 ]</p></dd><dt><span class="term"><span><strong class="command">outgoing.batches.max.to.select</strong></span></span></dt><dd><p> The maximum number of unprocessed outgoing batch rows for a node that will be read into memory for the next data extraction. [ Default: 50000 ]</p></dd><dt><span class="term"><span><strong class="command">outgoing.batches.peek.ahead.batch.commit.size</strong></span></span></dt><dd><p> This is the number of data events that will be batched and committed together while building a batch. Note that this only kicks in if the prospective batch size is bigger than the configured max batch size. [ Default: 10 ]</p></dd><dt><span class="term"><span><strong class="command">parameter.reload.timeout.ms</strong></span></span></dt><dd><p> The number of milliseconds parameters will be cached by the ParameterService before they are reread from the file system and database. [ Default: 600000 ]</p></dd><dt><span class="term"><span><strong class="command">pull.lock.timeout.ms</strong></span></span></dt><dd><p> The amount of time a single pull worker node_communication lock will timeout after. [ Default: 7200000 ]</p></dd><dt><span class="term"><span><strong class="command">pull.period.minimum.ms</strong></span></span></dt><dd><p> This is the minimum time that is allowed between pulls of a specific node. [ Default: 0 ]</p></dd><dt><span class="term"><span><strong class="command">pull.thread.per.server.count</strong></span></span></dt><dd><p> The number of threads created that will be used to pull nodes concurrently on one server in the cluster. [ Default: 1 ]</p></dd><dt><span class="term"><span><strong class="command">purge.extract.request.retention.minutes</strong></span></span></dt><dd><p> This is the retention time for how long a extract request will be retained [ Default: 7200 ]</p></dd><dt><span class="term"><span><strong class="command">purge.registration.request.retention.minutes</strong></span></span></dt><dd><p> This is the retention time for how long a registration request will be retained [ Default: 7200 ]</p></dd><dt><span class="term"><span><strong class="command">purge.retention.minutes</strong></span></span></dt><dd><p> This is the retention for how long synchronization data will be kept in the symmetric synchronization tables.  Note that data will be purged only if the purge job is enabled. [ Default: 1440 ]</p></dd><dt><span class="term"><span><strong class="command">purge.stats.retention.minutes</strong></span></span></dt><dd><p> This is the retention for how long statistic data will be kept in the symmetric stats tables.  Note that data will be purged only if the statistics flush job is enabled. [ Default: 1440 ]</p></dd><dt><span class="term"><span><strong class="command">push.lock.timeout.ms</strong></span></span></dt><dd><p> The amount of time a single push worker node_communication lock will timeout after. [ Default: 7200000 ]</p></dd><dt><span class="term"><span><strong class="command">push.period.minimum.ms</strong></span></span></dt><dd><p> This is the minimum time that is allowed between pushes to a specific node. [ Default: 0 ]</p></dd><dt><span class="term"><span><strong class="command">push.thread.per.server.count</strong></span></span></dt><dd><p> The number of threads created that will be used to push to nodes concurrently on one server in the cluster. [ Default: 1 ]</p></dd><dt><span class="term"><span><strong class="command">registration.number.of.attempts</strong></span></span></dt><dd><p> This is the number of times registration will be attempted before being aborted.  The default value is -1 which means an endless number of attempts.  This parameter is specific to the node that is trying to register, not the node that is providing registration. [ Default: -1 ]</p></dd><dt><span class="term"><span><strong class="command">registration.reinitialize.enable</strong></span></span></dt><dd><p> Indicates whether SymmetricDS should be re-initialized immediately before registration. [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">rest.api.enable</strong></span></span></dt><dd><p> Enables the REST API [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">rest.api.heartbeat.on.pull</strong></span></span></dt><dd><p> Enables the REST API to update the heartbeat when pulling data [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">routing.data.reader.order.by.gap.id.enabled</strong></span></span></dt><dd><p> Use the order by clause to order sym_data when selecting data for routing.  Most databases order the data naturally and might even have better performance when the order by clause is left off. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">routing.data.reader.threshold.gaps.to.use.greater.than.query</strong></span></span></dt><dd><p> Select data to route from sym_data using a simple &gt; start_gap_id query if the number of gaps in sym_data_gap are greater than the following number [ Default: 100 ]</p></dd><dt><span class="term"><span><strong class="command">routing.data.reader.type.gap.retention.period.minutes</strong></span></span></dt><dd><p>null [ Default: 1440 ]</p></dd><dt><span class="term"><span><strong class="command">routing.delete.filled.in.gaps.immediately</strong></span></span></dt><dd><p> When true, delete the gaps instead of marking them as OK or SK. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">routing.flush.jdbc.batch.size</strong></span></span></dt><dd><p>null [ Default: 50000 ]</p></dd><dt><span class="term"><span><strong class="command">routing.largest.gap.size</strong></span></span></dt><dd><p> This is the maximum number of data that will be routed during one run.  It should be a number that well exceeds the number rows that will be in a transaction. [ Default: 50000000 ]</p></dd><dt><span class="term"><span><strong class="command">routing.max.gaps.to.qualify.in.sql</strong></span></span></dt><dd><p> This is the number of gaps that will be included in the SQL that is used to select data from sym_data.  If there are more gaps than this number, then the last gap will in the SQL will use the end id of the last gap. [ Default: 100 ]</p></dd><dt><span class="term"><span><strong class="command">routing.peek.ahead.window.after.max.size</strong></span></span></dt><dd><p> This is the maximum number of events that will be peeked at to look for additional transaction rows after the max batch size is reached.  The more concurrency in your db and the longer the transaction takes the bigger this value might have to be. [ Default: 2000 ]</p></dd><dt><span class="term"><span><strong class="command">routing.stale.dataid.gap.time.ms</strong></span></span></dt><dd><p> This is the time that any gaps in data_ids will be considered stale and skipped. [ Default: 7200000 ]</p></dd><dt><span class="term"><span><strong class="command">routing.wait.for.data.timeout.seconds</strong></span></span></dt><dd><p>null [ Default: 330 ]</p></dd><dt><span class="term"><span><strong class="command">schema.version</strong></span></span></dt><dd><p> This is hook to give the user a mechanism to indicate the schema version that is being synchronized. [ Default: ? ]</p></dd><dt><span class="term"><span><strong class="command">stream.to.file.enabled</strong></span></span></dt><dd><p> Save data to the file system before transporting it to the client or loading it to the database if the number of bytes is past a certain threshold.  This allows for better compression and better use of database and network resources.  Statistics in the batch tables will be more accurate if this is set to true because each timed operation is independent of the others. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">stream.to.file.threshold.bytes</strong></span></span></dt><dd><p> If stream.to.file.enabled is true, then the threshold number of bytes at which a file will be written is controlled by this property.  Note that for a synchronization the entire payload of the synchronization will be buffered in memory up to this number (at which point it will be written and continue to stream to disk.) [ Default: 32767 ]</p></dd><dt><span class="term"><span><strong class="command">stream.to.file.ttl.ms</strong></span></span></dt><dd><p> If stream.to.file.enabled is true, then this is how long a file will be retained in the staging directory after it has been marked as done. [ Default: 3600000 ]</p></dd><dt><span class="term"><span><strong class="command">time.between.ack.retries.ms</strong></span></span></dt><dd><p> This is the amount of time to wait between trying to send an ACK back to the remote node when pulling and loading data. [ Default: 5000 ]</p></dd><dt><span class="term"><span><strong class="command">transport.max.bytes.to.sync</strong></span></span></dt><dd><p> This is the number of maximum number of bytes to synchronize in one connect. [ Default: 1048576 ]</p></dd><dt><span class="term"><span><strong class="command">trigger.create.before.initial.load.enabled</strong></span></span></dt><dd><p> Disable this property to prevent table triggers from being created before initial load has completed. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">trigger.update.capture.changed.data.only.enabled</strong></span></span></dt><dd><p> Enable this property to force a compare of old and new data in triggers.  If old=new, then don't record the change in the data capture table. This is currently supported by the following dialects:  mysql, oracle, db2 [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">web.compression.disabled</strong></span></span></dt><dd><p> Disable compression from occurring on Servlet communication.  This property only affects the outbound HTTP traffic streamed by the PullServlet and PushServlet. [ Default: false ]</p></dd></dl></div><p>
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap01-server"></a>B.3.&nbsp;Server Configuration</h2></div></div></div>
        
        <p>
            Server configuration is read from <code class="literal">conf/symmetric-server.conf</code> for settings needed by the server
            before the parameter system has been initialized.
            </p><div class="variablelist"><dl><dt><span class="term"><span><strong class="command">http.enable</strong></span></span></dt><dd><p> Enable synchronization over HTTP. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">http.port</strong></span></span></dt><dd><p> Port number for synchronization over HTTP. [ Default: 31415 ]</p></dd><dt><span class="term"><span><strong class="command">https.allow.self.signed.certs</strong></span></span></dt><dd><p> Use a trust manager that allows self-signed server SSL certificates. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">https.enable</strong></span></span></dt><dd><p> Enable synchronization over HTTPS (HTTP over SSL). [ Default: false ]</p></dd><dt><span class="term"><span><strong class="command">https.port</strong></span></span></dt><dd><p> Port number for synchronization over HTTPS (HTTP over SSL). [ Default: 31417 ]</p></dd><dt><span class="term"><span><strong class="command">https.verified.server.names</strong></span></span></dt><dd><p> List host names that are allowed for server SSL certificates. [ Default: all ]</p></dd><dt><span class="term"><span><strong class="command">jmx.http.enable</strong></span></span></dt><dd><p> Enable Java Management Extensions (JMX) web console. [ Default: true ]</p></dd><dt><span class="term"><span><strong class="command">jmx.http.port</strong></span></span></dt><dd><p> Port number for Java Management Extensions (JMX) web console. [ Default: 31416 ]</p></dd></dl></div><p>
        </p>
    </div>

</div>
    <div class="appendix" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="databases"></a>Appendix&nbsp;C.&nbsp;Database Notes</h2></div></div></div>
    
    <p>
        Each database management system has its own characteristics that results in
        feature coverage in SymmetricDS.  The following table shows which features are available
        by database.
    </p>
    <p>
        </p><div class="table"><a name="d4e7646"></a><div class="table-contents">
            
            <table summary="Support by Database" border="1"><colgroup><col width="75"><col width="65"><col width="50"><col width="50"><col width="50"><col width="50"><col width="50"></colgroup><thead><tr><th>Database</th><th>Versions supported</th><th>Transaction Identifier</th><th>Data Capture</th><th>Conditional Sync</th><th>Update Loop Prevention</th><th>BLOB Sync</th><th>CLOB Sync</th></tr></thead><tbody><tr><td>Oracle</td><td>10g and above</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>MySQL</td><td>5.0.2 and above</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>MariaDB</td><td>5.1 and above</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>PostgreSQL</td><td>8.2.5 and above</td><td>Y (8.3 and above only)</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>Greenplum</td><td>8.2.15 and above</td><td>N</td><td>N</td><td>N</td><td>Y</td><td>N</td><td>N</td></tr><tr><td>SQL Server</td><td>2005 and above</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>SQL Server Azure</td><td>Tested on 11.00.2065</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>N</td></tr><tr><td>HSQLDB</td><td>1.8</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>HSQLDB</td><td>2.0</td><td>N</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>H2</td><td>1.x</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>Apache Derby</td><td>10.3.2.1</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>IBM DB2</td><td>9.5</td><td>N</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>Firebird</td><td>2.0</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>Informix</td><td>11</td><td>N</td><td>Y</td><td>Y</td><td>Y</td><td>N</td><td>N</td></tr><tr><td>Interbase</td><td>9.0</td><td>N</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>SQLite</td><td>3.x</td><td>N</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>Active Server Enterprise</td><td>12.5</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>SQL Anywhere</td><td>9</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td></tr></tbody></table>
        </div><p class="title"><b>Table&nbsp;C.1.&nbsp;Support by Database</b></p></div><p><br class="table-break">
    </p>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-oracle"></a>C.1.&nbsp;Oracle</h2></div></div></div>
        
        <p>SymmetricDS has bulk loading capability available for Oracle.  SymmetricDS specifies data loader types on
        a channel by channel basis.  To utilize Oracle Bulk loading versus straight JDBC insert, specify the Oracle Bulk
        Loader ("oracle_bulk") in the data_loader_type column of sym_channel.
        </p>
        <p>
            While BLOBs are supported on Oracle, the LONG data type is not.  LONG columns cannot be accessed from triggers.
        </p>
        <p>
            Note that while Oracle supports multiple triggers of the same type to be defined, the order
            in which the triggers occur appears to be arbitrary.
        </p>
        <p>
            The SymmetricDS user generally needs privileges for connecting and creating
            tables (including indexes), triggers, sequences, and procedures (including packages and functions).
            The following is an example of the needed grant statements:
            </p><pre class="programlisting">
GRANT CONNECT TO SYMMETRIC;
GRANT RESOURCE TO SYMMETRIC;
GRANT CREATE ANY TRIGGER TO SYMMETRIC;
GRANT EXECUTE ON UTL_RAW TO SYMMETRIC;</pre><p>
        </p>
        <p>
            Partitioning the <a href="#table_data" title="A.3.&nbsp;DATA">DATA</a> table by channel can help
            insert, routing and extraction performance on concurrent, high throughput systems.
            <a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>s should be organized to put data that is
            expected to be inserted concurrently on separate <a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>s.  The following is an example of
            partitioning.  Note that both the table and the index should be partitioned.  The default
            value allows for more channels to be added without having to modify the partitions.
            </p><pre class="programlisting">
CREATE TABLE SYM_DATA
(
    data_id INTEGER NOT NULL ,
    table_name VARCHAR2(50) NOT NULL,
    event_type CHAR(1) NOT NULL,
    row_data CLOB,
    pk_data CLOB,
    old_data CLOB,
    trigger_hist_id INTEGER NOT NULL,
    channel_id VARCHAR2(20),
    transaction_id VARCHAR2(1000),
    source_node_id VARCHAR2(50),
    external_data VARCHAR2(50),
    create_time TIMESTAMP
) PARTITION BY LIST (channel_id) (
PARTITION P_CONFIG VALUES ('config'),
PARTITION P_CHANNEL_ONE VALUES ('channel_one'),
PARTITION P_CHANNEL_TWO VALUES ('channel_two'),
...
PARTITION P_CHANNEL_N VALUES ('channel_n'),
PARTITION P_DEFAULT VALUES (DEFAULT));
            </pre><p>
            </p><pre class="programlisting">
CREATE UNIQUE INDEX IDX_D_CHANNEL_ID ON SYM_DATA (DATA_ID, CHANNEL_ID)  LOCAL
(
 PARTITION I_CONFIG,
 PARTITION I_CHANNEL_ONE,
 PARTITION I_CHANNEL_TWO,
 ...
 PARTITION I_CHANNEL_N,
 PARTITION I_DEFAULT
);
            </pre><p>
        </p>
        <p>Note also that, for Oracle, you can control the amount of precision used by the Oracle triggers
        with the parameter <code class="literal">oracle.template.precision</code>, which defaults to a precision of 30,10.
        </p>
        <p>If the following Oracle error 'ORA-01489: result of string concatenation is too long' is encountered
        you might need to set <code class="code">use_capture_lobs</code> to 1 on in the <a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a> table
        and resync the triggers.  The error can happen when the captured data in a row exceeds 4k and lob columns do not exist
        in the table.  By enabling <code class="code">use_capture_lobs</code> the concatanated varchar string is cast to a clob which
        allows a length of more than 4k.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-mysql"></a>C.2.&nbsp;MySQL</h2></div></div></div>
        
        <p>
            MySQL supports several storage engines for different table types.  SymmetricDS requires
            a storage engine that handles transaction-safe tables.  The recommended storage engine
            is InnoDB, which is included by default in MySQL 5.0 distributions.
            Either select the InnoDB engine during installation or modify your server configuration.
            To make InnoDB the default storage engine, modify your MySQL server configuration file
            (<code class="filename">my.ini</code> on Windows, <code class="filename">my.cnf</code> on Unix):
            </p><pre class="programlisting">default-storage_engine = innodb</pre><p>
            Alternatively, you can convert tables to the InnoDB storage engine with the following
            command:
            </p><pre class="programlisting">alter table t engine = innodb;</pre><p>
        </p>
        <p>
            On MySQL 5.0, the SymmetricDS user needs the SUPER privilege in order to create triggers.

            </p><pre class="programlisting">grant super on *.* to symmetric;</pre><p>

            On MySQL 5.1, the SymmetricDS user needs the TRIGGER and CREATE ROUTINE privileges
            in order to create triggers and functions.

            </p><pre class="programlisting">grant trigger on *.* to symmetric;</pre><p>
            </p><pre class="programlisting">grant create routine on *.* to symmetric;</pre><p>

        </p>
        <p>
            MySQL allows '0000-00-00 00:00:00' to be entered as a value for datetime and timestamp columns.
            JDBC cannot deal with a date value with a year of 0.  In order to work around this SymmetricDS
            can be configured to treat date and time columns as varchar columns for data capture and data
            load.  To enable this feature set the <code class="code">db.treat.date.time.as.varchar.enabled</code> property
            to <code class="code">true</code>.
        </p>
        <p>
            If you are using UTF-8 encoding in the database, you might consider using the
            <code class="code">characterEncoding</code> parameter in the JDBC URL.
            </p><pre class="programlisting">jdbc:mysql://hostname/databasename?tinyInt1isBit=false&amp;characterEncoding=utf8</pre><p>
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-mariadb"></a>C.3.&nbsp;MariaDB</h2></div></div></div>
        
        <p>
        	See MySQL notes.  In addition, you will need to use a MySQL driver for this dialect.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-postgresql"></a>C.4.&nbsp;PostgreSQL</h2></div></div></div>
        
        <p>SymmetricDS has bulk loading capability available for Postgres.  SymmetricDS specifies data loader types on
        a channel by channel basis.  To utilize Postgres Bulk loading versus straight JDBC insert, specify the Postgres Bulk
        Loader ("postgres_bulk") in the data_loader_type column of sym_channel.
        </p>
        <p>
            Starting with PostgreSQL 8.3, SymmetricDS supports the transaction identifier.
            Binary Large Object (BLOB) replication is supported for both byte array (BYTEA)
            and object ID (OID) data types.
        </p>
        <p>
            In order to function properly, SymmetricDS needs to use session variables.
            On PostgreSQL, session variables are enabled using a custom variable class.
            Add the following line to the <code class="filename">postgresql.conf</code> file
            of PostgreSQL server:

            </p><pre class="programlisting">
custom_variable_classes = 'symmetric'
</pre><p>

            This setting is required, and SymmetricDS will log an error and exit if it is not present.
        </p>
        <p>
            Before database triggers can be created by in PostgreSQL,
            the plpgsql language handler must be installed on the database.
            The following statements should be run by the administrator on the database:

            </p><pre class="programlisting">
CREATE FUNCTION plpgsql_call_handler() RETURNS language_handler AS
    '$libdir/plpgsql' LANGUAGE C;

CREATE FUNCTION plpgsql_validator(oid) RETURNS void AS
    '$libdir/plpgsql' LANGUAGE C;

CREATE TRUSTED PROCEDURAL LANGUAGE plpgsql
    HANDLER plpgsql_call_handler
    VALIDATOR plpgsql_validator;</pre><p>
        </p>
        <p>
        If you want SymmetricDS to install into a schema other than public you should alter the database user to set the default schema.
</p><pre class="programlisting">
        alter user {user name} set search_path to {schema name};
</pre><p>
        In addition, you will likely need the follow privelegdes as well:
</p><pre class="programlisting">
        GRANT USAGE ON SCHEMA {schema name} TO {user name};
        GRANT CREATE ON SCHEMA {schema name} TO {user name};
</pre><p>
        </p>

    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-greenplum"></a>C.5.&nbsp;Greenplum</h2></div></div></div>
        
        <p>
            Greenplum is a data warehouse based on PostgreSQL.  It is supported as a target platform in SymmetricDS.
        </p>

        <p>SymmetricDS has bulk loading capability available for Greenplum.  SymmetricDS specifies data loader types on
        a channel by channel basis.  To utilize Greenplum Bulk loading versus straight JDBC insert, specify the Postgres Bulk
        Loader ("postgres_bulk") in the data_loader_type column of sym_channel.
        </p>

    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-sql-server"></a>C.6.&nbsp;MS SQL Server</h2></div></div></div>
        
        <p>
            SQL Server was tested using the
            <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://jtds.sourceforge.net/" target="_top">
                jTDS
            </a>
            JDBC driver.
        </p>
        <p>
        	SQL Server allows the update of primary key fields via the SQL update statement.  If your application allows updating of the primary key
        	field(s) for a table, and you want those updates synchronized, you will need to set the "Handle Key Updates" field on the trigger record for
        	that specific table.  The default for Handle Key Updates is false.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-hsqldb"></a>C.7.&nbsp;HSQLDB</h2></div></div></div>
        
        <p>
            HSQLDB was implemented with the intention that the database be run embedded in the same JVM process
            as SymmetricDS.  Instead of dynamically generating static SQL-based triggers like the other databases, HSQLDB
            triggers are Java classes that re-use existing SymmetricDS services to read the configuration and insert data events
            accordingly.
        </p>
        <p>
            The transaction identifier support is based on SQL events that happen in a 'window' of time.  The trigger(s) track when the
            last trigger fired.  If a trigger fired within X milliseconds of the previous firing, then the current event gets the same
            transaction identifier as the last.  If the time window has passed, then a new transaction identifier is generated.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-h2"></a>C.8.&nbsp;H2</h2></div></div></div>
        
        <p>
            The H2 database allows only Java-based triggers.  Therefore the H2 dialect requires that the SymmetricDS jar file be in the database's classpath.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-derby"></a>C.9.&nbsp;Apache Derby</h2></div></div></div>
        
        <p>
            The Derby database can be run as an embedded database that is accessed by an application
            or a standalone server that can be accessed from the network.
            This dialect implementation creates database triggers that make method calls into
            Java classes.  This means that the supporting JAR files need to be in the classpath when
            running Derby as a standalone database, which includes symmetric-ds.jar and
            commons-lang.jar.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-db2"></a>C.10.&nbsp;IBM DB2</h2></div></div></div>
        
        <p>
            The DB2 Dialect uses global variables to enable and disable node and trigger synchronization.
            These variables are created automatically during the first startup.
            The DB2 JDBC driver should be placed in the "lib" folder.
        </p>
        <p>
            Currently, the DB2 Dialect for SymmetricDS does not provide support for transactional synchronization.
            Large objects (LOB) are supported, but are limited to 16,336 bytes in size.
            The current features in the DB2 Dialect have been tested using DB2 9.5 on Linux and Windows operating systems.
        </p>
        <p>
            There is currently a bug with the retrieval of auto increment columns with the DB2 9.5 JDBC drivers that causes
            some of the SymmetricDS configuration tables to be rebuilt when auto.config.database=true.  The DB2 9.7 JDBC drivers
            seem to have fixed the issue.  They may be used with the 9.5 database.
        </p>
        <p>
            A system temporary tablespace with too small of a page size may cause the following trigger build errors:
            </p><pre class="programlisting">
SQL1424N Too many references to transition variables and transition table
columns or the row length for these references is too long. Reason
code="2". LINE NUMBER=1. SQLSTATE=54040
            </pre><p>
            Simply create a system temporary tablespace that has a bigger page size.  A page size of 8k will probably suffice.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-firebird"></a>C.11.&nbsp;Firebird</h2></div></div></div>
        
        <p>
            The Firebird Dialect requires the installation of a User Defined Function (UDF) library
            in order to provide functionality needed by the database triggers.
            SymmetricDS includes the required UDF library, called SYM_UDF, in both source form
            (as a C program) and as pre-compiled libraries for both Windows and Linux.
            The SYM_UDF library is copied into the UDF folder within the Firebird installation directory.
        </p>
        <p>
            For Linux users:
        </p>
        <p>
            <span><strong class="command">cp databases/firebird/sym_udf.so /opt/firebird/UDF</strong></span>
        </p>
        <p>
            For Windows users:
        </p>
        <p>
            <span><strong class="command">copy databases\firebird\sym_udf.dll C:\Program Files\Firebird\Firebird_2_0\UDF</strong></span>
        </p>
        <p>
            The following limitations currently exist for this dialect:
        </p>
        <p>
          </p><div class="itemizedlist"><ul type="disc" compact><li>
                  <p>
                      The outgoing batch does not honor the channel size, and all
                      outstanding data events are included in a batch.
                  </p>
              </li><li>
                  <p>
                      Syncing of Binary Large Object (BLOB) is limited to 16K bytes per column.
                  </p>
              </li><li>
                  <p>
                      Syncing of character data is limited to 32K bytes per column.
                  </p>
              </li></ul></div><p>
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-informix"></a>C.12.&nbsp;Informix</h2></div></div></div>
        
        <p>
            The Informix Dialect was tested against Informix Dynamic Server 11.50, but older versions
            may also work.  You need to download the Informix JDBC Driver (from the
            <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://www-01.ibm.com/software/data/informix/downloads.html" target="_top">IBM Download Site</a>)
            and put the <code class="filename">ifxjdbc.jar</code> and <code class="filename">ifxlang.jar</code> files
            in the SymmetricDS <code class="filename">lib</code> folder.
        </p>
        <p>
            Make sure your database has logging enabled, which enables transaction
            support.  Enable logging when creating the database, like this:
            </p><pre class="programlisting">
CREATE DATABASE MYDB WITH LOG;
            </pre><p>

            Or enable logging on an existing database, like this:
            </p><pre class="programlisting">
ondblog mydb unbuf log
ontape -s -L 0
            </pre><p>
        </p>
        <p>
            The following features are not yet implemented:
        </p>
        <p>
          </p><div class="itemizedlist"><ul type="disc" compact><li>
                  <p>
                      Syncing of Binary and Character Large Objects (LOB) is disabled.
                  </p>
              </li><li>
                  <p>
                      There is no transaction ID recorded on data captured, so it is possible for data
                      to be committed within different transactions on the target database.
                      If transaction synchronization is required, either specify a custom transaction ID
                      or configure the synchronization so data is always sent in a single batch.
                      A custom transaction ID can be specified with the tx_id_expression on
                      <a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>.
                      The batch size is controlled with the max_batch_size on
                      <a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>.
                      The pull and push jobs have runtime properties to control their interval.
                  </p>
              </li></ul></div><p>
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-interbase"></a>C.13.&nbsp;Interbase</h2></div></div></div>
        
        <p>
            The Interbase Dialect requires the installation of a User Defined Function (UDF) library
            in order to provide functionality needed by the database triggers.
            SymmetricDS includes the required UDF library, called SYM_UDF, in both source form
            (as a C program) and as pre-compiled libraries for both Windows and Linux.
            The SYM_UDF library is copied into the UDF folder within the Interbase installation directory.
        </p>
        <p>
            For Linux users:
        </p>
        <p>
            <span><strong class="command">cp databases/interbase/sym_udf.so /opt/interbase/UDF</strong></span>
        </p>
        <p>
            For Windows users:
        </p>
        <p>
            <span><strong class="command">copy databases\interbase\sym_udf.dll C:\CodeGear\InterBase\UDF</strong></span>
        </p>
        <p>
            The Interbase dialect currently has the following limitations:
        </p>
        <div class="itemizedlist"><ul type="disc" compact><li>
                <p>
                    Data capture is limited to 4 KB per row, including large objects (LOB).
                </p>
            </li><li>
                <p>
                    There is no transaction ID recorded on data captured.
                    Either specify a tx_id_expression on the
                    <a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a> table,
                    or set a max_batch_size on the
                    <a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a> table that
                    will accommodate your transactional data.
                </p>
            </li></ul></div>
    </div>
     <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-sqlite"></a>C.14.&nbsp;SQLite</h2></div></div></div>
        
        <p>
            For SQLite, the implementation of sync-on-incoming back and the population of a source node if in the sym data rows relies
            on use of a context table (by default, called sym_context) to hold a boolean and node id in place of the more common methods
            of using temp tables (which are inaccessible from triggers) or functions (which are not available).  The context table assumes
            there's a single thread updating the database at any onetime.  If that is not the case in the future, the current implementation of
            sync on incoming batch will be unreliable.
        </p>
        <p>Nodes using SQLite should have the <code class="literal">jobs.synchronized.enable</code> parameter set to <code class="literal">true</code>.  This parameter
        causes the jobs and push/pull threads to all run in a synchronized fashion, which is needed in the case of SQLite.
        </p>
        <p>
        The SQLite dialect has the following limitations:
         </p><div class="itemizedlist"><ul type="disc" compact><li>
                <p>
                    There is no transaction ID recorded on data captured.
                    Either specify a tx_id_expression on the
                    <a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a> table,
                    or set a max_batch_size on the
                    <a href="#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a> table that
                    will accommodate your transactional data.
                </p>
                </li><li>
                <p>
                    Due to the single threaded access to SQLite, the
                    following parameter should be set to true: <code class="literal">jobs.synchronized.enable</code>.
                </p>
                </li></ul></div><p>
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-ase"></a>C.15.&nbsp;Sybase Active Server Enterprise</h2></div></div></div>
        
        <p>
            Active Server Enterprise (ASE) was tested using the jConnect JDBC driver. The jConnect JDBC driver should be placed in the "lib" folder.
        </p>
        <p>
            Columns of type DATETIME are accurate to 1/300th of a second, which means that the last digit of the milliseconds portion will end with 0, 3, or 6.
            An incoming DATETIME synced from another database will also have its millisconds rounded to one of these digits
            (0 and 1 become 0; 2, 3, and 4 become 3; 5, 6, 7, and 8 become 6; 9 becomes 10). 
            If DATETIME is used as the primary key or as one of the columns to detect a conflict, then conflict resolution could fail unless
            the milliseconds are rounded in the same fashion on the source system.
        </p>
        <p>
            On ASE, each new trigger in a table for the same operation (insert, update, or delete) overwrites the previous one.
            No warning message displays before the overwrite occurs. When SymmetricDS is installed and configured to synchronize a table, it
            will install triggers that could overwrite already existing triggers on the database. New triggers created after SymmetricDS is installed
            will overwrite the SymmetricDS triggers. Custom trigger text can be added to the SymmetricDS triggers by modifying
            CUSTOM_ON_INSERT_TEXT, CUSTOM_ON_UPDATE_TEXT, and CUSTOM_ON_DELETE_TEXT on the <a href="#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a> table.
        </p>
    </div>
    <div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ap02-sqlanywhere"></a>C.16.&nbsp;Sybase SQL Anywhere</h2></div></div></div>
        
        <p>
            SQL Anywhere was tested using the jConnect JDBC driver. The jConnect JDBC driver should be placed in the "lib" folder.
        </p>
    </div>
</div>
    <div class="appendix" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="data-format"></a>Appendix&nbsp;D.&nbsp;Data Format</h2></div></div></div>
    
    <p>
        The SymmetricDS Data Format is used to stream data from one node to another. The data format
        reader and writer are pluggable with an initial implementation using a format based on
        Comma Separated Values (CSV). Each line in the stream is a record with fields separated
        by commas. String fields are surrounded with double quotes. Double quotes and
        backslashes used in a string field are escaped with a backslash. Binary values are
        represented as a string with hex values in "\0xab" format. The absence of any value in
        the field indicates a null value. Extra spacing is ignored and lines starting with a
        hash are ignored.
    </p>
    <p>
        The first field of each line gives the directive for the line. The following directives
        are used:

        </p><div class="variablelist"><dl><dt><span class="term">
                    <span><strong class="command">nodeid, {node_id}</strong></span>
                </span></dt><dd>
                    <p>Identifies which node the data is coming from.  Occurs once in CSV file.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">binary, {BASE64|NONE|HEX}</strong></span>
                </span></dt><dd>
                    <p>Identifies the type of decoding the loader needs to use to decode binary data in the pay load.  This varies depending on what database is the source of the data.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">channel, {channel_id}</strong></span>
                </span></dt><dd>
                    <p>Identifies which channel a batch belongs to.  The SymmetricDS data loader expects the channel to be specified before the batch.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">batch, {batch_id}</strong></span>
                </span></dt><dd>
                    <p>Uniquely identifies a batch.  Used to track whether a batch has been loaded before. A batch of -9999 is considered a virtual batch and will be loaded, but will not be recorded in incoming_batch.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">schema, {schema name}</strong></span>
                </span></dt><dd>
                    <p>The name of the schema that is being targeted.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">catalog, {catalog name}</strong></span>
                </span></dt><dd>
                    <p>The name of the catalog that is being targeted.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">table, {table name}</strong></span>
                </span></dt><dd>
                    <p>The name of the table that is being targeted.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">keys, {column name...}</strong></span>
                </span></dt><dd>
                    <p>
                        Lists the column names that are used as the primary key for the table.
                        Only needs to occur after the first occurrence of the table.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">columns, {column name...}</strong></span>
                </span></dt><dd>
                    <p>
                        Lists all the column names (including key columns) of the table. Only needs to occur after the
                        first occurrence of the table.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">insert, {column value...}</strong></span>
                </span></dt><dd>
                    <p>
                        Insert into the table with the values that correspond with the columns.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">update, {new column value...},{old key value...}</strong></span>
                </span></dt><dd>
                    <p>
                        Update the table using the old key values to set the new column values.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">old, {old column value...}</strong></span>
                </span></dt><dd>
                    <p>
                        Represent all the old values of the data.  This data can be used for conflict 
                        resolution.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">delete, {old key value...}</strong></span>
                </span></dt><dd>
                    <p>Delete from the table using the old key values.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">sql, {sql statement}</strong></span>
                </span></dt><dd>
                    <p>Optional notation that instructs the data loader to run the accompanying SQL statement.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">bsh, {bsh script}</strong></span>
                </span></dt><dd>
                    <p>Optional notation that instructs the data loader to run the accompanying  <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://www.beanshell.org/" target="_top">BeanShell</a> snippet.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">create, {xml}</strong></span>
                </span></dt><dd>
                    <p>Optional notation that instructs the data loader to run the accompanying <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://db.apache.org/ddlutils/" target="_top">DdlUtils</a> XML table definition in order to create a database table.</p>
                </dd><dt><span class="term">
                    <span><strong class="command">commit, {batch_id}</strong></span>
                </span></dt><dd>
                    <p>An indicator that the batch has been transmitted and the data can be committed to the database.</p>
                </dd></dl></div><p>
    </p>
    <div class="example"><a name="d4e8076"></a><div class="example-contents">
        
        <pre class="programlisting">
nodeid, 1001
channel, pricing
binary, BASE64
batch, 100
schema,
catalog,
table, item_selling_price
keys, price_id
columns, price_id, price, cost
insert, 55, 0.65, 0.55
schema,
catalog,
table, item
keys, item_id 
columns, item_id, price_id, name
insert, 110000055, 55, "Soft Drink"
delete, 110000001
schema,
catalog,
table, item_selling_price
update, 55, 0.75, 0.65, 55
commit, 100
        </pre>
    </div><p class="title"><b>Example&nbsp;D.1.&nbsp;Data Format Stream</b></p></div><br class="example-break">
</div>
    <div class="appendix" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="upgrading"></a>Appendix&nbsp;E.&nbsp;Upgrading from 2.x</h2></div></div></div>
    
    <p>
        Please test carefully when upgrading SymmetricDS 2 to SymmetricDS 3. Note that
        <a href="#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
        table's primary key changed. The automatic upgrade backs up and copies the table. This might take some time if the
        table is large.
    </p>
    <p>
        The following parameters are no longer supported:
        </p><div class="itemizedlist"><ul type="disc"><li>
                <p>
                    <code class="literal">db.spring.bean.name</code>
                    - The connection pool is no longer wired in via the Spring Framework
                </p>
            </li><li>
                <p>
                    <code class="literal">db.tx.timeout.seconds</code>
                    - Transactions are no longer managed by the Spring Framework
                </p>
            </li><li>
                <p>
                    <code class="literal">db.default.schema</code>
                    - The default schema is always the schema associated with the database user
                </p>
            </li><li>
                <p>
                    <code class="literal">db.jndi.name</code>
                    - JNDI data sources are no longer supported
                </p>
            </li><li>
                <p>
                    <code class="literal">auto.upgrade</code>
                    - Database upgrade is controlled by
                    <code class="literal">auto.config.database</code>
                </p>
            </li><li>
                <p>
                    <code class="literal">routing.data.reader.type</code>
                    - As of this release, there is only one data reader type.
                </p>
            </li><li>
                <p>
                    <code class="literal">job.purge.max.num.data.events.to.delete.in.tx</code>
                    - The name of this property changed to
                    <code class="literal">job.purge.max.num.data.event.batches.to.delete.in.tx</code>
                </p>
            </li><li>
                <p>
                    <code class="literal">web.base.servlet.path</code>
                    - No longer needed
                </p>
            </li><li>
                <p>
                    <code class="literal">dataloader.allow.missing.delete</code>
                    - Controlled by conflict detection and resolution
                </p>
            </li><li>
                <p>
                    <code class="literal">dataloader.enable.fallback.insert</code>
                    - Controlled by conflict detection and resolution
                </p>
            </li><li>
                <p>
                    <code class="literal">dataloader.enable.fallback.update</code>
                    - Controlled by conflict detection and resolution
                </p>
            </li><li>
                <p>
                    <code class="literal">dataloader.enable.fallback.savepoint</code>
                    - No longer needed
                </p>
            </li><li>
                <p>
                    <code class="literal">db.force.delimited.identifier.mode.on</code>
                    - No longer needed
                </p>
            </li><li>
                <p>
                    <code class="literal">db.force.delimited.identifier.mode.off</code>
                    - No longer needed
                </p>
            </li></ul></div><p>
    </p>
    <p>
        The way extension points work has changed. SymmetricDS services are no longer Spring injectable into extension
        points. Please use the
        <code class="literal">ISymmetricEngineAware</code>
        interface to get a handle to the engine which gives access to services.
    </p>
    <p>
        The following extension points are no longer supported:
        </p><div class="itemizedlist"><ul type="disc"><li>
                <p>
                    <code class="literal">IDataLoaderFilter</code>
                    - Replaced by IDatabaseWriterFilter
                </p>
            </li><li>
                <p>
                    <code class="literal">IBatchListener</code>
                    - Replaced by IDatabaseWriterFilter
                </p>
            </li><li>
                <p>
                    <code class="literal">IExtractorFilter</code>
                    - No longer supported. Rarely used.
                </p>
            </li><li>
                <p>
                    <code class="literal">IColumnFilter</code>
                    - No longer needed. Please use the transformation feature.
                </p>
            </li></ul></div><p>
    </p>
</div>
    <div class="appendix" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="version-numbering"></a>Appendix&nbsp;F.&nbsp;Version Numbering</h2></div></div></div>
    
    <p>
        The software is released with a version number based on the
        <a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://apr.apache.org/versioning.html" target="_top">
            Apache Portable Runtime Project
        </a>
        version guidelines. In summary, the version is denoted as three integers in the
        format of MAJOR.MINOR.PATCH. Major versions are incompatible at the API level, and
        they can include any kind of change. Minor versions are compatible with older
        versions at the API and binary level, and they can introduce new functions or remove
        old ones. Patch versions are perfectly compatible, and they are released to fix
        defects.
    </p>
</div>
</div><p xmlns:fo="http://www.w3.org/1999/XSL/Format" class="copyright">&copy; 2007, 2008 Eric Long and Chris Henson</p></body></html>