<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>Chapter&nbsp;4.&nbsp;Configuration</title><link rel="stylesheet" href="css/docbook-style.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.72.0"><link rel="start" href="user-guide.html" title="SymmetricDS User Guide"><link rel="up" href="user-guide.html" title="SymmetricDS User Guide"><link rel="prev" href="planning.html" title="Chapter&nbsp;3.&nbsp;Planning"><link rel="next" href="advanced-topics.html" title="Chapter&nbsp;5.&nbsp;Advanced Topics"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div xmlns:fo="http://www.w3.org/1999/XSL/Format" id="banner"><a style="border:none;" href="http://www.symmetricds.org/" title="SymmetricDS User Guide"><img style="border:none;" alt="SymmetricDS" src="images/banner-logo.gif"></a></div><div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="configuration"></a>Chapter&nbsp;4.&nbsp;Configuration</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="configuration.html#configuration-node-properties">4.1. Node Properties</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-node">4.2. Node</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-node-group">4.3. Node Group</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-node-group-link">4.4. Node Group Link</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-channel">4.5. Channel</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-triggers-and-routers">4.6. Triggers, Routers, and Trigger / Routers Mappings</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#configuration-trigger">4.6.1. Trigger</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#configuration-trigger-lobs">4.6.1.1. Large Objects</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-trigger-external-select">4.6.1.2. External Select</a></span></dt></dl></dd><dt><span class="section"><a href="configuration.html#configuration-router">4.6.2. Router</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#configuration-default-router">4.6.2.1. Default Router</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-column-match-router">4.6.2.2. Column Match Router</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-lookup-table-router">4.6.2.3. Lookup Table Router</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-subselect-router">4.6.2.4. Subselect Router</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-scripted-router">4.6.2.5. Scripted Router</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-audit-table-router">4.6.2.6. Audit Table Router</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-routing-external-select">4.6.2.7. Utilizing External Select when Routing</a></span></dt></dl></dd><dt><span class="section"><a href="configuration.html#configuration-trigger-router">4.6.3. Trigger / Router Mappings</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#configuration-trigger-router-enabled">4.6.3.1. Enable / disable trigger router</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-initial-load">4.6.3.2. Initial Loads</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-dead-triggers">4.6.3.3. Dead Triggers</a></span></dt><dt><span class="section"><a href="configuration.html#configuration-trigger-router-ping-back">4.6.3.4. Enabling "Ping Back"</a></span></dt></dl></dd></dl></dd><dt><span class="section"><a href="configuration.html#configuration-registration">4.7. Opening Registration</a></span></dt><dt><span class="section"><a href="configuration.html#transform-data">4.8. Transforming Data</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#transform-data-tables">4.8.1. Transform Configuration Tables</a></span></dt><dt><span class="section"><a href="configuration.html#transform-data-types">4.8.2. Transformation Types</a></span></dt></dl></dd><dt><span class="section"><a href="configuration.html#data-load-filter">4.9. Data Load Filters</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#data-load-filter-config">4.9.1. Load Filter Configuration Table</a></span></dt><dt><span class="section"><a href="configuration.html#data-load-filter-variables">4.9.2. Variables available to Data Load Filters</a></span></dt><dt><span class="section"><a href="configuration.html#data-load-filter-examples">4.9.3. Data Load Filter Example</a></span></dt></dl></dd><dt><span class="section"><a href="configuration.html#conflicts">4.10. Conflict Detection and Resolution</a></span></dt><dt><span class="section"><a href="configuration.html#file-sync">4.11. File Synchronization</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#filesync-overview">4.11.1. Overview</a></span></dt><dt><span class="section"><a href="configuration.html#filesync-operation">4.11.2. Operation</a></span></dt><dt><span class="section"><a href="configuration.html#filesync-beanshell">4.11.3. File Sync Bean Shell Scripts</a></span></dt><dt><span class="section"><a href="configuration.html#filesync-examples">4.11.4. File Sync Examples</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#filesync-example-1">4.11.4.1. Sync Text Files From Server To Client</a></span></dt><dt><span class="section"><a href="configuration.html#filesync-example-2">4.11.4.2. Route changes to a specific node based on a directory
name</a></span></dt></dl></dd></dl></dd><dt><span class="section"><a href="configuration.html#jobs">4.12. Jobs</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#routing-job">4.12.1. Route Job</a></span></dt><dd><dl><dt><span class="section"><a href="configuration.html#data-gaps">4.12.1.1. Data Gaps</a></span></dt></dl></dd><dt><span class="section"><a href="configuration.html#push-pull-job">4.12.2. Push and Pull Jobs for Database changes</a></span></dt><dt><span class="section"><a href="configuration.html#file-sync-push-pull">4.12.3. File Sync Push and Pull Jobs</a></span></dt><dt><span class="section"><a href="configuration.html#file-sync-tracker-job">4.12.4. File System Tracker Job</a></span></dt><dt><span class="section"><a href="configuration.html#sync-triggers">4.12.5. Sync Triggers Job</a></span></dt><dt><span class="section"><a href="configuration.html#purge-job">4.12.6. Purge Jobs</a></span></dt></dl></dd></dl></div>


<p>
<a href="planning.html" title="Chapter&nbsp;3.&nbsp;Planning">Chapter&nbsp;3</a>
introduced numerous concepts and the analysis and design needed to
create an implementation of SymmetricDS. This chapter re-visits each
analysis step and documents how to turn a SymmetricDS design into
reality through configuration of the various SymmetricDS tables. In
addition, several advanced configuration options, not presented
previously, will also be covered.
</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-node-properties"></a>4.1.&nbsp;Node Properties</h2></div></div></div>


<p>
To get a SymmetricDS node running, it needs to be given an identity and
it needs to know how to connect to the database it will be
synchronizing. The preferred way to configure a SymmetricDS engine is to
create a properties file in the engines directory. The SymmetricDS
server will create an engine for each properties file found in the
engines directory. When started up, SymmetricDS reads the
synchronization configuration and state from the database. If the
configuration tables are missing, they are created automatically (auto
creation can be disabled). Basic configuration is described by inserting
into the following tables (the complete data model is defined in
<a href="data-model.html" title="Appendix&nbsp;A.&nbsp;Data Model">Appendix&nbsp;A, <i xmlns:xlink="http://www.w3.org/1999/xlink">Data Model</i></a>
).
</p><div class="itemizedlist"><ul type="disc"><li>
<p>
<a href="data-model.html#table_node_group" title="A.20.&nbsp;NODE_GROUP">NODE_GROUP</a>
- specifies the tiers that exist in a SymmetricDS network
</p>
</li><li>
<p>
<a href="data-model.html#table_node_group_link" title="A.22.&nbsp;NODE_GROUP_LINK">NODE_GROUP_LINK</a>
- links two node groups together for synchronization
</p>
</li><li>
<p>
<a href="data-model.html#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
- grouping and priority of synchronizations
</p>
</li><li>
<p>
<a href="data-model.html#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
- specifies tables, channels, and conditions for which changes in the
database should be captured
</p>
</li><li>
<p>
<a href="data-model.html#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
- specifies the routers defined for synchronization, along with other
routing details
</p>
</li><li>
<p>
<a href="data-model.html#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
- provides mappings of routers and triggers
</p>
</li></ul></div><p>
</p>

<p>During start up, triggers are verified against the
database, and database triggers are installed on tables that require
data changes to be captured. The Route, Pull and Push Jobs begin running
to synchronize changes with other nodes.</p>

<p>
Each node requires properties that allow it to connect to a database and
register with a parent node. Properties are configured in a file named
<code class="code">xxxxx.properties</code>
that is placed in the engines directory of the SymmetricDS install. The
file is usually named according to the engine.name, but it is not a
requirement.
</p>

<p>
To give a node its identity, the following properties are required. Any
other properties found in
<code class="code">conf/symmetric.properties</code>
can be overridden for a specific engine in an engine's properties file.
If the properties are changed in
<code class="code">conf/symmetric.properties</code>
they will take effect across all engines deployed to the server. Note
that you can use the variable
<code class="literal">$(hostName)</code>
to represent the host name of the machine when defining these properties
(for example, external.id=$(hostName) ).
</p>

<div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">engine.name</strong></span>
</span></dt><dd>
<p>This is an arbitrary name that is used to access a specific
engine using an HTTP URL. Each node configured in the engines directory
must have a unique engine name. The engine name is also used for the
domain name of registered JMX beans.</p>
</dd><dt><span class="term">
<span><strong class="command">group.id</strong></span>
</span></dt><dd>
<p>The node group that this node is a member of.
Synchronization is specified between node groups, which means you only
need to specify it once for multiple nodes in the same group.</p>
</dd><dt><span class="term">
<span><strong class="command">external.id</strong></span>
</span></dt><dd>
<p>The external id for this node has meaning to the user and
provides integration into the system where it is deployed. For example,
it might be a retail store number or a region number. The external id
can be used in expressions for conditional and subset data
synchronization. Behind the scenes, each node has a unique sequence
number for tracking synchronization events. That makes it possible to
assign the same external id to multiple nodes, if desired.</p>
</dd><dt><span class="term">
<span><strong class="command">sync.url</strong></span>
</span></dt><dd>
<p>
The URL where this node can be contacted for synchronization. At startup
and during each heartbeat, the node updates its entry in the database
with this URL. The sync url is of the format:
<code class="code">http://{hostname}:{port}/{webcontext}/sync/{engine.name}</code>
.
</p>

<p>The {webcontext} is blank for a standalone deployment. It
will typically be the name of the war file for an application server
deployment.</p>

<p>The {engine.name} can be left blank if there is only one
engine deployed in a SymmetricDS server.</p>
</dd></dl></div>

<p>When a new node is first started, it is has no information
about synchronizing. It contacts the registration server in order to
join the network and receive its configuration. The configuration for
all nodes is stored on the registration server, and the URL must be
specified in the following property:</p>

<div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">registration.url</strong></span>
</span></dt><dd>
<p>The URL where this node can connect for registration to
receive its configuration. The registration server is part of
SymmetricDS and is enabled as part of the deployment. This is typically
equal to the value of the sync.url of the registration server.</p>
</dd></dl></div>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
<p>
Note that a
<span class="emphasis"><em>registration server node</em></span>
is defined as one whose
<code class="literal">registration.url</code>
is either (a) blank, or (b) identical to its
<code class="literal">sync.url</code>
.
</p>
</div>

<p>For a deployment where the database connection pool should
be created using a JDBC driver, set the following properties:</p>

<div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">db.driver</strong></span>
</span></dt><dd>
<p>The class name of the JDBC driver.</p>
</dd><dt><span class="term">
<span><strong class="command">db.url</strong></span>
</span></dt><dd>
<p>The JDBC URL used to connect to the database.</p>
</dd><dt><span class="term">
<span><strong class="command">db.user</strong></span>
</span></dt><dd>
<p>The database username, which is used to login, create, and
update SymmetricDS tables.</p>
</dd><dt><span class="term">
<span><strong class="command">db.password</strong></span>
</span></dt><dd>
<p>The password for the database user.</p>
</dd></dl></div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-node"></a>4.2.&nbsp;Node</h2></div></div></div>


<p>
A
<span class="emphasis"><em>node</em></span>
, a single instance of SymmetricDS, is defined in the
<a href="data-model.html#table_node" title="A.17.&nbsp;NODE">NODE</a>
table. Two other tables play a direct role in defining a node, as well
The first is
<a href="data-model.html#table_node_identity" title="A.27.&nbsp;NODE_IDENTITY">NODE_IDENTITY</a>
. The
<span class="emphasis"><em>only</em></span>
row in this table is inserted in the database when the node first
<span class="emphasis"><em>registers</em></span>
with a parent node. In the case of a root node, the row is entered by
the user. The row is used by a node instance to determine its node
identity.
</p>

<p>
The following SQL statements set up a top-level registration server as a
node identified as "00000" in the "corp" node group.
</p><pre class="programlisting"> insert into SYM_NODE (node_id,
node_group_id, external_id, sync_enabled) values ('00000', 'corp',
'00000', 1); insert into SYM_NODE_IDENTITY values ('00000');</pre><p>
</p>

<p>
The second table,
<a href="data-model.html#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
has rows created for each
<span class="emphasis"><em>child</em></span>
node that registers with the node, assuming auto-registration is
enabled. If auto registration is not enabled, you must create a row in
<a href="data-model.html#table_node" title="A.17.&nbsp;NODE">NODE</a>
and
<a href="data-model.html#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
for the node to be able to register. You can also, with this table,
manually cause a node to re-register or do a re-initial load by setting
the corresponding columns in the table itself. Registration is discussed
in more detail in
<a href="configuration.html#configuration-registration" title="4.7.&nbsp;Opening Registration">Section&nbsp;4.7, &#8220;Opening Registration&#8221;</a>
.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-node-group"></a>4.3.&nbsp;Node Group</h2></div></div></div>


<p>
Node Groups are straightforward to configure and are defined in the
<a href="data-model.html#table_node_group" title="A.20.&nbsp;NODE_GROUP">NODE_GROUP</a>
table. The following SQL statements would create node groups for "corp"
and "store" based on our retail store example.
</p><pre class="programlisting"> insert into SYM_NODE_GROUP
(node_group_id, description) values ('store', 'A retail store node');

insert into SYM_NODE_GROUP (node_group_id, description) values ('corp',
'A corporate node');</pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-node-group-link"></a>4.4.&nbsp;Node Group Link</h2></div></div></div>


<p>
Similarly, Node Group links are established using a data event action of
'P' for Push and 'W' for Pull ("wait"). The following SQL statements
links the "corp" and "store" node groups for synchronization. It
configures the "store" nodes to push their data changes to the "corp"
nodes, and the "corp" nodes to send changes to "store" nodes by waiting
for a pull.
</p><pre class="programlisting"> insert into SYM_NODE_GROUP_LINK
(source_node_group, target_node_group, data_event_action) values
('store', 'corp', 'P'); insert into SYM_NODE_GROUP_LINK
(source_node_group, target_node_group, data_event_action) values
('corp', 'store', 'W');</pre><p>
</p>

<p>A node group link can be configured to use the same node
group as the source and the target. This configuration allows a node
group to sync with every other node in its group.</p>
<p>A third type of link action of 'R' for 'Route Only' exists
if you want to associate a router with a link that will not move the
data. This action type might be useful when using an XML publishing
router or an audit table changes router.</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-channel"></a>4.5.&nbsp;Channel</h2></div></div></div>


<p>
By categorizing data into channels and assigning them to
<a href="data-model.html#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
s, the user gains more control and visibility into the flow of data. In
addition, SymmetricDS allows for synchronization to be enabled,
suspended, or scheduled by channels as well. The frequency of
synchronization and order that data gets synchronized is also controlled
at the channel level.
</p>

<p>
The following SQL statements setup channels for a retail store. An
"item" channel includes data for items and their prices, while a
"sale_transaction" channel includes data for ringing sales at a
register.
</p><pre class="programlisting"> insert into SYM_CHANNEL (channel_id,
processing_order, max_batch_size, max_batch_to_send,
extract_period_millis, batch_algorithm, enabled, description) values
('item', 10, 1000, 10, 0, 'default', 1, 'Item and pricing data'); insert
into SYM_CHANNEL (channel_id, processing_order, max_batch_size,
max_batch_to_send, extract_period_millis, batch_algorithm, enabled,
description) values ('sale_transaction', 1, 1000, 10, 60000,
'transactional', 1, 'retail sale transactions from register');</pre><p>
</p>

<p>
Batching is the grouping of data, by channel, to be transferred and
committed at the client together. There are three different
out-of-the-box batching algorithms which may be configured in the
batch_algorithm column on channel.
</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">default</strong></span>
</span></dt><dd>
<p>All changes that happen in a transaction are guaranteed to
be batched together. Multiple transactions will be batched and committed
together until there is no more data to be sent or the max_batch_size is
reached.</p>
</dd><dt><span class="term">
<span><strong class="command">transactional</strong></span>
</span></dt><dd>
<p>Batches will map directly to database transactions. If
there are many small database transactions, then there will be many
batches. The max_batch_size column has no effect.</p>
</dd><dt><span class="term">
<span><strong class="command">nontransactional</strong></span>
</span></dt><dd>
<p>Multiple transactions will be batched and committed
together until there is no more data to be sent or the max_batch_size is
reached. The batch will be cut off at the max_batch_size regardless of
whether it is in the middle of a transaction.</p>
</dd></dl></div><p>
</p>

<p>
If a channel contains
<span class="emphasis"><em>only</em></span>
tables that will be synchronized in one direction and and data is routed
to all the nodes in the target node groups, then batching on the channel
can be optimized to share batches across nodes. This is an important
feature when data needs to be routed to thousands of nodes. When this
mode is detected, you will see batches created in
<a href="data-model.html#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
with the
<code class="literal">common_flag</code>
set to 1.
</p>

<p>
There are also several size-related parameters that can be set by
channel. They include:
</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">max_batch_size</strong></span>
</span></dt><dd>
<p>Specifies the maximum number of data events to process
within a batch for this channel.</p>
</dd><dt><span class="term">
<span><strong class="command">max_batch_to_send</strong></span>
</span></dt><dd>
<p>Specifies the maximum number of batches to send for a given
channel during a 'synchronization' between two nodes. A
'synchronization' is equivalent to a push or a pull. For example, if
there are 12 batches ready to be sent for a channel and
max_batch_to_send is equal to 10, then only the first 10 batches will be
sent even though 12 batches are ready.</p>
</dd><dt><span class="term">
<span><strong class="command">max_data_to_route</strong></span>
</span></dt><dd>
<p>Specifies the maximum number of data rows to route for a
channel at a time.</p>
</dd></dl></div><p>
</p>

<p>Based on your particular synchronization requirements, you
can also specify whether old, new, and primary key data should be read
and included during routing for a given channel. These are controlled by
the columns use_old_data_to_route, use_row_data_to_route, and
use_pk_data_to_route, respectively. By default, they are all 1 (true).</p>

<p>
Finally, if data on a particular channel contains big lobs, you can set
the column contains_big_lob to 1 (true) to provide SymmetricDS the hint
that the channel contains big lobs. Some databases have shortcuts that
SymmetricDS can take advantage of if it knows that the lob columns in
<a href="data-model.html#table_data" title="A.3.&nbsp;DATA">DATA</a>
aren't going to contain large lobs. The definition of how large a 'big'
lob is varies from database to database.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-triggers-and-routers"></a>4.6.&nbsp;Triggers, Routers, and Trigger / Routers Mappings</h2></div></div></div>


<p>In order to synchronize data, you must define at least one
trigger, at least one router, and provide at least one link between the
two (known as a trigger-router). </p>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="configuration-trigger"></a>4.6.1.&nbsp;Trigger</h3></div></div></div>


<p>
SymmetricDS captures synchronization data using database triggers.
SymmetricDS' Triggers are defined in the
<a href="data-model.html#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
table. Each record is used by SymmetricDS when generating database
triggers. Database triggers are only generated when a trigger is
associated with a
<a href="data-model.html#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
whose
<code class="literal">source_node_group_id</code>
matches the node group id of the current node.
</p>

<p>
The
<code class="literal">source_table_name</code>
may contain the asterisk ('*') wildcard character so that one
<a href="data-model.html#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
table entry can define synchronization for many tables. System tables
and any tables that start with the SymmetricDS table prefix will be
excluded. A list of wildcard tokens can also be supplied. If there are
multiple tokens, they should be delimited with a comma. A wildcard token
can also start with a bang ('!') to indicate an exclusive match. Tokens
are always evalulated from left to right. When a table match is made,
the table is either added to or removed from the list of tables. If
another trigger already exists for a table, then that table is not
included in the wildcard match (the explictly defined trigger entry take
precendence).
</p>

<p>
When determining whether a data change has occurred or not, by defalt
the triggers will record a change even if the data was updated to the
same value(s) they were originally. For example, a data change will be
captured if an update of one column in a row updated the value to the
same value it already was. There is a global property,
<code class="literal">trigger.update.capture.changed.data.only.enabled</code>
(false by default), that allows you to override this behavior. When set
to true, SymmetricDS will only capture a change if the data has truly
changed (i.e., when the new column data is not equal to the old column
data).
</p>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
The property
<code class="literal">trigger.update.capture.changed.data.only.enabled</code>
is currently only supported in the MySQL, DB2 and Oracle dialects.
</div>

<p>
The following SQL statement defines a trigger that will capture data for
a table named "item" whenever data is inserted, updated, or deleted. The
trigger is assigned to a channel also called 'item'.
</p><pre class="programlisting"> insert into SYM_TRIGGER
(trigger_id,source_table_name,channel_id,last_update_time,create_time)
values ('item', 'item', 'item', current_timestamp, current_timestamp); </pre><p>
</p>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
<p>Note that many databases allow for multiple triggers of the
same type to be defined. Each database defines the order in which the
triggers fire differently. If you have additional triggers beyond those
SymmetricDS installs on your table, please consult your database
documentation to determine if there will be issues with the ordering of
the triggers.</p>
</div>


<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-trigger-lobs"></a>4.6.1.1.&nbsp;Large Objects</h4></div></div></div>

<p>
Two lobs-related settings are also available on
<a href="data-model.html#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
:
</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">use_stream_lobs</strong></span>
</span></dt><dd>
<p>Specifies whether to capture lob data as the trigger is
firing or to stream lob columns from the source tables using callbacks
during extraction. A value of 1 indicates to stream from the source via
callback; a value of 0, lob data is captured by the trigger.</p>
</dd><dt><span class="term">
<span><strong class="command">use_capture_lobs</strong></span>
</span></dt><dd>
<p>Provides a hint as to whether this trigger will capture big
lobs data. If set to 1 every effort will be made during data capture in
trigger and during data selection for initial load to use lob facilities
to extract and store data in the database.</p>
</dd></dl></div><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-trigger-external-select"></a>4.6.1.2.&nbsp;External Select</h4></div></div></div>


<p>
Occasionally, you may find that you need to capture and save away a
piece of data present in another table when a trigger is firing. This
data is typically needed for the purposes of determining where to
'route' the data to once routing takes place. Each trigger definition
contains an optional
<code class="literal">external_select</code>
field which can be used to specify the data to be captured. Once
captured, this data is available during routing in
<a href="data-model.html#table_data" title="A.3.&nbsp;DATA">DATA</a>
's
<code class="literal">external_data</code>
field. For these cases, place a SQL select statement which returns the
data item you need for routing in
<code class="literal">external_select</code>
. An example of the use of external select can be found in
<a href="configuration.html#configuration-routing-external-select" title="4.6.2.7.&nbsp;Utilizing External Select when Routing">Section&nbsp;4.6.2.7, &#8220;Utilizing External Select when Routing&#8221;</a>
.
</p>
</div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="configuration-router"></a>4.6.2.&nbsp;Router</h3></div></div></div>


<p>
Routers provided in the base implementation currently include:
</p><div class="itemizedlist"><ul type="disc"><li>Default Router - a router that sends all data to
all nodes that belong to the target node group defined in the router.</li><li>Column Match Router - a router that compares old or
new column values to a constant value or the value of a node's
external_id or node_id.</li><li>Lookup Router - a router which can be configured to
determine routing based on an existing or ancillary table specifically
for the purpose of routing data.</li><li>Subselect Router - a router that executes a SQL
expression against the database to select nodes to route to. This SQL
expression can be passed values of old and new column values.</li><li>Scripted Router - a router that executes a Bean
Shell script expression in order to select nodes to route to. The script
can use the old and new column values.</li><li>Xml Publishing Router - a router the publishes data
changes directly to a messaging solution instead of transmitting changes
to registered nodes. This router must be configured manually in XML as
an extension point.</li><li>Audit Table Router - a router that inserts into an
automatically created audit table. It records captured changes to tables
that it is linked to. </li></ul></div><p>
The mapping between the set of triggers and set of routers is
many-to-many. This means that one trigger can capture changes and route
to multiple locations. It also means that one router can be defined an
associated with many different triggers.
</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-default-router"></a>4.6.2.1.&nbsp;Default Router</h4></div></div></div>


<p>
The simplest router is a router that sends all the data that is captured
by its associated triggers to all the nodes that belong to the target
node group defined in the router. A router is defined as a row in the
<a href="data-model.html#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table. It is then linked to triggers in the
<a href="data-model.html#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
table.
</p>

<p>
The following SQL statement defines a router that will send data from
the 'corp' group to the 'store' group.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, create_time,
last_update_time) values ('corp-2-store','corp', 'store',
current_timestamp, current_timestamp); </pre><p>
</p>

<p>
The following SQL statement maps the 'corp-2-store' router to the item
trigger.
</p><pre class="programlisting"> insert into SYM_TRIGGER_ROUTER
(trigger_id, router_id, initial_load_order, create_time,
last_update_time) values ('item', 'corp-2-store', 1, current_timestamp,
current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-column-match-router"></a>4.6.2.2.&nbsp;Column Match Router</h4></div></div></div>


<p>
Sometimes requirements may exist that require data to be routed based on
the current value or the old value of a column in the table that is
being routed. Column routers are configured by setting the
<code class="literal">router_type</code>
column on the
<a href="data-model.html#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table to
<code class="literal">column</code>
and setting the
<code class="literal">router_expression</code>
column to an equality expression that represents the expected value of
the column.
</p>

<p>The first part of the expression is always the column name.
The column name should always be defined in upper case. The upper case
column name prefixed by OLD_ can be used for a comparison being done
with the old column data value.</p>

<p>The second part of the expression can be a constant value,
a token that represents another column, or a token that represents some
other SymmetricDS concept. Token values always begin with a colon (:).</p>

<p>
Consider a table that needs to be routed to all nodes in the target
group only when a status column is set to 'READY TO SEND.' The following
SQL statement will insert a column router to accomplish that.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-ok','corp', 'store', 'column', 'STATUS=READY TO SEND',
current_timestamp, current_timestamp); </pre><p>
</p>

<p>
Consider a table that needs to be routed to all nodes in the target
group only when a status column changes values. The following SQL
statement will insert a column router to accomplish that. Note the use
of OLD_STATUS, where the OLD_ prefix gives access to the old column
value.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-status','corp', 'store', 'column', 'STATUS!=:OLD_STATUS',
current_timestamp, current_timestamp); </pre><p>
</p>

<p>
Consider a table that needs to be routed to only nodes in the target
group whose STORE_ID column matches the external id of a node. The
following SQL statement will insert a column router to accomplish that.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-id','corp', 'store', 'column', 'STORE_ID=:EXTERNAL_ID',
current_timestamp, current_timestamp); </pre><p>
Attributes on a
<a href="data-model.html#table_node" title="A.17.&nbsp;NODE">NODE</a>
that can be referenced with tokens include:
</p><div class="itemizedlist"><ul type="disc"><li>:NODE_ID</li><li>:EXTERNAL_ID</li><li>:NODE_GROUP_ID</li></ul></div><p>
Captured EXTERNAL_DATA is also available for routing as a virtual
column.
</p>

<p>
Consider a table that needs to be routed to a redirect node defined by
its external id in the
<a href="data-model.html#table_registration_redirect" title="A.31.&nbsp;REGISTRATION_REDIRECT">REGISTRATION_REDIRECT</a>
table. The following SQL statement will insert a column router to
accomplish that.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-redirect','corp', 'store', 'column',
'STORE_ID=:REDIRECT_NODE', current_timestamp, current_timestamp); </pre><p>
</p>

<p>
More than one column may be configured in a router_expression. When more
than one column is configured, all matches are added to the list of
nodes to route to. The following is an example where the STORE_ID column
may contain the STORE_ID to route to or the constant of ALL which
indicates that all nodes should receive the update.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-multiple-matches','corp', 'store', 'column',
'STORE_ID=ALL or STORE_ID=:EXTERNAL_ID', current_timestamp,
current_timestamp); </pre><p>
</p>

<p>
The NULL keyword may be used to check if a column is null. If the column
is null, then data will be routed to all nodes who qualify for the
update. This following is an example where the STORE_ID column is used
to route to a set of nodes who have a STORE_ID equal to their
EXTERNAL_ID, or to all nodes if the STORE_ID is null.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-multiple-matches','corp', 'store', 'column',
'STORE_ID=NULL or STORE_ID=:EXTERNAL_ID', current_timestamp,
current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-lookup-table-router"></a>4.6.2.3.&nbsp;Lookup Table Router</h4></div></div></div>


<p>
A lookup table may contain the id of the node where data needs to be
routed. This could be an existing table or an ancillary table that is
added specifically for the purpose of routing data. Lookup table routers
are configured by setting the
<code class="literal">router_type</code>
column on the
<a href="data-model.html#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table to
<code class="literal">lookuptable</code>
and setting a list of configuration parameters in the
<code class="literal">router_expression</code>
column.
</p>

<p>
Each of the following configuration parameters are required.
</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">LOOKUP_TABLE</strong></span>
</span></dt><dd>
<p>This is the name of the lookup table.</p>
</dd><dt><span class="term">
<span><strong class="command">KEY_COLUMN</strong></span>
</span></dt><dd>
<p>This is the name of the column on the table that is being
routed. It will be used as a key into the lookup table.</p>
</dd><dt><span class="term">
<span><strong class="command">LOOKUP_KEY_COLUMN</strong></span>
</span></dt><dd>
<p>This is the name of the column that is the key on the
lookup table.</p>
</dd><dt><span class="term">
<span><strong class="command">EXTERNAL_ID_COLUMN</strong></span>
</span></dt><dd>
<p>This is the name of the column that contains the
external_id of the node to route to on the lookup table.</p>
</dd></dl></div><p>
</p>

<p>Note that the lookup table will be read into memory and
cached for the duration of a routing pass for a single channel.</p>

<p>
Consider a table that needs to be routed to a specific store, but the
data in the changing table only contains brand information. In this
case, the STORE table may be used as a lookup table.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-ok','corp', 'store', 'lookuptable', 'LOOKUP_TABLE=STORE
KEY_COLUMN=BRAND_ID LOOKUP_KEY_COLUMN=BRAND_ID
EXTERNAL_ID_COLUMN=STORE_ID', current_timestamp, current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-subselect-router"></a>4.6.2.4.&nbsp;Subselect Router</h4></div></div></div>


<p>
Sometimes routing decisions need to be made based on data that is not in
the current row being synchronized. A 'subselect' router can be used in
these cases. A 'subselect' is configured with a
<code class="literal">router_expression</code>
that is a SQL select statement which returns a result set of the node
ids that need routed to. Column tokens can be used in the SQL expression
and will be replaced with row column data. The overhead of using this
router type is high because the 'subselect' statement runs for each row
that is routed. It should not be used for tables that have a lot of rows
that are updated. It also has the disadvantage that if the data being
relied on to determine the node id has been deleted before routing takes
place, then no results would be returned and routing would not happen.
</p>
<p>
The
<code class="literal">router_expression</code>
you specify is appended to the following SQL statement in order to
select the node ids:
</p><pre class="programlisting">select c.node_id from sym_node c where
c.node_group_id=:NODE_GROUP_ID and c.sync_enabled=1 and ... </pre><p>
</p><p>
As you can see, you have access to information about the node currently
under consideration for routing through the 'c' alias, for example
<code class="literal">c.external_id</code>
. There are two node-related tokens you can use in your expression:
</p><div class="itemizedlist"><ul type="disc"><li>:NODE_GROUP_ID</li><li>:EXTERNAL_DATA</li></ul></div><p>
</p><p>
Column names representing data for the row in question are prefixed with
a colon as well, for example:

<code class="literal">:EMPLOYEE_ID</code>
, or
<code class="literal">:OLD_EMPLOYEE_ID</code>
. Here, the OLD_ prefix indicates the value before the change in cases
where the old data has been captured.

</p>
<p> For an example, consider the case where an Order table and
an OrderLineItem table need to be routed to a specific store. The Order
table has a column named order_id and STORE_ID. A store node has an
external_id that is equal to the STORE_ID on the Order table.
OrderLineItem, however, only has a foreign key to its Order of order_id.
To route OrderLineItems to the same nodes that the Order will be routed
to, we need to reference the master Order record.</p>

<p>
There are two possible ways to solve this in SymmetricDS. One is to
configure a 'subselect' router_type on the
<a href="data-model.html#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table, shown below (The other possible approach is to use an
<code class="literal">external_select</code>
to capture the data via a trigger for use in a column match router,
demonstrated in
<a href="configuration.html#configuration-routing-external-select" title="4.6.2.7.&nbsp;Utilizing External Select when Routing">Section&nbsp;4.6.2.7, &#8220;Utilizing External Select when Routing&#8221;</a>
).
</p>

<p>
Our solution utilizing subselect compares the external id of the current
node with the store id from the Order table where the order id matches
the order id of the current row being routed:
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store','corp', 'store', 'subselect', 'c.external_id in (select
STORE_ID from order where order_id=:ORDER_ID)', current_timestamp,
current_timestamp); </pre><p>
</p>

<p>As a final note, please note in this example that the
parent row in Order must still exist at the moment of routing for the
child rows (OrderLineItem) to route, since the select statement is run
when routing is occurring, not when the change data is first captured. </p>

</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-scripted-router"></a>4.6.2.5.&nbsp;Scripted Router</h4></div></div></div>


<p>
When more flexibility is needed in the logic to choose the nodes to
route to, then the a scripted router may be used. The currently
available scripting language is Bean Shell. Bean Shell is a Java-like
scripting language. Documentation for the Bean Shell scripting language
can be found at
<a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://www.beanshell.org/" target="_top">http://www.beanshell.org</a>
.
</p>

<p>
The router_type for a Bean Shell scripted router is 'bsh'. The
router_expression is a valid Bean Shell script that:
</p><div class="itemizedlist"><ul type="disc"><li>
adds node ids to the
<code class="code">targetNodes</code>
collection which is bound to the script
</li><li>returns a new collection of node ids</li><li>returns a single node id</li><li>returns true to indicate that all nodes should be
routed or returns false to indicate that no nodes should be routed</li></ul></div><p>
Also bound to the script evaluation is a list of
<code class="code">nodes</code>
. The list of
<code class="code">nodes</code>
is a list of eligible
<code class="code">org.jumpmind.symmetric.model.Node</code>
objects. The current data column values and the old data column values
are bound to the script evaluation as Java object representations of the
column data. The columns are bound using the uppercase names of the
columns. Old values are bound to uppercase representations that are
prefixed with 'OLD_'.
</p>

<p>
If you need access to any of the SymmetricDS services, then the instance
of
<code class="code">org.jumpmind.symmetric.ISymmetricEngine</code>
is accessible via the bound
<code class="code">engine</code>
variable.
</p>

<p>
In the following example, the node_id is a combination of STORE_ID and
WORKSTATION_NUMBER, both of which are columns on the table that is being
routed.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-bsh','corp', 'store', 'bsh', 'targetNodes.add(STORE_ID +
"-" + WORKSTATION_NUMBER);', current_timestamp, current_timestamp); </pre><p>
</p>

<p>
The same could also be accomplished by simply returning the node id. The
last line of a bsh script is always the return value.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-bsh','corp', 'store', 'bsh', 'STORE_ID + "-" +
WORKSTATION_NUMBER', current_timestamp, current_timestamp); </pre><p>
</p>

<p>
The following example will synchronize to all nodes if the FLAG column
has changed, otherwise no nodes will be synchronized. Note that here we
make use of OLD_, which provides access to the old column value.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-flag-changed','corp', 'store', 'bsh', 'FLAG != null
&amp;&amp; !FLAG.equals(OLD_FLAG)', current_timestamp,
current_timestamp); </pre><p>
</p>

<p>
The next example shows a script that iterates over each eligible node
and checks to see if the trimmed value of the column named STATION
equals the external_id.
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-trimmed-station','corp', 'store', 'bsh', 'for
(org.jumpmind.symmetric.model.Node node : nodes) { if (STATION != null
&amp;&amp; node.getExternalId().equals(STATION.trim())) {
targetNodes.add(node.getNodeId()); } }', current_timestamp,
current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-audit-table-router"></a>4.6.2.6.&nbsp;Audit Table Router</h4></div></div></div>


<p>
This router audits captured data by recording the change in an audit
table that the router creates and keeps up to date (as long as
<code class="code">auto.config.database</code>
is set to true.) The router creates a table named the same as the table
for which data was captured with the suffix of _AUDIT. It will contain
all of the same columns as the original table with the same data types
only each column is nullable with no default values.
</p>

<p>
Three extra "AUDIT" columns are added to the table:
</p><div class="itemizedlist"><ul type="disc"><li>AUDIT_ID - the primary key of the table.</li><li>AUDIT_TIME - the time at which the change occurred.</li><li>AUDIT_EVENT - the DML type that happened to the
row.</li></ul></div><p>
</p>

<p>
The following is an example of an audit router
</p><pre class="programlisting"> insert into SYM_ROUTER (router_id,
source_node_group_id, target_node_group_id, router_type, create_time,
last_update_time) values ('audit_at_corp','corp', 'local', 'audit',
current_timestamp, current_timestamp); </pre><p>
</p>

<p>The audit router captures data for a group link. For the
audit router to work it must be associated with a node_group_link with
an action of type 'R'. The 'R' stands for 'only routes to'. In the above
example, we refer to a 'corp to local' group link. Here, local is a new
node_group created for the audit router. No nodes belong to the 'local'
node_group. If a trigger linked to an audit router fires on the corp
node, a new audit table will be created at the corp node with the new
data inserted.</p>
</div>




<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-routing-external-select"></a>4.6.2.7.&nbsp;Utilizing External Select when Routing</h4></div></div></div>




<p>
There may be times when you wish to route based on a piece of data that
exists in a table other than the one being routed. The approach, first
discussed in
<a href="configuration.html#configuration-subselect-router" title="4.6.2.4.&nbsp;Subselect Router">Section&nbsp;4.6.2.4, &#8220;Subselect Router&#8221;</a>
, is to utilize an
<code class="literal">external_select</code>
to save away data in
<code class="literal">external_data</code>
, which can then be referenced during routing.
</p>
<p>
Reconsider subselect's Order / OrderLineItem example (found in
<a href="configuration.html#configuration-subselect-router" title="4.6.2.4.&nbsp;Subselect Router">Section&nbsp;4.6.2.4, &#8220;Subselect Router&#8221;</a>
), where routing for the line item is accomplished by linking to the
"header" Order row. As an alternate way of solving the problem, we will
now use External Select combined with a column match router.
</p>
<p>
In this version of the solution, the STORE_ID is captured from the Order
table in the EXTERNAL_DATA column when the trigger fires. The router is
configured to route based on the captured EXTERNAL_DATA to all nodes
whose external id matches the captured external data.
</p><pre class="programlisting">insert into SYM_TRIGGER
(trigger_id,source_table_name,channel_id,external_select,
last_update_time,create_time) values ('orderlineitem', 'orderlineitem',
'orderlineitem','select STORE_ID from order where
order_id=$(curTriggerValue).$(curColumnPrefix)order_id',
current_timestamp, current_timestamp); insert into SYM_ROUTER
(router_id, source_node_group_id, target_node_group_id, router_type,
router_expression, create_time, last_update_time) values
('corp-2-store-ext','corp', 'store', 'column',
'EXTERNAL_DATA=:EXTERNAL_ID', current_timestamp, current_timestamp); </pre><p>
</p>

<p>The following variables can be used with the external select:</p>

<div class="variablelist"><dl><dt><span class="term">
    		<span><strong class="command">$(curTriggerValue)</strong></span>
		</span></dt><dd>
    		<p>
    		  Variable to be replaced with the NEW or OLD column alias provided by the trigger context, which is platform specific.
    		  For insert and update triggers, the NEW alias is used; for delete triggers, the OLD alias is used.
    		  For example, "$(curTriggerValue).COLUMN" becomes ":new.COLUMN" for an insert trigger on Oracle.
    		</p>
		</dd><dt><span class="term">
            <span><strong class="command">$(curColumnPrefix)</strong></span>
        </span></dt><dd>
            <p>
                Variable to be replaced with the NEW_ or OLD_ column prefix for platforms that don't support column aliases.
                This is currently only used by the H2 database.  All other platforms will replace the variable with an empty string.
                For example "$(curColumnPrefix)COLUMN" becomes "NEW_COLUMN" on H2 and "COLUMN" on Oracle.
            </p>
        </dd></dl></div>

<p>The advantage of this approach over the 'subselect'
approach is that it guards against the (somewhat unlikely) possibility
that the master Order table row might have been deleted before routing
has taken place. This external select solution also is a bit more
efficient than the 'subselect' approach, although the triggers produced
do run the extra external_select SQL inline with application database
updates.</p>

</div>

</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="configuration-trigger-router"></a>4.6.3.&nbsp;Trigger / Router Mappings</h3></div></div></div>


<p>
The
<a href="data-model.html#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
table is used to define which specific combinations of triggers and
routers are needed for your configuration. The relationship between
triggers and routers is many-to-many, so this table serves as the join
table to define which combinations are valid, as well as to define
settings available at the trigger-router level of granularity.
</p>
<p>
Three important controls can be configured for a specific Trigger /
Router combination: Enabled, Initial Loads and Ping Back. The parameters
for these can be found in the Trigger / Router mapping table,
<a href="data-model.html#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
.
</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-trigger-router-enabled"></a>4.6.3.1.&nbsp;Enable / disable trigger router</h4></div></div></div>


<p>
Each individual trigger-router combination can be disabled or enabled if
needed. By default, a trigger router is enabled, but if you have a
reason you wish to define a trigger router combination prior to it being
active, you can set the
<code class="literal">enabled</code>
flag to 0. This will cause the trigger-router mapping to be sent to all
nodes, but the trigger-router mapping will not be considered active or
enabled for the purposes of capturing data changes or routing.
</p>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-initial-load"></a>4.6.3.2.&nbsp;Initial Loads</h4></div></div></div>



<p>An initial load is the process of seeding tables at a
target node with data from its parent node. When a node connects and
data is extracted, after it is registered and if an initial load was
requested, each table that is configured to synchronize to the target
node group will be given a reload event in the order defined by the end
user. A SQL statement is run against each table to get the data load
that will be streamed to the target node. The selected data is filtered
through the configured router for the table being loaded. If the data
set is going to be large, then SQL criteria can optionally be provided
to pare down the data that is selected out of the database.</p>

<p>
An initial load cannot occur until after a node is registered. An
initial load is requested by setting the
<code class="literal">initial_load_enabled</code>
column on
<a href="data-model.html#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
to
<span class="emphasis"><em>1</em></span>
on the row for the target node in the parent node's database. You can
configure SymmetricDS to automatically perform an initial load when a
node registers by setting the parameter
<code class="literal">auto.reload</code>
to true. Regardless of how the initial load is initiated, the next time
the source node routes data, reload batches will be inserted. At the
same time reload batches are inserted, all previously pending batches
for the node are marked as successfully sent.
</p>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
<p>
Note that if the parent node that a node is registering with is
<span class="emphasis"><em>not</em></span>
a registration server node (as can happen with a registration redirect
or certain non-tree structure node configurations) the parent node's
<a href="data-model.html#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
entry must exist at the parent node and have a non-null value for column
<code class="literal">initial_load_time</code>
. Nodes can't be registered to non-registration-server nodes without
this value being set one way or another (i.e., manually, or as a result
of an initial load occurring at the parent node).
</p>
</div>

<p>
SymmetricDS recognizes that an initial load has completed when the
<code class="literal">initial_load_time</code>
column on the target node is set to a non-null value.
</p>

<p>
An initial load is accomplished by inserting reload batches in a defined
order according to the
<code class="literal">initial_load_order</code>
column on
<a href="data-model.html#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
. If the
<code class="literal">initial_load_order</code>
column contains a negative value the associated table will
<span class="emphasis"><em>NOT</em></span>
be loaded. If the
<code class="literal">initial_load_order</code>
column contains the same value for multiple tables, SymmetricDS will
attempt to order the tables according to foreign key constraints. If
there are cyclical constraints, then foreign keys might need to be
turned off or the initial load will need to be manually configured based
on knowledge of how the data is structured.
</p>

<p>Initial load data is always queried from the source
database table. All data is passed through the configured router to
filter out data that might not be targeted at a node.</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="configuration-initial-load-options"></a>Target table prep for initial load</h5></div></div></div>

<p>There are several parameters that can be used to specify
what, if anything, should be done to the table on the target database
just prior to loading the data. Note that the parameters below specify
the desired behavior for all tables in the initial load, not just one. </p>
<div class="itemizedlist"><ul type="disc"><li>
<code class="literal">initial.load.delete.first /
initial.load.delete.first.sql</code>
<p>
By default, an initial load will not delete existing rows from a target
table before loading the data. If a delete is desired, the parameter
<code class="literal">initial.load.delete.first</code>
can be set to true. If true, the command found in
<code class="literal">initial.load.delete.first.sql</code>
will be run on each table prior to loading the data. The default value
for
<code class="literal">initial.load.delete.first.sql</code>
is
<code class="literal">delete from %s</code>
, but could be changed if needed. Note that additional reload batches
are created, in the correct order, to achieve the delete.
</p>
</li><li>
<code class="literal">initial.load.create.first</code>
<p>
By default, an initial load will not create the table on the target if
it doesn't alleady exist. If the desired behavior is to create the table
on the target if it is not present, set the parameter
<code class="literal">intial.load.create.first</code>
to true. SymmetricDS will attempt to create the table and indexes on the
target database before doing the initial load. (Additional batches are
created to represent the table schema).
</p>
</li></ul></div>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="configuration-initial-load-select"></a>Loading subsets of data</h5></div></div></div>


<p>
An efficient way to select a subset of data from a table for an initial
load is to provide an
<code class="literal">initial_load_select</code>
clause on
<a href="data-model.html#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>
. This clause, if present, is applied as a
<code class="literal">where</code>
clause to the SQL used to select the data to be loaded. The clause may
use "t" as an alias for the table being loaded, if needed. The
<code class="literal">$(externalId)</code>
token can be used for subsetting the data in the where clause.
</p>

<p>
In cases where routing is done using a feature like
<a href="configuration.html#configuration-subselect-router" title="4.6.2.4.&nbsp;Subselect Router">Section&nbsp;4.6.2.4, &#8220;Subselect Router&#8221;</a>
, an
<code class="literal">initial_load_select</code>
clause matching the subselect's criteria would be a more efficient
approach. Some routers will check to see if the
<code class="literal">initial_load_select</code>
clause is provided, and they will
<span class="emphasis"><em>not</em></span>
execute assuming that the more optimal path is using the
<code class="literal">initial_load_select</code>
statement.
</p>

<p>
One example of the use of an initial load select would be if you wished
to only load data created more recently than the start of year 2011.
Say, for example, the column
<code class="literal">created_time</code>
contains the creation date. Your
<code class="literal">initial_load_select</code>
would read
<code class="literal">created_time &gt; ts {'2011-01-01 00:00:00.0000'}</code>
(using whatever timestamp format works for your database). This then
gets applied as a
<code class="literal">where</code>
clause when selecting data from the table.
</p>

<div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
<p>
When providing an
<code class="literal">initial_load_select</code>
be sure to test out the criteria against production data in a query
browser. Do an explain plan to make sure you are properly using indexes.
</p>
</div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="configuration-initial-load-batches"></a>Splitting an Initial Load for a Table Across Multiple Batches</h5></div></div></div>

<p>
By default, all data for a given table will be initial loaded in a single batch, regardless
of the max batch size parameter on the reload channel.  That is, for a table with one million
rows, all rows for that table will be initial loaded and sent to the destination node in a
single batch. For large tables, this can result in a batch that can take a long time to
extract and load.
</p>

<p>
Initial loads for a table can be broken into multiple batches by specifying
<code class="literal">initial.load.use.extract.job.enabled</code> to true.  This parameter allows
SymmetricDS to pre-extract initial load batches versus having them extracted when
the batch is pulled or pushed.  When using this parameter, there are two ways to tell
SymmetricDS the number of batches to create for a given table.  The first is to specify
a positive integer in the initial_load_batch_count column on
<a href="data-model.html#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a>.  This
number will dictate the number of batches created for the initial load of the given table.
The second way is to specify 0 for initial_load_batch_count on
<a href="data-model.html#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a> and
specify a max_batch_size on the reload channel in <a href="data-model.html#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>.
When 0 is specified for
initial_load_batch_count, SymmetricDS will execute a count(*) query on the table during
the extract process and create N batches based on the total number of records found
in the table divided by the max_batch_size on the reload channel.
</p>

</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="configuration-initial-load-reverse"></a>Reverse Initial Loads</h5></div></div></div>

<p>
The default behavior for initial loads is to load data from the
registration server or parent node, to a client node. Occasionally,
there may be need to do a one-time intial load of data in the opposite
or "reverse" direction, namely from a client node to the registration
node. To achieve this, set the parameter
<code class="literal">auto.reload.reverse</code>
to be true,
<span class="emphasis"><em>but only for the specific node group representing
the client nodes</em></span>
. This will cause a onetime reverse load of data, for tables configured
with non-negative initial load orders, to be batched at the point when
registration of the client node is occurring. These batches are then
sent to the parent or registration node. This capability might be
needed, for example, if there is data already present in the client that
doesn't exist in the parent but needs to.
</p>
</div>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-dead-triggers"></a>4.6.3.3.&nbsp;Dead Triggers</h4></div></div></div>


<p>
Occasionally the decision of what data to load initially results in
additional triggers. These triggers, known as
<span class="emphasis"><em>Dead Triggers</em></span>
, are configured such that they do not capture any data changes. A
"dead" Trigger is one that does not capture data changes. In other
words, the
<code class="literal">sync_on_insert</code>
,
<code class="literal">sync_on_update</code>
, and
<code class="literal">sync_on_delete</code>
properties for the Trigger are all set to false. However, since the
Trigger is specified, it
<span class="emphasis"><em>will</em></span>
be included in the initial load of data for target Nodes.
</p>

<p>Why might you need a Dead Trigger? A dead Trigger might be
used to load a read-only lookup table, for example. It could also be
used to load a table that needs populated with example or default data.
Another use is a recovery load of data for tables that have a single
direction of synchronization. For example, a retail store records sales
transactions that synchronize in one direction by trickling back to the
central office. If the retail store needs to recover all the sales
transactions from the central office, they can be sent are part of an
initial load from the central office by setting up dead Triggers that
"sync" in that direction.</p>

<p>
The following SQL statement sets up a non-syncing dead Trigger that
sends the
<code class="literal">sale_transaction</code>
table to the "store" Node Group from the "corp" Node Group during an
initial load.
</p><pre class="programlisting"> insert into sym_trigger
(TRIGGER_ID,SOURCE_CATALOG_NAME,
SOURCE_SCHEMA_NAME,SOURCE_TABLE_NAME,CHANNEL_ID,
SYNC_ON_UPDATE,SYNC_ON_INSERT,SYNC_ON_DELETE,
SYNC_ON_INCOMING_BATCH,NAME_FOR_UPDATE_TRIGGER,
NAME_FOR_INSERT_TRIGGER,NAME_FOR_DELETE_TRIGGER,
SYNC_ON_UPDATE_CONDITION,SYNC_ON_INSERT_CONDITION,
SYNC_ON_DELETE_CONDITION,EXTERNAL_SELECT,
TX_ID_EXPRESSION,EXCLUDED_COLUMN_NAMES,
CREATE_TIME,LAST_UPDATE_BY,LAST_UPDATE_TIME) values
('SALE_TRANSACTION_DEAD',null,null, 'SALE_TRANSACTION','transaction',
0,0,0,0,null,null,null,null,null,null,null,null,null,
current_timestamp,'demo',current_timestamp); insert into sym_router
(ROUTER_ID,TARGET_CATALOG_NAME,TARGET_SCHEMA_NAME,
TARGET_TABLE_NAME,SOURCE_NODE_GROUP_ID,TARGET_NODE_GROUP_ID,ROUTER_TYPE,
ROUTER_EXPRESSION,SYNC_ON_UPDATE,SYNC_ON_INSERT,SYNC_ON_DELETE,
CREATE_TIME,LAST_UPDATE_BY,LAST_UPDATE_TIME) values
('CORP_2_STORE',null,null,null, 'corp','store',null,null,1,1,1,
current_timestamp,'demo',current_timestamp); insert into
sym_trigger_router (TRIGGER_ID,ROUTER_ID,INITIAL_LOAD_ORDER,
INITIAL_LOAD_SELECT,CREATE_TIME,LAST_UPDATE_BY,LAST_UPDATE_TIME) values
('SALE_TRANSACTION_DEAD','CORP_2_REGION',100,null,
current_timestamp,'demo',current_timestamp); </pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="configuration-trigger-router-ping-back"></a>4.6.3.4.&nbsp;Enabling "Ping Back"</h4></div></div></div>


<p>
As discussed in
<a href="planning.html#defining-data-changes-trigger-routers-ping-back" title="3.6.3.2.&nbsp;Circular References and &#34;Ping Back&#34;">Section&nbsp;3.6.3.2, &#8220;Circular References and "Ping Back"&#8221;</a>
SymmetricDS, by default, avoids circular data changes. When a trigger
fires as a result of SymmetricDS itself (such as the case when sync on
incoming batch is set), it records the originating source node of the
data change in
<code class="literal">source_node_id</code>
. During routing, if routing results in sending the data back to the
originating source node, the data is not routed by default. If instead
you wish to route the data back to the originating node, you can set the
<code class="literal">ping_back_enabled</code>
column for the needed particular trigger / router combination. This will
cause the router to "ping" the data back to the originating node when it
usually would not.
</p>
</div>
</div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="configuration-registration"></a>4.7.&nbsp;Opening Registration</h2></div></div></div>


<p>
Node registration is the act of setting up a new
<a href="data-model.html#table_node" title="A.17.&nbsp;NODE">NODE</a>
and
<a href="data-model.html#table_node_security" title="A.28.&nbsp;NODE_SECURITY">NODE_SECURITY</a>
so that when the new node is brought online it is allowed to join the
system. Nodes are only allowed to register if rows exist for the node
and the
<code class="literal">registration_enabled</code>
flag is set to 1. If the
<code class="literal">auto.registration</code>
SymmetricDS property is set to true, then when a node attempts to
register, if registration has not already occurred, the node will
automatically be registered.
</p>

<p>
SymmetricDS allows you to have multiple nodes with the same
<code class="literal">external_id</code>
. Out of the box, openRegistration will open a new registration if a
registration already exists for a node with the same external_id. A new
registration means a new node with a new
<code class="literal">node_id</code>
and the same
<code class="literal">external_id</code>
will be created. If you want to re-register the same node you can use
the
<code class="literal">reOpenRegistration()</code>
JMX method which takes a
<code class="literal">node_id</code>
as an argument.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="transform-data"></a>4.8.&nbsp;Transforming Data</h2></div></div></div>


<p>New as of SymmetricDS 2.4, SymmetricDS is now able to
transform synchronized data by way of configuration (previously, for
most cases a custom data loader would need to have been written). This
transformation can take place on a source node or on a target node, as
the data is being loaded or extracted. With this new feature you can,
for example:</p>

<div class="itemizedlist"><ul type="disc"><li>
<p>Copy a column from a source table to two (or more) target
table columns,</p>
</li><li>
<p>Merge columns from two or more source tables into a single
row in a target table,</p>
</li><li>
<p>Insert constants in columns in target tables based on
source data synchronizations,</p>
</li><li>
<p>Insert multiple rows of data into a single target table
based on one change in a source table,</p>
</li><li>
<p>Apply a Bean Shell script to achieve a custom transform
when loading into the target database.</p>
</li></ul></div>

<p>These transformations can take place either on the target
or on the source, and as data is either being extracted or loaded. In
either case, the transformation is initiated due to existence of a
source synchronization trigger. The source trigger creates the
synchronization data, while the transformation configuration decides
what to do with the synchronization data as it is either being extracted
from the source or loaded into the target. You have the flexibility of
defining different transformation behavior depending on whether the
source change that triggered the synchronization was an Insert, Update,
or Delete. In the case of Delete, you even have options on what exactly
to do on the target side, be it a delete of a row, setting columns to
specific values, or absolutely nothing at all.</p>

<p>A few key concepts are important to keep in mind to
understand how SymmetricDS performs transformations. The first concept
is that of the "source operation" or "source DML type", which is the
type of operation that occurred to generate the synchronization data in
the first place (i.e., an insert, a delete, or an update). Your
transformations can be configured to act differently based on the source
DML type, if desired. When transforming, by default the DML action taken
on the target matches that of the action taken on the row in the source
(although this behavior can be altered through configuration if needed).
If the source DML type is an Insert, for example, the resulting
transformation DML(s) will be Insert(s).</p>

<p>Another important concept is the way in which transforms
are applied. Each source operation may map to one or more transforms and
result in one or more operations on the target tables. Each of these
target operations are performed as independent operations in sequence
and must be "complete" from a SQL perspective. In other words, you must
define columns for the transformation that are sufficient to fill in any
primary key or other required data in the target table if the source
operation was an Insert, for example.</p>

<p>Finally, please note that the transformation engine relies
on a source trigger / router existing to supply the source data for the
transformation. The transform configuration will never be used if the
source table and target node group does not have a defined trigger /
router combination for that source table and target node group.</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="transform-data-tables"></a>4.8.1.&nbsp;Transform Configuration Tables</h3></div></div></div>


<p>
SymmetricDS stores its transformation configuration in two configuration
tables,
<a href="data-model.html#table_transform_table" title="A.36.&nbsp;TRANSFORM_TABLE">TRANSFORM_TABLE</a>
and
<a href="data-model.html#table_transform_column" title="A.37.&nbsp;TRANSFORM_COLUMN">TRANSFORM_COLUMN</a>
. Defining a transformation involves configuration in both tables, with
the first table defining which source and destination tables are
involved, and the second defining the columns involved in the
transformation and the behavior of the data for those columns. We will
explain the various options available in both tables and the various
pre-defined transformation types.

</p>

<p>
To define a transformation, you will first define the source table and
target table that applies to a particular transformation. The source and
target tables, along with a unique identifier (the transform_id column)
are defined in
<a href="data-model.html#table_transform_table" title="A.36.&nbsp;TRANSFORM_TABLE">TRANSFORM_TABLE</a>
. In addition, you will specify the source_node_group_id and
target_node_group_id to which the transform will apply, along with
whether the transform should occur on the Extract step or the Load step
(transform_point). All of these values are required.
</p>

<p>
Three additional configuration settings are also defined at the
source-target table level: the order of the transformations, the
behavior when deleting, and whether an update should always be attempted
first. More specifically,
</p><div class="itemizedlist"><ul type="disc"><li>transform_order: For a single source operation that
is mapped to a transformation, there could be more than one target
operation that takes place. You may control the order in which the
target operations are applied through a configuration parameter defined
for each source-target table combination. This might be important, for
example, if the foreign key relationships on the target tables require
you to execute the transformations in a particular order.</li><li>
column_policy: Indicates whether unspecified columns are passed thru or
if all columns must be explicitly defined. The options include:
<div class="itemizedlist"><ul type="circle"><li>SPECIFIED - Indicates that only the transform
columns that are defined will be the ones that end up as part of the
transformation.</li><li>IMPLIED - Indicates that if not specified, then
columns from the source are passed through to the target. This is useful
if you just want to map a table from one name to anther or from one
schema to another. It is also useful if you want to transform a table,
but also want to pass it through. You would define an implied transform
from the source to the target and would not have to configure each
column.</li></ul></div>
</li><li>
delete_action: When a source operation of Delete takes place, there are
three possible ways to handle the transformation at the target. The
options include:
<div class="itemizedlist"><ul type="circle"><li>NONE - The delete results in no target changes.</li><li>DEL_ROW - The delete results in a delete of the row
as specified by the pk columns defined in the transformation
configuration.</li><li>UPDATE_COL - The delete results in an Update
operation on the target which updates the specific rows and columns
based on the defined transformation.</li></ul></div>
</li><li>
update_first: This option overrides the default behavior for an Insert
operation. Instead of attempting the Insert first, SymmetricDS will
always perform an Update first and then fall back to an Insert if that
fails. Note that, by default, fall back logic
<span class="emphasis"><em>always</em></span>
applies for Insert and Updates. Here, all you a specifying is whether to
always do an Update first, which can have performance benefits under
certain situations you may run into.
</li></ul></div><p>
</p>

<p>
For each transformation defined in
<a href="data-model.html#table_transform_table" title="A.36.&nbsp;TRANSFORM_TABLE">TRANSFORM_TABLE</a>
, the columns to be transformed (and how they are transformed) are
defined in
<a href="data-model.html#table_transform_column" title="A.37.&nbsp;TRANSFORM_COLUMN">TRANSFORM_COLUMN</a>
. This column-level table typically has several rows for each
transformation id, each of which defines the source column name, the
target column name, as well as the following details:
</p><div class="itemizedlist"><ul type="disc"><li>include_on: Defines whether this entry applies to
source operations of Insert (I), Update (U), or Delete (D), or any
source operation.</li><li>pk: Indicates that this mapping is used to define
the "primary key" for identifying the target row(s) (which may or may
not be the true primary key of the target table). This is used to define
the "where" clause when an Update or Delete on the target is occurring.
At least one row marked as a pk should be present for each transform_id.</li><li>transform_type, transform_expression: Specifies how
the data is modified, if at all. The available transform types are
discussed below, and the default is 'copy', which just copies the data
from source to target.</li><li>transform_order: In the event there are more than
one columns to transform, this defines the relative order in which the
transformations are applied.</li></ul></div><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="transform-data-types"></a>4.8.2.&nbsp;Transformation Types</h3></div></div></div>


<p>
There are several pre-defined transform types available in SymmetricDS.
Additional ones can be defined by creating and configuring an extension
point which implements the
<code class="code">IColumnTransform</code>
interface. The pre-defined transform types include the following (the
transform_type entry is shown in parentheses):
</p><div class="itemizedlist"><ul type="disc"><li>Copy Column Transform ('copy'): This transformation
type copies the source column value to the target column. This is the
default behavior.</li><li>Remove Column Transform ('remove'): This
transformation type removes the source column. This transform type is
only valid for a table transformation type of 'IMPLIED' where all the
columns from the source are automatically copied to the target.</li><li>Constant Transform ('const'): This transformation
type allows you to map a constant value to the given target column. The
constant itself is placed in transform_expression.</li><li>
Variable Transform ('variable'): This transformation type allows you to
map a built-in dynamic variable to the given target column. The variable
name is placed in transform_expression. The following variables are
available:
<code class="code">system_date</code>
is the current system date,
<code class="code">system_timestamp</code>
is the current system date and time,
<code class="code">source_node_id</code>
is the node id of the source,
<code class="code">target_node_id</code>
is the node id of the target,
<code class="code">null</code>
is a null value, and <code class="code">old_column_value</code> is the column's old value prior to the DML operation.
</li><li>Additive Transform ('additive'): This
transformation type is used for numeric data. It computes the change
between the old and new values on the source and then adds the change to
the existing value in the target column. That is, target = target +
multiplier (source_new - source_old), where multiplier is a constant
found in the transform_expression (default is 1 if not specified). For
example, if the source column changed from a 2 to a 4, the target column
is currently 10, and the multiplier is 3, the effect of the transform
will be to change the target column to a value of 16 ( 10+3*(4-2) =&gt;
16 ). Note that, in the case of deletes, the new column value is
considered 0 for the purposes of the calculation.</li><li>
Substring Transform ('substr'): This transformation computes a substring
of the source column data and uses the substring as the target column
value. The transform_expression can be a single integer (
<code class="code">n</code>
, the beginning index), or a pair of comma-separated integers (
<code class="code">n,m</code>
- the beginning and ending index). The transform behaves as the Java
substring function would using the specified values in
transform_expression.
</li><li>Multiplier Transform ('multiply'): This
transformation allows for the creation of multiple rows in the target
table based on the transform_expression. This transform type can only be
used on a primary key column. The transform_expression is a SQL
statement that returns the list to be used to create the multiple
targets.</li><li>Lookup Transform ('lookup'): This transformation
determines the target column value by using a query, contained in
transform_expression to lookup the value in another table. The query
must return a single row, and the first column of the query is used as
the value. Your query references source column names by prefixing with a
colon (e.g., :MY_COLUMN).</li><li>
Shell Script Transform ('bsh'): This transformation allows you to
provide a Bean Shell script in transform_expression and executes the
script at the time of transformation. Some variables are provided to the
script:
<code class="code">COLUMN_NAME</code>
is a variable for a source column in the row, where the variable name is
the column name in uppercase;
<code class="code">currentValue</code>
is the value of the current source column;
<code class="code">oldValue</code>
is the old value of the source column for an updated row;
<code class="code">sqlTemplate</code>
is a
<code class="code">org.jumpmind.db.sql.ISqlTemplate</code>
object for querying or updating the database;
<code class="code">channelId</code>
is a reference to the channel on which the transformation is happening;
<code class="code">sourceNode</code>
is a
<code class="code">org.jumpmind.symmetric.model.Node</code>
object that represents the node from where the data came;
<code class="code">targetNode</code>
is a
<code class="code">org.jumpmind.symmetric.model.Node</code>
object that represents the node where the data is being loaded.
</li><li>Identity Transform ('identity'): This
transformation allows you to insert into an identity column by computing
a new identity, not copying the actual identity value from the source.
</li><li>
Mathematical Transform ('math'): This transformation allows you to 
perform mathematical equations in the transform expression. Some 
variables are provided to the script:
<code class="code">#{COLUMN_NAME}</code>
is a variable for a source column in the row, where the variable name
is the column name in uppercase;
<code class="code">#{currentValue}</code>
is the value of the current source column;
<code class="code">#{oldValue}</code>
is the old value of the source column for an updated row.
</li><li>
Copy If Changed Transform ('copyIfChanged'):  This transformation will copy the value to the target column if the source value has changed.  More
specifically, the copy will occur if the the old value of the source does not equal the new value.  If the old and new are, in fact, equal, then either
the column will be ignored or the row will be ignored, based on the setting of the transform expression.  If the transform expression is euqal
to the string 'IgnoreColumn', the column will be ignored; otherwise, the row will be ignored.
</li><li>
Value Map Transform ('valueMap'):  This transformation allows for simple value substitutions through use of the transform expression.
The transform expresion should consist of a space separated list of value pairs of the format sourceValue=TargetValue.  The column value is used to 
locate the correct sourceValue, and the transform will change the value into the corresponding targetValue.  A sourceValue of * can be used to
represent a default target value in the event that the sourceValue is not found.  Otherwise, if no default value is found,
the result will be null.  For example, consider the following transform expression:  s1=t1 s2=t2 s3=t3 *=t4.  A source value of
s1 will be transformed to t1, s2 to t2, s3 to t3, s4 to t4, s5 to t4, null to t4, etc.
</li></ul></div><p>
</p>
</div>


</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="data-load-filter"></a>4.9.&nbsp;Data Load Filters</h2></div></div></div>


<p>
New as of SymmetricDS 3.1, SymmetricDS is now capable of taking actions
upon the load of certain data via configurable load filters. This new
configurable option is in additon to the already existing option of
writing a class that implements
<a href="advanced-topics.html#extensions-data-loader-filter" title="5.10.2.&nbsp;IDatabaseWriterFilter">IDatabaseWriterFilter</a>
. A configurable load filter watches for specific data that is being
loaded and then takes action based on the load of that data.
</p>

<p>Specifying which data to action is done by specifying a
souce and target node group (data extracted from this node group, and
loaded into that node group), and a target catalog, schema and table
name. You can decide to take action on rows that are inserted, updated
and/or deleted, and can also further delineate which rows of the target
table to take action on by specifying additional criteria in the bean
shell script that is executed in response to the loaded data. As an
example, old and new values for the row of data being loaded are
available in the bean shell script, so you can action rows with a
certain column value in old or new data.</p>

<p>The action taken is based on a bean shell script that you
can provide as part of the configuration. Actions can be taken at
different points in the load process including before write, after
write, at batch complete, at batch commit and/or at batch rollback.</p>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="data-load-filter-config"></a>4.9.1.&nbsp;Load Filter Configuration Table</h3></div></div></div>


<p>
SymmetricDS stores its load filter configuration in a single table
called
<a href="data-model.html#table_load_filter" title="A.15.&nbsp;LOAD_FILTER">LOAD_FILTER</a>
. The load filter table allows you to specify the following:
</p><div class="itemizedlist"><ul type="disc"><li>Load Filter Type ('load_filter_type'): The type of
load filter. Today only Bean Shell is supported ('BSH'), but SQL scripts
may be added in a future release.</li><li>Source Node Group ('source_node_group_id'): The
source node group for which you would like to watch for changes.</li><li>Target Node Group ('target_node_group_id'): The
target node group for which you would like to watch for changes. The
source and target not groups are used together to identify the node
group link for which you would like to watch for changes (i.e. When the
Server node group sends data to a Client node group).</li><li>Target Catalog ('target_catalog_name'): The name of
the target catalog for which you would like to watch for changes.</li><li>Target Schema ('target_schema_name'): The name of
the target schema for which you would like to watch for changes.</li><li>Target Table ('target_table_name'): The name of the
target table for which you would like to watch for changes. The target
catalog, target schema and target table name are used together to fully
qualify the table for which you would like to watch for changes.</li><li>Filter on Update ('filter_on_update'): Determines
whether the load filter takes action (executes) on a database update
statement.</li><li>Filter on Insert ('filter_on_insert'): Determines
whether the load filter takes action (executes) on a database insert
statement.</li><li>Filter on Delete ('filter_on_delete'): Determines
whether the load filter takes action (executes) on a database delete
statement.</li><li>Before Write Script ('before_write_script'): The
script to execute before the database write occurs.</li><li>After Write Script ('after_write_script'): The
script to execute after the database write occurs.</li><li>Batch Complete Script ('batch_complete_script'):
The script to execute after the entire batch completes.</li><li>Batch Commit Script ('batch_commit_script'): The
script to execute after the entire batch is committed.</li><li>Batch Rollback Script ('batch_rollback_script'):
The script to execute if the batch rolls back.</li><li>Handle Error Script ('handle_error_script'): A
script to execute if data cannot be processed.</li><li>Load Filter Order ('load_filter_order'): The order
in which load filters should execute if there are multiple scripts
pertaining to the same source and target data.</li></ul></div><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="data-load-filter-variables"></a>4.9.2.&nbsp;Variables available to Data Load Filters</h3></div></div></div>


<p>
As part of the bean shell load filters, SymmetricDS provides certain
variables for use in the bean shell script. Those variables include:
</p><div class="itemizedlist"><ul type="disc"><li>Symmetric Engine ('ENGINE'): The Symmetric engine
object.</li><li>Source Values ('&lt;COLUMN_NAME&gt;'): The source
values for the row being inserted, updated or deleted.</li><li>Old Values ('OLD_&lt;COLUMN_NAME&gt;'): The old
values for the row being inserted, updated or deleted.</li><li>Data Context ('CONTEXT'): The data context object
for the data being inserted, updated or deleted. .</li><li>Table Data ('TABLE'): The table object for the
table being inserted, updated or deleted.</li></ul></div><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="data-load-filter-examples"></a>4.9.3.&nbsp;Data Load Filter Example</h3></div></div></div>


<p>
The following is an example of a load filter that watches a table named
TABLE_TO_WATCH being loaded from the Server Node Group to the Client
Node Group for inserts or updates, and performs an initial load on a
table named "TABLE_TO_RELOAD" for KEY_FIELD on the reload table equal to
a column named KEY_FIELD on the TABLE_TO_WATCH table.
</p><pre class="programlisting"> insert into sym_load_filter
(LOAD_FILTER_ID, LOAD_FILTER_TYPE, SOURCE_NODE_GROUP_ID,
TARGET_NODE_GROUP_ID, TARGET_CATALOG_NAME, TARGET_SCHEMA_NAME,
TARGET_TABLE_NAME, FILTER_ON_UPDATE, FILTER_ON_INSERT, FILTER_ON_DELETE,
BEFORE_WRITE_SCRIPT, AFTER_WRITE_SCRIPT, BATCH_COMPLETE_SCRIPT,
BATCH_COMMIT_SCRIPT, BATCH_ROLLBACK_SCRIPT, HANDLE_ERROR_SCRIPT,
CREATE_TIME, LAST_UPDATE_BY, LAST_UPDATE_TIME, LOAD_FILTER_ORDER,
FAIL_ON_ERROR) values
('TABLE_TO_RELOAD','BSH','Client','Server',NULL,NULL,
'TABLE_TO_WATCH',1,1,0,null,
'engine.getDataService().reloadTable(context.getBatch().getSourceNodeId(),
table.getCatalog(), table.getSchema(), "TABLE_TO_RELOAD","KEY_FIELD=''"
+ KEY_FIELD + "''");'
,null,null,null,null,sysdate,'userid',sysdate,1,1); </pre><p>
</p>
</div>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="conflicts"></a>4.10.&nbsp;Conflict Detection and Resolution</h2></div></div></div>
    
    <p> Conflict detection and resolution is new as of SymmetricDS 3.0. Conflict detection is the act of determining if an
        insert, update or delete is in "conflict" due to the target data row not being consistent with the data at the source
        prior to the insert/update/delete. Conflict resolution is the act of figuring out what to do when a conflict is
        detected.
    </p>
    <p>
        Conflict detection and resolution strategies are configured in the
        <a href="data-model.html#table_conflict" title="A.2.&nbsp;CONFLICT">CONFLICT</a>
        table. They are configured at minimum for a specific
        <a href="data-model.html#table_node_group_link" title="A.22.&nbsp;NODE_GROUP_LINK">NODE_GROUP_LINK</a>
        . The configuration can also be specific to a
        <a href="data-model.html#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
        and/or table.
    </p>
    <p>
        Conflict detection is configured in the
        <code class="literal">detect_type</code>
        and
        <code class="literal">detect_expression</code>
        columns of
        <a href="data-model.html#table_conflict" title="A.2.&nbsp;CONFLICT">CONFLICT</a>
        . The value for
        <code class="literal">detect_expression</code>
        depends on the
        <code class="literal">detect_type</code>
        . Conflicts are detected while data is being loaded into a target system.
        </p><div class="variablelist"><dl><dt><span class="term">
                    <span><strong class="command">USE_PK_DATA</strong></span>
                </span></dt><dd>
                    <p>Indicates that only the primary key is used to detect a conflict. If a row exists with the same
                        primary key, then no conflict is detected during an update or a delete. Updates and deletes rows are
                        resolved using only the primary key columns. If a row already exists during an insert then a conflict
                        has been detected.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">USE_OLD_DATA</strong></span>
                </span></dt><dd>
                    <p>Indicates that all of the old data values are used to detect a conflict. Old data is the data
                        values of the row on the source system prior to the change. If a row exists with the same old values
                        on the target system as they were on the source system, then no conflict is detected during an update
                        or a delete. If a row already exists during an insert then a conflict has been detected.
                    </p>
                    <p>Note that some platforms do not support comparisons of binary columns. Conflicts in binary column
                    values will not be detected on the following platforms: DB2, DERBY, ORACLE, and SQLSERVER.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">USE_CHANGED_DATA</strong></span>
                </span></dt><dd>
                    <p>Indicates that the primary key plus any data that has changed on the source system will be used to
                        detect a conflict. If a row exists with the same old values on the target system as they were on the
                        source system for the columns that have changed on the source system, then no conflict is detected
                        during an update or a delete. If a row already exists during an insert then a conflict has been
                        detected.
                    </p>
                    <p>Note that some platforms do not support comparisons of binary columns. Conflicts in binary column
                    values will not be detected on the following platforms: DB2, DERBY, ORACLE, and SQLSERVER.
                    </p>
                    <p>The detect_expression can be used to exclude certain column names from being used.  In order to 
                    exclude column1 and column2, the expression would
                    be: <code class="literal">excluded_column_names=column1,column2</code> 
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">USE_TIMESTAMP</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that the primary key plus a timestamp column (as configured in
                        <code class="literal">detect_expression</code>
                        ) will indicate whether a conflict has occurred. If the target timestamp column is not equal to the
                        old source timestamp column, then a conflict has been detected. If a row already exists during an
                        insert then a conflict has been detected.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">USE_VERSION</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that the primary key plus a version column (as configured in
                        <code class="literal">detect_expression</code>
                        ) will indicate whether a conflict has occurred. If the target version column is not equal to the old
                        source version column, then a conflict has been detected. If a row already exists during an insert
                        then a conflict has been detected.
                    </p>
                </dd></dl></div><p>
    </p>
          <div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3>
            <p>Be aware that conflict detection will <span class="emphasis"><em>not</em></span> detect changes to binary columns in
            the case where <code class="literal">use_stream_lobs</code> is true in the trigger for the table.  In addition, some
            databases do not allow comparisons of binary columns whether <code class="literal">use_stream_lobs</code> is true or not. 
           </p>
      </div>
      
    <p>
        The choice of how to resolve a detected conflict is configured via the <code class="literal">resolve_type</code> column. Depending on the setting, two additional boolean settings
        may also be configured, namely <code class="literal">resolve_row_only</code> and <code class="literal">resolve_changes_only</code>, as discussed in the resolution settings below.
        </p><div class="variablelist"><dl><dt><span class="term">
                    <span><strong class="command">FALLBACK</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that when a conflict is detected the system should automatically apply the changes anyways.
                        If the source operation was an insert, then an update will be attempted. If the source operation was
                        an update and the row does not exist, then an insert will be attempted. If the source operation was a
                        delete and the row does not exist, then the delete will be ignored. The
                        <code class="literal">resolve_changes_only</code>
                        flag controls whether all columns will be updated or only columns that have changed will be updated
                        during a fallback operation.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">IGNORE</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that when a conflict is detected the system should automatically ignore the incoming
                        change. The
                        <code class="literal">resolve_row_only</code>
                        column controls whether the entire batch should be ignore or just the row in conflict.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command"><a name="conflict-resolution-manual"></a>MANUAL</strong></span>
                </span></dt><dd>
                    <p>
                        Indicates that when a conflict is detected the batch will remain in error until manual intervention
                        occurs. A row in error is inserted into the
                        <a href="data-model.html#table_incoming_error" title="A.14.&nbsp;INCOMING_ERROR">INCOMING_ERROR</a>
                        table.  The conflict detection id that detected the conflict is recorded (i.e., the <code class="literal">conflict_id</code> value from 
                          <a href="data-model.html#table_conflict" title="A.2.&nbsp;CONFLICT">CONFLICT</a>), along with the old data, new data, and the "current data" 
                          (by current data, we mean the unexpected data at the target which doesn't match the old data as expected)
                            in columns <code class="literal">old_data, new_data,</code> and <code class="literal">cur_data</code>. 
                        In order to resolve, the
                        <code class="literal">resolve_data</code>
                        column can be manually filled out which will be used on the next load attempt instead of the original
                        source data. The
                        <code class="literal">resolve_ignore</code>
                        flag can also be used to indicate that the row should be ignored on the next load attempt.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">NEWER_WINS</strong></span>
                </span></dt><dd>
                    <p>Indicates that when a conflict is detected by USE_TIMESTAMP or USE_VERSION that the either the
                        source or the target will win based on the which side has the newer timestamp or higher version
                        number.  The
                        <code class="literal">resolve_row_only</code>
                        column controls whether the entire batch should be ignore or just the row in conflict.
                    </p>
                </dd></dl></div><p>
    </p>
     <p>
        For each configured conflict, you also have the ability to control if and how much "resolved" data is sent back to the node who's data change is in conflict.  This "ping back" behavior
        is specified by the setting of the <code class="literal">ping_back</code>
        column and can be one of the following values:
        </p><div class="variablelist"><dl><dt><span class="term">
                    <span><strong class="command">OFF</strong></span>
                </span></dt><dd>
                    <p>
                       No data is sent back to the originating node, even if the resolved data doesn't match the data the node sent.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">SINGLE_ROW</strong></span>
                </span></dt><dd>
                    <p>
                       The resolved data of the single row in the batch that caused the conflict is sent back to the originating node.
                    </p>
                </dd><dt><span class="term">
                    <span><strong class="command">REMAINING_ROWS.</strong></span>
                </span></dt><dd>
                    <p>
                       The resolved data of the single row in the batch in conflict, along with the entire remainder of the batch, is sent back to the originating node.
                    </p>
                </dd></dl></div><p>
        </p>
           
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="file-sync"></a>4.11.&nbsp;File Synchronization</h2></div></div></div>
           

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="filesync-overview"></a>4.11.1.&nbsp;Overview</h3></div></div></div>


<p> SymmetricDS not only supports the synchronization of
database tables, but it also supports the synchronization of files and folders 
from one node to another. </p>
<p>
File synchronization features include:

</p><div class="itemizedlist"><ul type="disc"><li> Monitoring one or more file system directory locations for file and folder changes </li><li> Support synchronizing a different target directory than the source directory</li><li> Use of wild card expressions to &#8220;include&#8221; or
&#8220;exclude&#8221; files </li><li> Choice of whether to recurse into subfolders
of monitored directories </li><li> Use of existing SymmetricDS routers to subset
target nodes based on file and directory metadata </li><li> Ability to specify if files will be synchronized on
creation, or deletion, and/or modification </li><li> Ability to specify the frequency with which file systems are
monitored for changes </li><li> Ability to extend file synchronization through
scripts that run before or after a file is copied to its source location
</li><li> Support for bidirectional file synchronization </li></ul></div><p>
</p>
<p> Like database synchronization, file synchronization is
configured in a series of database tables. The configuration was
designed to be similar to database synchronization in order to maintain
consistency and to give database synchronization users a sense of
familiarity. </p>
<p>For database synchronization, SymmetricDS uses
<a href="data-model.html#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a> to configure which tables will capture data for synchronization
and <a href="data-model.html#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a> to designate which nodes will be the source of data changes
and which nodes will receive the data changes.
<a href="data-model.html#table_trigger_router" title="A.40.&nbsp;TRIGGER_ROUTER">TRIGGER_ROUTER</a> links triggers to routers. </p>
<p> Likewise, for file synchronization, SymmetricDS uses <a href="data-model.html#table_file_trigger" title="A.9.&nbsp;FILE_TRIGGER">FILE_TRIGGER</a> to designate which base directories will be monitored.
Each entry in <a href="data-model.html#table_file_trigger" title="A.9.&nbsp;FILE_TRIGGER">FILE_TRIGGER</a> designates one base directory to monitor for changes on
the source system. The columns on <a href="data-model.html#table_file_trigger" title="A.9.&nbsp;FILE_TRIGGER">FILE_TRIGGER</a> provide additional
settings for choosing specific files in the base directory that will be monitored, and whether to recurse into subdirectories, etc.  File triggers are linked to routers by
<a href="data-model.html#table_file_trigger_router" title="A.10.&nbsp;FILE_TRIGGER_ROUTER">FILE_TRIGGER_ROUTER</a>. The file trigger router not only links the source
and the target node groups, but it also optionally provides the ability to
override the base directory name at the target. <a href="data-model.html#table_file_trigger_router" title="A.10.&nbsp;FILE_TRIGGER_ROUTER">FILE_TRIGGER_ROUTER</a> also
provides a flag that indicates if the target node should be seeded with
the files from the source node during SymmetricDS's initial load
process. </p>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="filesync-operation"></a>4.11.2.&nbsp;Operation</h3></div></div></div>

<p> Not only is file synchronization configured similar to database synchronization, but it also operates in a very similar way. The file system is monitored for changes via a
background job that tracks the file system changes
(this parallels the use of triggers to monitor for changes when synchronizing database changes).
When a change is detected it is written to the <a href="data-model.html#table_file_snapshot" title="A.8.&nbsp;FILE_SNAPSHOT">FILE_SNAPSHOT</a>
table. The file snapshot table represents the most recent known state of the
monitored files. The file snapshot table has a SymmetricDS database trigger automatically installed
on it so that when it is updated the changes are captured by SymmetricDS on an internal
channel named <code class="literal">filesync</code>. </p>
<p> The changes to <a href="data-model.html#table_file_snapshot" title="A.8.&nbsp;FILE_SNAPSHOT">FILE_SNAPSHOT</a> are then routed and batched by a file-synchronization-specific router
that delegates to the configured router
based on the <a href="data-model.html#table_file_trigger_router" title="A.10.&nbsp;FILE_TRIGGER_ROUTER">FILE_TRIGGER_ROUTER</a> configuration. The
 file sync router can
make routing decisions based on the column data of the snapshot table, columns which contain attributes of the file like the name, path,
size, and last modified time. Both old and new file snapshot data are also
available. The router can, for example, parse the path or name of the
file and use it as the node id to route to. </p>
<p> Batches of file snapshot changes are stored on the
<code class="literal">filesync</code> channel in <a href="data-model.html#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>. The existing SymmetricDS pull and
push jobs ignore the <code class="literal">filesync</code> channel. Instead, they are processed by
file-synchronization-specific push and pull jobs. </p>
<p> When transferring data, the file sync push and pull jobs build a zip
file dynamically based on the batched snapshot data. The
zip file contains a directory per batch. The directory name is the
<code class="literal">batch_id</code>. A <code class="literal">sync.bsh</code> Bean Shell
script is generated and placed in the root of each batch directory. The Bean Shell script contains the commands to copy
or delete files at their file destination from an extracted zip in the staging directory on the
target node. The zip file is downloaded in the
case of a pull, or, in the case of a push, is uploaded as an HTTP multi-part attachment.
Outgoing zip files are written and transferred from the
outgoing staging directory. Incoming zip files are staged in the
<code class="literal">filesync_incoming</code> staging directory by source node id. The
<code class="literal">filesync_incoming/{node_id}</code> staging directory is cleared out before each
subsequent delivery of files. </p>
<p> The acknowledgement of a batch happens the same way it is acknowledged in database synchronization. The client responds with an acknowledgement as part of the response
during a file push or pull. </p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="filesync-beanshell"></a>4.11.3.&nbsp;File Sync Bean Shell Scripts</h3></div></div></div>

<p> There are two types of Bean Shell scripts that can be
leveraged to customize file synchronization behavior: <code class="literal">before_copy_script</code>
and <code class="literal">after_copy_script</code>. </p>
<p>
Each of these scripts have access to local variables that can be read or
set to affect the behavior of copying files.

</p><div class="variablelist"><dl><dt><span class="term">
<span><strong class="command">targetBaseDir</strong></span>
</span></dt><dd>
<p> The preset base directory as configured in <a href="data-model.html#table_file_trigger" title="A.9.&nbsp;FILE_TRIGGER">FILE_TRIGGER</a> or
overwritten in <a href="data-model.html#table_file_trigger_router" title="A.10.&nbsp;FILE_TRIGGER_ROUTER">FILE_TRIGGER_ROUTER</a>. This variable can be set by the
<code class="literal">before_copy_script</code> to set a different target directory. </p>
</dd><dt><span class="term">
<span><strong class="command">targetFileName</strong></span>
</span></dt><dd>
<p> The name of the file that is being synchronized. This variable can be overwritten by the
<code class="literal">before_copy_script</code> to rename a file at the target. </p>
</dd><dt><span class="term">
<span><strong class="command">targetRelativeDir</strong></span>
</span></dt><dd>
<p> The name of a directory relative to the target base directory to which the target file will be copied.  The 
default value of this variable is the relative directory of the source.  For example, if the source base directory is 
<code class="literal">/src</code> and the target base directory is <code class="literal">/tgt</code> and the file <code class="literal">/src/subfolder/1.txt</code>
is changed, then the default targetRelativeDir will be <code class="literal">subfolder</code>.
This variable can be overwritten by the
<code class="literal">before_copy_script</code> to change the relative directory at the target. In the above example, if the variable is
set to blank using the following script, then the target file will be copied to <code class="literal">/tgt/1.txt</code>.
</p><pre class="programlisting">
targetRelativeDir = "";
</pre><p>
</p>
</dd><dt><span class="term">
<span><strong class="command">processFile</strong></span>
</span></dt><dd>
<p>This is a variable that is set to true by default. A custom
<code class="literal">before_copy_script</code> may process the file itself and set this variable to
false to indicate that the file should NOT be copied to its target
location. </p>
</dd><dt><span class="term">
<span><strong class="command">sourceFileName</strong></span>
</span></dt><dd>
<p>This is the name of the file.</p>
</dd><dt><span class="term">
<span><strong class="command">sourceFilePath</strong></span>
</span></dt><dd>
<p>This is the path where the file can be found relative to
the batch directory.</p>
</dd><dt><span class="term">
<span><strong class="command">batchDir</strong></span>
</span></dt><dd>
<p>This is the staging directory where the batch has been
extracted. The batchDir + sourceFilePath + sourceFileName can be used to
locate the extracted file. </p>
</dd><dt><span class="term">
<span><strong class="command">engine</strong></span>
</span></dt><dd>
<p>This is the bound instance of the ISymmetricEngine that is
processing a file. It gives access to all of the APIs available in
SymmetricDS. </p>
</dd><dt><span class="term">
<span><strong class="command">sourceNodeId </strong></span>
</span></dt><dd>
<p>This is a bound variable that represents the nodeId that is
the source of the file.</p>
</dd><dt><span class="term">
<span><strong class="command">log</strong></span>
</span></dt><dd>
<p>This is the bound instance of an <code class="literal">org.slf4j.Logger</code> that can
be used to log to the SymmetricDS log file.</p>
</dd></dl></div><p>

</p>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="filesync-examples"></a>4.11.4.&nbsp;File Sync Examples</h3></div></div></div>


<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="filesync-example-1"></a>4.11.4.1.&nbsp;Sync Text Files From Server To Client</h4></div></div></div>

<p>
The following example is for a configuration with client and server node
groups. Creation, modification, and deletion of files with the extension
of <code class="literal">txt</code> will be captured recursively
in the <code class="literal">/filesync/server/all</code>
directory. A before copy script will set the targetBaseDir to
<code class="literal">/filesync/clients/{externalId}</code>.

</p><pre class="programlisting">INSERT INTO sym_file_trigger
  (trigger_id,base_dir,recurse,includes_files,excludes_files,sync_on_create,
   sync_on_modified,sync_on_delete,before_copy_script,after_copy_script,
   create_time,last_update_by,last_update_time)
VALUES ('sync_directory','/filesync/server/all',1,'*.txt',null,1,1,1,
  'targetBaseDir = "/filesync/clients/" +
  engine.getParameterService().getExternalId();',null,current_timestamp,'example',
  current_timestamp);

INSERT INTO sym_file_trigger_router
 (trigger_id,router_id,enabled,initial_load_enabled,target_base_dir,
  conflict_strategy,create_time,last_update_by,last_update_time)
VALUES
  ('sync_directory','server_2_client',1,1,'','SOURCE_WINS',current_timestamp,
  'example',current_timestamp);

INSERT INTO sym_router
  (router_id,target_catalog_name,target_schema_name,target_table_name,
  source_node_group_id,target_node_group_id,
  router_type,router_expression,sync_on_update,sync_on_insert,sync_on_delete,
  create_time,last_update_by,last_update_time)
VALUES
  ('server_2_client',null,null,null,'server','client','default',null,1,1,1,
   current_timestamp,'example',current_timestamp);
</pre><p>
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="filesync-example-2"></a>4.11.4.2.&nbsp;Route changes to a specific node based on a directory
name</h4></div></div></div>

<p>
The following example is also for a configuration with client and server
node groups. This example monitors the <code class="literal">/filesync/server/nodes</code> directory.
It expects the directory to contain subdirectories that are named by the node_ids
in the client group. Any files put directly into a folder with the name
of the node will be routed to that node.
</p>
<p>
Note that the router is a <a href="configuration.html#configuration-column-match-router" title="4.6.2.2.&nbsp;Column Match Router">Section&nbsp;4.6.2.2, &#8220;Column Match Router&#8221;</a> that is matching the client node_id with the value of the RELATIVE_DIR column in
<a href="data-model.html#table_file_snapshot" title="A.8.&nbsp;FILE_SNAPSHOT">FILE_SNAPSHOT</a>.  Because the router is looking for an exact match any files in subdirectories would result in a path
of node_id/subdir which would not match.
</p><pre class="programlisting">

INSERT INTO sym_file_trigger
  (trigger_id,base_dir,recurse,includes_files,excludes_files,sync_on_create,
  sync_on_modified,sync_on_delete,before_copy_script,after_copy_script,create_time,
  last_update_by,last_update_time)
VALUES
  ('node_specific','/filesync/server/nodes',1,null,null,1,1,1,'',null,
  current_timestamp,'example',current_timestamp);

INSERT INTO sym_file_trigger_router
  (trigger_id,router_id,enabled,initial_load_enabled,target_base_dir,
  conflict_strategy,create_time,last_update_by,last_update_time)
VALUES
  ('node_specific','router_files_to_node',1,1,'/filesync/clients','SOURCE_WINS',
  current_timestamp,'example',current_timestamp);

INSERT INTO sym_router
  (router_id,target_catalog_name,target_schema_name,target_table_name,
   source_node_group_id,target_node_group_id,router_type,router_expression,
   sync_on_update,sync_on_insert,sync_on_delete,create_time,last_update_by,
   last_update_time)
VALUES
  ('router_files_to_node',null,null,null,'server','client','column',
  'RELATIVE_DIR = :NODE_ID ',1,1,1,current_timestamp,'example', current_timestamp);

</pre><p>
</p>
</div>
</div>



</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="jobs"></a>4.12.&nbsp;Jobs</h2></div></div></div>

<p>
Work done by SymmetricDS is initiated by jobs. Jobs are tasks that are
started and scheduled by a job manager. Jobs are enabled by the
<code class="literal">start.{name}.job</code>
property. Most jobs are enabled by default. The frequency at which a job
runs in controlled by one of two properties:
<code class="literal">job.{name}.period.time.ms</code>
or
<code class="literal">job.{name}.cron</code>
. If a valid cron property exists in the configuration, then it will be
used to schedule the job. Otherwise, the job manager will attempt to use
the period.time.ms property.
</p>
<p>
The frequency of jobs can be configured in either the engines properties
file or in
<a href="data-model.html#table_parameter" title="A.30.&nbsp;PARAMETER">PARAMETER</a>
. When managed in
<a href="data-model.html#table_parameter" title="A.30.&nbsp;PARAMETER">PARAMETER</a>
the frequency properties can be changed in the registration server and
when the updated settings sync to the nodes in the system the job
manager will restart the jobs at the new frequency settings.
</p>
<p>
SymmetricDS utilizes Spring's CRON support, which includes seconds as
the first parameter. This differs from the typical Unix-based
implementation, where the first parameter is usually minutes. For
example,
<code class="literal">*/15 * * * * *</code>
means every 15 seconds, not every 15 minutes. See
<a xmlns:xlink="http://www.w3.org/1999/xlink" href="http://static.springsource.org/spring/docs/3.0.x/javadoc-api/org/springframework/scheduling/support/CronSequenceGenerator.html" target="_top">Spring's
documentation</a>
for more details.
</p>
<p>
Some jobs cannot be run in parallel against a single node. When running
on a cluster these jobs use the
<a href="data-model.html#table_lock" title="A.16.&nbsp;LOCK">LOCK</a>
table to get an exclusive semaphore to run the job. In order to use this
table the
<code class="literal">cluster.lock.enabled</code>
must be set to true.
</p>
<p> The three main jobs in SymmetricDS are the route, push and
pull jobs. The route job decides what captured data changes should be
sent to which nodes. It also decides what captured data changes should
be transported and loaded together in a batch. The push and pull jobs
are responsible for initiating HTTP communication with linked nodes to
push or pull data changes that have been routed. </p>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="routing-job"></a>4.12.1.&nbsp;Route Job</h3></div></div></div>

<p>
After data is captured in the
<a href="data-model.html#table_data" title="A.3.&nbsp;DATA">DATA</a>
table, it is routed to specific nodes in batches by the
<span class="emphasis"><em>Route Job</em></span>
. It is a single background task that inserts into
<a href="data-model.html#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
and
<a href="data-model.html#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
.
</p>
<p>
The job processes each enabled channel, one at a time, collecting a list
of data ids from
<a href="data-model.html#table_data" title="A.3.&nbsp;DATA">DATA</a>
which have not been routed (see
<a href="configuration.html#data-gaps" title="4.12.1.1.&nbsp;Data Gaps">Section&nbsp;4.12.1.1, &#8220;Data Gaps&#8221;</a>
for much more detail about this step), up to a limit specified by the
channel configuration (
<code class="literal">max_data_to_route</code>
, on
<a href="data-model.html#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
). The data is then batched based on the
<code class="literal">batch_algorithm</code>
defined for the channel and as documented in
<a href="configuration.html#configuration-channel" title="4.5.&nbsp;Channel">Section&nbsp;4.5, &#8220;Channel&#8221;</a>
. Note that, for the
<code class="literal">default</code>
and
<code class="literal">transactional</code>
algorithm, there may actually be more than
<code class="literal">max_data_to_route</code>
included depending on the transaction boundaries. The mapping of data to
specific nodes, organized into batches, is then recorded in
<a href="data-model.html#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
with a status of "RT" in each case (representing the fact that the Route
Job is still running). Once the routing algorithms and batching are
completed, the batches are organized with their corresponding data ids
and saved in
<a href="data-model.html#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
. Once
<a href="data-model.html#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
is updated, the rows in
<a href="data-model.html#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
are updated to a status of New "NE".
</p>
<p>
The route job will respect the
<code class="literal">max_batch_size</code>
on
<a href="data-model.html#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
. If the max batch size is reached before the end of a database
tranaction and the batch algorithm is set to something other than
<code class="literal">nontransactional</code>
the batch may exceed the specified max size.
</p>
<p>
The route job delegates to a router defined by the
<code class="literal">router_type</code>
and configured by the
<code class="literal">router_expression</code>
in the
<a href="data-model.html#table_router" title="A.33.&nbsp;ROUTER">ROUTER</a>
table. Each router that has a
<code class="literal">source_node_group_id</code>
that matches the current node's source node group id and is linked to
the
<a href="data-model.html#table_trigger" title="A.38.&nbsp;TRIGGER">TRIGGER</a>
that captured the data gets an opportunity to choose a list of nodes the
data should be sent to. Data can only be routed to nodes that belong to
the router's
<code class="literal">target_node_group_id</code>
.
</p>
<div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="data-gaps"></a>4.12.1.1.&nbsp;Data Gaps</h4></div></div></div>

<p>
On the surface, the first Route Job step of collecting unrouted data ids
seems simple: assign sequential data ids for each data row as it's
inserted and keep track of which data id was last routed and start from
there. The difficulty arises, however, due to the fact that there can be
multiple transactions inserting into
<a href="data-model.html#table_data" title="A.3.&nbsp;DATA">DATA</a>
simultaneously. As such, a given section of rows in the
<a href="data-model.html#table_data" title="A.3.&nbsp;DATA">DATA</a>
table may actually contain "gaps" in the data ids when the Route Job is
executing. Most of these gaps are only temporarily and fill in at some
point after routing and need to be picked up with the next run of the
Route Job. Thus, the Route Job needs to remember to route the filled-in
gaps. Worse yet, some of these gaps are actually permanent and result
from a transaction that is rolled back for some reason. In this case,
the Route Job must continue to watch for the gap to fill in and, at some
point, eventually gives up and assumes the gap is permanent and can be
skipped. All of this must be done in some fashion that guarantees that
gaps are routed when they fill in while also keeping routing as
efficient as possible.
</p>
<p>
SymmetricDS handles the issue of data gaps by making use of a table,
<a href="data-model.html#table_data_gap" title="A.5.&nbsp;DATA_GAP">DATA_GAP</a>
, to record gaps found in the data ids. In fact, this table completely
defines the entire range of data tha can be routed at any point in time.
For a brand new instance of SymmetricDS, this table is empty and
SymmetricDS creates a gap starting from data id of zero and ending with
a very large number (defined by
<code class="literal">routing.largest.gap.size</code>
). At the start of a Route Job, the list of valid gaps (gaps with status
of 'GP') is collected, and each gap is evaluated in turn. If a gap is
sufficiently old (as defined by
<code class="literal">routing.stale.dataid.gap.time.ms</code>
, the gap is marked as skipped (status of 'SK') and will no longer be
evaluated in future Route Jobs (note that the 'last' gap (the one with
the highest starting data id) is never skipped). If not skipped, then
<a href="data-model.html#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
is searched for data ids present in the gap. If one or more data ids is
found in
<a href="data-model.html#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
, then the current gap is marked with a status of OK, and new gap(s) are
created to represent the data ids still missing in the gap's range. This
process is done for all gaps. If the very last gap contained data, a new
gap starting from the highest data id and ending at (highest data id +
<code class="literal">routing.largest.gap.size</code>
) is then created. This process has resulted in an updated list of gaps
which may contain new data to be routed.
</p>
</div>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="push-pull-job"></a>4.12.2.&nbsp;Push and Pull Jobs for Database changes</h3></div></div></div>

<p>
After database-change data is routed, it awaits transport to the target nodes. Transport
can occur when a client node is configured to pull data or when the host
node is configured to push data. These events are controlled by the
<span class="emphasis"><em>push</em></span>
and the
<span class="emphasis"><em>pull jobs</em></span>
. When the
<code class="literal">start.pull.job</code>
SymmetricDS property is set to
<code class="literal">true</code>
, the frequency that data is pulled is controlled by the
<code class="literal">job.pull.period.time.ms</code>
. When the
<code class="literal">start.push.job</code>
SymmetricDS property is set to
<code class="literal">true</code>
, the frequency that data is pushed is controlled by the
<code class="literal">job.push.period.time.ms</code>
.
</p>
<p>
Data is extracted by channel from the source database's
<a href="data-model.html#table_data" title="A.3.&nbsp;DATA">DATA</a>
table at an interval controlled by the
<code class="literal">extract_period_millis</code>
column on the
<a href="data-model.html#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
table. The
<code class="literal">last_extract_time</code>
is always recorded, by channel, on the
<a href="data-model.html#table_node_channel_ctl" title="A.19.&nbsp;NODE_CHANNEL_CTL">NODE_CHANNEL_CTL</a>
table for the host node's id. When the Pull and Push Job run, if the
extract period has not passed according to the last extract time, then
the channel will be skipped for this run. If the
<code class="literal">extract_period_millis</code>
is set to zero, data extraction will happen every time the jobs run.
</p>
<p>
The maximum number of batches to extract per synchronization is
controlled by
<code class="literal">max_batch_to_send</code>
on the
<a href="data-model.html#table_channel" title="A.1.&nbsp;CHANNEL">CHANNEL</a>
table. There is also a setting that controls the max number of bytes to
send in one synchronization. If SymmetricDS has extracted the more than
the number of bytes configured by the
<code class="literal">transport.max.bytes.to.sync</code>
parameter, then it will finish extracting the current batch and finish
synchronization so the client has a chance to process and acknowlege the
"big" batch. This may happen before the configured max number of batches
has been reached.
</p>
<p>
Both the push and pull jobs can be configured to push and pull multiple
nodes in parallel. In order to take advantage of this the
<code class="literal">pull.thread.per.server.count</code>
or
<code class="literal">push.thread.per.server.count</code>
should be adjusted (from their default value of 10) to the number to the
number of concurrent push/pulls you want to occur per period on each
SymmetricDS instance. Push and pull activity is recorded in the
<a href="data-model.html#table_node_communication" title="A.18.&nbsp;NODE_COMMUNICATION">NODE_COMMUNICATION</a>
table. This table is also used to lock push and pull activity across
multiple servers in a cluster.
</p>
<p>
SymmetricDS also provides the ability to configure windows of time when
synchronization is allowed. This is done using the
<a href="data-model.html#table_node_group_channel_wnd" title="A.21.&nbsp;NODE_GROUP_CHANNEL_WND">NODE_GROUP_CHANNEL_WND</a>
table. A list of allowed time windows can be specified for a node group
and a channel. If one or more windows exist, then data will only be
extracted and transported if the time of day falls within the window of
time specified. The configured times are always for the target node's
local time. If the
<code class="literal">start_time</code>
is greater than the
<code class="literal">end_time</code>
, then the window crosses over to the next day.
</p>
<p>
All data loading may be disabled by setting the
<code class="literal">dataloader.enable</code>
property to false. This has the effect of not allowing incoming
synchronizations, while allowing outgoing synchronizations. All data
extractions may be disabled by setting the
<code class="literal">dataextractor.enable</code>
property to false. These properties can be controlled by inserting into
the root server's
<a href="data-model.html#table_parameter" title="A.30.&nbsp;PARAMETER">PARAMETER</a>
table. These properties affect every channel with the exception of the
'config' channel.
</p>
<p> Node communication over HTTP is represented in the
following figure. </p>
<p>
</p><div class="figure"><a name="d4e1605"></a><div class="figure-contents">

<div class="mediaobject"><img src="./images/seq-node-communication.gif" alt="Node Communication"></div>
</div><p class="title"><b>Figure&nbsp;4.1.&nbsp;Node Communication</b></p></div><p><br class="figure-break">
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="file-sync-push-pull"></a>4.12.3.&nbsp;File Sync Push and Pull Jobs</h3></div></div></div>

<p>
The File Sync Push and Pull jobs (introduced in version 3.5) are responsible for synchronizing file changes.
These jobs work with batches on the <code class="literal">filesync</code> channel and create ZIP files of changed files
to be sent and applied on other nodes.
The parameters <code class="literal">job.file.sync.push.period.time.ms</code> and <code class="literal">job.file.sync.pull.period.time.ms</code>
control how often the jobs runs, which default to every 60 seconds.
See also <a href="configuration.html#jobs" title="4.12.&nbsp;Jobs">Section&nbsp;4.12, &#8220;Jobs&#8221;</a> and <a href="configuration.html#filesync-operation" title="4.11.2.&nbsp;Operation">Section&nbsp;4.11.2, &#8220;Operation&#8221;</a>.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="file-sync-tracker-job"></a>4.12.4.&nbsp;File System Tracker Job</h3></div></div></div>

<p>
The File System Tracker job (introduced in version 3.5) is responsible for monitoring and
recording the events of files being created, modified, or deleted.
It records the current state of files to the <a href="data-model.html#table_file_snapshot" title="A.8.&nbsp;FILE_SNAPSHOT">FILE_SNAPSHOT</a> table.
The parameter <code class="literal">job.file.sync.tracker.cron</code> controls how often the job runs,
which defaults to every 5 minutes.
See also <a href="configuration.html#jobs" title="4.12.&nbsp;Jobs">Section&nbsp;4.12, &#8220;Jobs&#8221;</a> and <a href="configuration.html#file-sync" title="4.11.&nbsp;File Synchronization">Section&nbsp;4.11, &#8220;File Synchronization&#8221;</a>.
</p>
</div>

<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="sync-triggers"></a>4.12.5.&nbsp;Sync Triggers Job</h3></div></div></div>

<p>
SymmetricDS examines the current configuration, corresponding database
triggers, and the underlying tables to determine if database triggers
need created or updated. The change activity is recorded on the
<a href="data-model.html#table_trigger_hist" title="A.39.&nbsp;TRIGGER_HIST">TRIGGER_HIST</a>
table with a reason for the change. The following reasons for a change
are possible:

</p><div class="itemizedlist"><ul type="disc"><li>
<p>N - New trigger that has not been created before</p>
</li><li>
<p>S - Schema changes in the table were detected</p>
</li><li>
<p>C - Configuration changes in Trigger</p>
</li><li>
<p>T - Trigger was missing</p>
</li></ul></div><p>

A configuration entry in Trigger without any history in Trigger Hist
results in a new trigger being created (N). The Trigger Hist stores a
hash of the underlying table, so any alteration to the table causes the
trigger to be rebuilt (S). When the
<code class="literal">last_update_time</code>
is changed on the Trigger entry, the configuration change causes the
trigger to be rebuilt (C). If an entry in Trigger Hist is missing the
corresponding database trigger, the trigger is created (T).
</p>
<p>
The process of examining triggers and rebuilding them is automatically
run during startup and each night by the SyncTriggersJob. The user can
also manually run the process at any time by invoking the
<code class="literal">syncTriggers()</code>
method over JMX.
</p>
</div>
<div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="purge-job"></a>4.12.6.&nbsp;Purge Jobs</h3></div></div></div>

<p>
Purging is the act of cleaning up captured data that is no longer needed
in SymmetricDS's runtime tables. Data is purged through delete
statements by the
<span class="emphasis"><em>Purge Job</em></span>
. Only data that has been successfully synchronized will be purged.
Purged tables include:
</p><div class="itemizedlist"><ul type="disc"><li>
<a href="data-model.html#table_data" title="A.3.&nbsp;DATA">DATA</a>
</li><li>
<a href="data-model.html#table_data_event" title="A.4.&nbsp;DATA_EVENT">DATA_EVENT</a>
</li><li>
<a href="data-model.html#table_outgoing_batch" title="A.29.&nbsp;OUTGOING_BATCH">OUTGOING_BATCH</a>
</li><li>
<a href="data-model.html#table_incoming_batch" title="A.13.&nbsp;INCOMING_BATCH">INCOMING_BATCH</a>
</li><li>
<a href="data-model.html#table_data_gap" title="A.5.&nbsp;DATA_GAP">DATA_GAP</a>
</li><li>
<a href="data-model.html#table_node_host_stats" title="A.26.&nbsp;NODE_HOST_STATS">NODE_HOST_STATS</a>
</li><li>
<a href="data-model.html#table_node_host_channel_stats" title="A.24.&nbsp;NODE_HOST_CHANNEL_STATS">NODE_HOST_CHANNEL_STATS</a>
</li><li>
<a href="data-model.html#table_node_host_job_stats" title="A.25.&nbsp;NODE_HOST_JOB_STATS">NODE_HOST_JOB_STATS</a>
</li></ul></div><p>
The purge job is enabled by the
<code class="literal">start.purge.job</code>
SymmetricDS property. The timing of the three purge jobs (incoming,
outgoing, and data gaps) is controlled by a cron expression as specified
by the following properties:
<code class="literal">job.purge.outgoing.cron</code>
,
<code class="literal">job.purge.incoming.cron</code>
, and
<code class="literal">job.purge.datagaps.cron</code>
. The default is
<code class="literal">0 0 0 * * *</code>
, or once per day at midnight.
</p>

<p>
Two retention period properties indicate how much history SymmetricDS
will retain before purging. The
<code class="literal">purge.retention.minutes</code>
property indicates the period of history to keep for synchronization
tables. The default value is 5 days. The
<code class="literal">statistic.retention.minutes</code>
property indicates the period of history to keep for statistics. The
default value is also 5 days.
</p>
<p> The purge properties should be adjusted according to how
much data is flowing through the system and the amount of storage space
the database has. For an initial deployment it is recommended that the
purge properties be kept at the defaults, since it is often helpful to
be able to look at the captured data in order to triage problems and
profile the synchronization patterns. When scaling up to more nodes, it
is recomended that the purge parameters be scaled back to 24 hours or
less. </p>
</div>

</div>

</div><div xmlns:fo="http://www.w3.org/1999/XSL/Format" class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="30%" align="left"><a accesskey="p" href="planning.html">Prev</a>&nbsp;</td><td width="40%" align="center"><a accesskey="h" href="user-guide.html">Home</a></td><td width="30%" align="right">&nbsp;<a accesskey="n" href="advanced-topics.html">Next</a></td></tr><tr><td width="30%" align="left" valign="top">Chapter&nbsp;3.&nbsp;Planning&nbsp;</td><td width="40%" align="center"><span style="color:white;font-size:90%;"><a href="http://www.symmetricds.org/" title="SymmetricDS">SymmetricDS
                                        </a></span></td><td width="30%" align="right" valign="top">&nbsp;Chapter&nbsp;5.&nbsp;Advanced Topics</td></tr></table></div></body></html>